{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy, scipy as sklearn, librosa, urllib\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import json \n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score\n",
    "import keras\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from os import path\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_curve, auc, silhouette_score,roc_auc_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import opensmile\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras import regularizers\n",
    "from joblib import dump, load\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_features(file,pad):\n",
    "    X, sample_rate = librosa.load(file)\n",
    "    max_ = X.shape[0] / sample_rate\n",
    "    # if max_ < pad:\n",
    "    #     length = (pad * sample_rate) -  (X.shape[0] / sample_rate)\n",
    "    #     X = librosa.util.pad_center(X, size = length, mode = 'constant')\n",
    "    smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "    y = smile.process_signal(X,sample_rate)\n",
    "    #  smile.process_file(file, end=3)\n",
    "    return y\n",
    "def get_max_min(files):\n",
    "    min_, max_ = 100, 0\n",
    "    for file in files:\n",
    "        sound_file, samplerate = librosa.load(file)\n",
    "        t = sound_file.shape[0] / samplerate\n",
    "        if t < min_:\n",
    "            min_ = t\n",
    "        if t >= max_:\n",
    "            max_ = t\n",
    "\n",
    "    return np.round(max_,2) + 0.01, min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add white noise to the original signal\n",
    "def noise_addition(data,noise_percentage_factor=0.035):\n",
    "    noise = np.random.normal(0, data.std(), data.size)\n",
    "    augmented_data = data + noise * noise_percentage_factor\n",
    "    return augmented_data\n",
    "\n",
    "#lower the pitch of the original signal\n",
    "def pitch_scaling(data, sr, num_semitones=-2):\n",
    "    return librosa.effects.pitch_shift(y = data,sr = sr,n_steps = num_semitones)\n",
    "\n",
    "#increase the pitch of the original signal\n",
    "def pitch_scaling2(data, sr, num_semitones=2):\n",
    "    return librosa.effects.pitch_shift(y = data,sr = sr,n_steps = num_semitones)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"DEMoS/data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(columns=['filename', 'features', 'label'])\n",
    "max, min = get_max_min('DEMoS/'+data_df.file_name)\n",
    "filenames= data_df.file_name\n",
    "labels= data_df.label\n",
    "\n",
    "tot = range(list(data_df.index)[-1])\n",
    "\n",
    "\n",
    "\n",
    "for index,file in tqdm(zip(tot,filenames)):\n",
    "    train_data.loc[index] = [file, return_features('DEMoS/'+file,max), labels[index]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PITCH ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_features(file,pad):\n",
    "    X, sample_rate = librosa.load(file)\n",
    "    max_ = X.shape[0] / sample_rate\n",
    "    # if max_ < pad:\n",
    "    #     length = (pad * sample_rate) -  (X.shape[0] / sample_rate)\n",
    "    #     X = librosa.util.pad_center(X, size = length, mode = 'constant')\n",
    "    smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "\n",
    "    X = pitch_scaling(X, sample_rate)\n",
    "    y = smile.process_signal(X,sample_rate)\n",
    "    #  smile.process_file(file, end=3)\n",
    "    return y\n",
    "\n",
    "def return_features2(file,pad):\n",
    "    X, sample_rate = librosa.load(file)\n",
    "    max_ = X.shape[0] / sample_rate\n",
    "    # if max_ < pad:\n",
    "    #     length = (pad * sample_rate) -  (X.shape[0] / sample_rate)\n",
    "    #     X = librosa.util.pad_center(X, size = length, mode = 'constant')\n",
    "    smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "\n",
    "    X = pitch_scaling2(X, sample_rate)\n",
    "    y = smile.process_signal(X,sample_rate)\n",
    "    #  smile.process_file(file, end=3)\n",
    "    return y\n",
    "\n",
    "def get_max_min(files):\n",
    "    min_, max_ = 100, 0\n",
    "    for file in files:\n",
    "        sound_file, samplerate = librosa.load(file)\n",
    "        t = sound_file.shape[0] / samplerate\n",
    "        if t < min_:\n",
    "            min_ = t\n",
    "        if t >= max_:\n",
    "            max_ = t\n",
    "\n",
    "    return np.round(max_,2) + 0.01, min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"EMOVO_dataset/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1174it [01:38, 11.93it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame(columns=['filename', 'features', 'label'])\n",
    "max, min = get_max_min('EMOVO_dataset/'+data_df.file_name)\n",
    "filenames= pd.concat([data_df.file_name]*2, ignore_index=True) \n",
    "labels= pd.concat([data_df.label]*2, ignore_index=True) \n",
    "features = []\n",
    "tot = range(list(data_df.index)[-1]*2)\n",
    "tot_m = (list(data_df.index)[-1]*2)\n",
    "\n",
    "for index,file in tqdm(zip(tot,filenames)):\n",
    "    if index <= tot_m//2:\n",
    "        train_data.loc[index] = [file, return_features('EMOVO_dataset/'+file,max), labels[index]]\n",
    "    else:\n",
    "        train_data.loc[index] = [file, return_features2('EMOVO_dataset/'+file,max), labels[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle(\"pitch_functional_emovo.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
