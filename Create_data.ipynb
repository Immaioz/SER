{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy, scipy as sklearn, librosa, urllib\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import json \n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score\n",
    "import keras\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from os import path\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_curve, auc, silhouette_score,roc_auc_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import opensmile\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras import regularizers\n",
    "from joblib import dump, load\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F0semitoneFrom27.5Hz_sma3nz_amean',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_stddevNorm',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_percentile20.0',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_percentile50.0',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_percentile80.0',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope',\n",
       " 'loudness_sma3_amean',\n",
       " 'loudness_sma3_stddevNorm',\n",
       " 'loudness_sma3_percentile20.0',\n",
       " 'loudness_sma3_percentile50.0',\n",
       " 'loudness_sma3_percentile80.0',\n",
       " 'loudness_sma3_pctlrange0-2',\n",
       " 'loudness_sma3_meanRisingSlope',\n",
       " 'loudness_sma3_stddevRisingSlope',\n",
       " 'loudness_sma3_meanFallingSlope',\n",
       " 'loudness_sma3_stddevFallingSlope',\n",
       " 'spectralFlux_sma3_amean',\n",
       " 'spectralFlux_sma3_stddevNorm',\n",
       " 'mfcc1_sma3_amean',\n",
       " 'mfcc1_sma3_stddevNorm',\n",
       " 'mfcc2_sma3_amean',\n",
       " 'mfcc2_sma3_stddevNorm',\n",
       " 'mfcc3_sma3_amean',\n",
       " 'mfcc3_sma3_stddevNorm',\n",
       " 'mfcc4_sma3_amean',\n",
       " 'mfcc4_sma3_stddevNorm',\n",
       " 'jitterLocal_sma3nz_amean',\n",
       " 'jitterLocal_sma3nz_stddevNorm',\n",
       " 'shimmerLocaldB_sma3nz_amean',\n",
       " 'shimmerLocaldB_sma3nz_stddevNorm',\n",
       " 'HNRdBACF_sma3nz_amean',\n",
       " 'HNRdBACF_sma3nz_stddevNorm',\n",
       " 'logRelF0-H1-H2_sma3nz_amean',\n",
       " 'logRelF0-H1-H2_sma3nz_stddevNorm',\n",
       " 'logRelF0-H1-A3_sma3nz_amean',\n",
       " 'logRelF0-H1-A3_sma3nz_stddevNorm',\n",
       " 'F1frequency_sma3nz_amean',\n",
       " 'F1frequency_sma3nz_stddevNorm',\n",
       " 'F1bandwidth_sma3nz_amean',\n",
       " 'F1bandwidth_sma3nz_stddevNorm',\n",
       " 'F1amplitudeLogRelF0_sma3nz_amean',\n",
       " 'F1amplitudeLogRelF0_sma3nz_stddevNorm',\n",
       " 'F2frequency_sma3nz_amean',\n",
       " 'F2frequency_sma3nz_stddevNorm',\n",
       " 'F2bandwidth_sma3nz_amean',\n",
       " 'F2bandwidth_sma3nz_stddevNorm',\n",
       " 'F2amplitudeLogRelF0_sma3nz_amean',\n",
       " 'F2amplitudeLogRelF0_sma3nz_stddevNorm',\n",
       " 'F3frequency_sma3nz_amean',\n",
       " 'F3frequency_sma3nz_stddevNorm',\n",
       " 'F3bandwidth_sma3nz_amean',\n",
       " 'F3bandwidth_sma3nz_stddevNorm',\n",
       " 'F3amplitudeLogRelF0_sma3nz_amean',\n",
       " 'F3amplitudeLogRelF0_sma3nz_stddevNorm',\n",
       " 'alphaRatioV_sma3nz_amean',\n",
       " 'alphaRatioV_sma3nz_stddevNorm',\n",
       " 'hammarbergIndexV_sma3nz_amean',\n",
       " 'hammarbergIndexV_sma3nz_stddevNorm',\n",
       " 'slopeV0-500_sma3nz_amean',\n",
       " 'slopeV0-500_sma3nz_stddevNorm',\n",
       " 'slopeV500-1500_sma3nz_amean',\n",
       " 'slopeV500-1500_sma3nz_stddevNorm',\n",
       " 'spectralFluxV_sma3nz_amean',\n",
       " 'spectralFluxV_sma3nz_stddevNorm',\n",
       " 'mfcc1V_sma3nz_amean',\n",
       " 'mfcc1V_sma3nz_stddevNorm',\n",
       " 'mfcc2V_sma3nz_amean',\n",
       " 'mfcc2V_sma3nz_stddevNorm',\n",
       " 'mfcc3V_sma3nz_amean',\n",
       " 'mfcc3V_sma3nz_stddevNorm',\n",
       " 'mfcc4V_sma3nz_amean',\n",
       " 'mfcc4V_sma3nz_stddevNorm',\n",
       " 'alphaRatioUV_sma3nz_amean',\n",
       " 'hammarbergIndexUV_sma3nz_amean',\n",
       " 'slopeUV0-500_sma3nz_amean',\n",
       " 'slopeUV500-1500_sma3nz_amean',\n",
       " 'spectralFluxUV_sma3nz_amean',\n",
       " 'loudnessPeaksPerSec',\n",
       " 'VoicedSegmentsPerSec',\n",
       " 'MeanVoicedSegmentLengthSec',\n",
       " 'StddevVoicedSegmentLengthSec',\n",
       " 'MeanUnvoicedSegmentLength',\n",
       " 'StddevUnvoicedSegmentLength',\n",
       " 'equivalentSoundLevel_dBp']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smile = opensmile.Smile(\n",
    "feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "\n",
    "smile.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_features(file,pad):\n",
    "    X, sample_rate = librosa.load(file)\n",
    "    max_ = X.shape[0] / sample_rate\n",
    "    # if max_ < pad:\n",
    "    #     length = (pad * sample_rate) -  (X.shape[0] / sample_rate)\n",
    "    #     X = librosa.util.pad_center(X, size = length, mode = 'constant')\n",
    "    smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "    y = smile.process_signal(X,sample_rate)\n",
    "    #  smile.process_file(file, end=3)\n",
    "    return y\n",
    "def get_max_min(files):\n",
    "    min_, max_ = 100, 0\n",
    "    for file in files:\n",
    "        sound_file, samplerate = librosa.load(file)\n",
    "        t = sound_file.shape[0] / samplerate\n",
    "        if t < min_:\n",
    "            min_ = t\n",
    "        if t >= max_:\n",
    "            max_ = t\n",
    "\n",
    "    return np.round(max_,2) + 0.01, min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add white noise to the original signal\n",
    "def noise_addition(data,noise_percentage_factor=0.035):\n",
    "    noise = np.random.normal(0, data.std(), data.size)\n",
    "    augmented_data = data + noise * noise_percentage_factor\n",
    "    return augmented_data\n",
    "\n",
    "#lower the pitch of the original signal\n",
    "def pitch_scaling(data, sr, num_semitones=-2):\n",
    "    return librosa.effects.pitch_shift(y = data,sr = sr,n_steps = num_semitones)\n",
    "\n",
    "#increase the pitch of the original signal\n",
    "def pitch_scaling2(data, sr, num_semitones=2):\n",
    "    return librosa.effects.pitch_shift(y = data,sr = sr,n_steps = num_semitones)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"Datasets/EMOVO/data.csv\")\n",
    "\n",
    "data_df = pd.read_csv((\"Datasets/emozionalmente/metadata/samples.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>actor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1/dis-f1-b1.wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1/dis-f1-b2.wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1/dis-f1-b3.wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1/dis-f1-d1.wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1/dis-f1-d2.wav</td>\n",
       "      <td>disgust</td>\n",
       "      <td>f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>m3/tri-m3-n1.wav</td>\n",
       "      <td>sadness</td>\n",
       "      <td>m3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>m3/tri-m3-n2.wav</td>\n",
       "      <td>sadness</td>\n",
       "      <td>m3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>m3/tri-m3-n3.wav</td>\n",
       "      <td>sadness</td>\n",
       "      <td>m3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>m3/tri-m3-n4.wav</td>\n",
       "      <td>sadness</td>\n",
       "      <td>m3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>m3/tri-m3-n5.wav</td>\n",
       "      <td>sadness</td>\n",
       "      <td>m3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            file_name    label actor\n",
       "0    f1/dis-f1-b1.wav  disgust    f1\n",
       "1    f1/dis-f1-b2.wav  disgust    f1\n",
       "2    f1/dis-f1-b3.wav  disgust    f1\n",
       "3    f1/dis-f1-d1.wav  disgust    f1\n",
       "4    f1/dis-f1-d2.wav  disgust    f1\n",
       "..                ...      ...   ...\n",
       "583  m3/tri-m3-n1.wav  sadness    m3\n",
       "584  m3/tri-m3-n2.wav  sadness    m3\n",
       "585  m3/tri-m3-n3.wav  sadness    m3\n",
       "586  m3/tri-m3-n4.wav  sadness    m3\n",
       "587  m3/tri-m3-n5.wav  sadness    m3\n",
       "\n",
       "[588 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.rename(columns={'emotion_expressed': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_language</th>\n",
       "      <th>actor</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1614951631538.wav</td>\n",
       "      <td>E’ andato a scuola dopo pranzo</td>\n",
       "      <td>italian</td>\n",
       "      <td>d4bbc5043503b9aed309ede00854ee48937684b57a1cc0...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1613671614352.wav</td>\n",
       "      <td>Tornerà a casa presto</td>\n",
       "      <td>italian</td>\n",
       "      <td>b830cbf6e79aeeeec1fbf2ef3be741628ffc574c9b15f3...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1613994293936.wav</td>\n",
       "      <td>Vado in biblioteca</td>\n",
       "      <td>italian</td>\n",
       "      <td>acdd987f9c1700b25898d3bd30c201df5ad4f34b3ca5eb...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1617135480050.wav</td>\n",
       "      <td>E’ andato a scuola dopo pranzo</td>\n",
       "      <td>italian</td>\n",
       "      <td>28043d2516f2d956b81ce66cc01fbd427ac54ff1eb3a07...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1613658275427.wav</td>\n",
       "      <td>Zia Marta ha detto che devo stare a casa stasera</td>\n",
       "      <td>italian</td>\n",
       "      <td>5b8476bb94a4a1a17df32b417ec035029f48e4487c9055...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6897</th>\n",
       "      <td>1613310701161.wav</td>\n",
       "      <td>E’ andato a scuola dopo pranzo</td>\n",
       "      <td>italian</td>\n",
       "      <td>1ae2a40d6e3a1b8c6041da953f650dc017fea8c646648b...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6898</th>\n",
       "      <td>1613061195435.wav</td>\n",
       "      <td>E’ impegnato in una riunione</td>\n",
       "      <td>italian</td>\n",
       "      <td>f4d0c9178a221556efe45a4ea3d2bb77b470626409af7f...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6899</th>\n",
       "      <td>1615231434303.wav</td>\n",
       "      <td>L’ho incontrato oggi dopo 2 anni</td>\n",
       "      <td>italian</td>\n",
       "      <td>7ce215563f7b620fdd32c6618a95215100b4fbede0eb4f...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6900</th>\n",
       "      <td>1613403675624.wav</td>\n",
       "      <td>E’ una notte stellata</td>\n",
       "      <td>italian</td>\n",
       "      <td>1dab1d691c3cb60f475163ff79b4fa2f58bac807098245...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6901</th>\n",
       "      <td>1613646342154.wav</td>\n",
       "      <td>Zia Marta ha detto che devo stare a casa stasera</td>\n",
       "      <td>italian</td>\n",
       "      <td>16d806aae1dff6ee86834bffe370a4a3e5a968490366af...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6902 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name                                          sentence  \\\n",
       "0     1614951631538.wav                    E’ andato a scuola dopo pranzo   \n",
       "1     1613671614352.wav                             Tornerà a casa presto   \n",
       "2     1613994293936.wav                                Vado in biblioteca   \n",
       "3     1617135480050.wav                    E’ andato a scuola dopo pranzo   \n",
       "4     1613658275427.wav  Zia Marta ha detto che devo stare a casa stasera   \n",
       "...                 ...                                               ...   \n",
       "6897  1613310701161.wav                    E’ andato a scuola dopo pranzo   \n",
       "6898  1613061195435.wav                      E’ impegnato in una riunione   \n",
       "6899  1615231434303.wav                  L’ho incontrato oggi dopo 2 anni   \n",
       "6900  1613403675624.wav                             E’ una notte stellata   \n",
       "6901  1613646342154.wav  Zia Marta ha detto che devo stare a casa stasera   \n",
       "\n",
       "     sentence_language                                              actor  \\\n",
       "0              italian  d4bbc5043503b9aed309ede00854ee48937684b57a1cc0...   \n",
       "1              italian  b830cbf6e79aeeeec1fbf2ef3be741628ffc574c9b15f3...   \n",
       "2              italian  acdd987f9c1700b25898d3bd30c201df5ad4f34b3ca5eb...   \n",
       "3              italian  28043d2516f2d956b81ce66cc01fbd427ac54ff1eb3a07...   \n",
       "4              italian  5b8476bb94a4a1a17df32b417ec035029f48e4487c9055...   \n",
       "...                ...                                                ...   \n",
       "6897           italian  1ae2a40d6e3a1b8c6041da953f650dc017fea8c646648b...   \n",
       "6898           italian  f4d0c9178a221556efe45a4ea3d2bb77b470626409af7f...   \n",
       "6899           italian  7ce215563f7b620fdd32c6618a95215100b4fbede0eb4f...   \n",
       "6900           italian  1dab1d691c3cb60f475163ff79b4fa2f58bac807098245...   \n",
       "6901           italian  16d806aae1dff6ee86834bffe370a4a3e5a968490366af...   \n",
       "\n",
       "         label  \n",
       "0        anger  \n",
       "1        anger  \n",
       "2        anger  \n",
       "3        anger  \n",
       "4        anger  \n",
       "...        ...  \n",
       "6897  surprise  \n",
       "6898  surprise  \n",
       "6899  surprise  \n",
       "6900  surprise  \n",
       "6901  surprise  \n",
       "\n",
       "[6902 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1614951631538.wav'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"file_name\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X, sample_rate = librosa.load(\"Datasets/emozionalmente/audio/1614951631538.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6901it [09:02, 12.72it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame(columns=['filename', 'features', 'label'])\n",
    "max, min = get_max_min('Datasets/emozionalmente/audio/'+data_df.file_name)\n",
    "filenames= data_df.file_name\n",
    "labels= data_df.label\n",
    "\n",
    "tot = range(list(data_df.index)[-1])\n",
    "\n",
    "\n",
    "\n",
    "for index,file in tqdm(zip(tot,filenames)):\n",
    "    train_data.loc[index] = [file, return_features('Datasets/emozionalmente/audio/'+file,max), labels[index]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle(\"emozionalmente_clear.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PITCH ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_features(file,pad):\n",
    "    X, sample_rate = librosa.load(file)\n",
    "    max_ = X.shape[0] / sample_rate\n",
    "    # if max_ < pad:\n",
    "    #     length = (pad * sample_rate) -  (X.shape[0] / sample_rate)\n",
    "    #     X = librosa.util.pad_center(X, size = length, mode = 'constant')\n",
    "    smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "\n",
    "    X = pitch_scaling(X, sample_rate)\n",
    "    y = smile.process_signal(X,sample_rate)\n",
    "    #  smile.process_file(file, end=3)\n",
    "    return y\n",
    "\n",
    "def return_features2(file,pad):\n",
    "    X, sample_rate = librosa.load(file)\n",
    "    max_ = X.shape[0] / sample_rate\n",
    "    # if max_ < pad:\n",
    "    #     length = (pad * sample_rate) -  (X.shape[0] / sample_rate)\n",
    "    #     X = librosa.util.pad_center(X, size = length, mode = 'constant')\n",
    "    smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "\n",
    "    X = pitch_scaling2(X, sample_rate)\n",
    "    y = smile.process_signal(X,sample_rate)\n",
    "    #  smile.process_file(file, end=3)\n",
    "    return y\n",
    "\n",
    "def get_max_min(files):\n",
    "    min_, max_ = 100, 0\n",
    "    for file in files:\n",
    "        sound_file, samplerate = librosa.load(file)\n",
    "        t = sound_file.shape[0] / samplerate\n",
    "        if t < min_:\n",
    "            min_ = t\n",
    "        if t >= max_:\n",
    "            max_ = t\n",
    "\n",
    "    return np.round(max_,2) + 0.01, min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"EMOVO_dataset/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1174it [01:38, 11.93it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame(columns=['filename', 'features', 'label'])\n",
    "max, min = get_max_min('EMOVO_dataset/'+data_df.file_name)\n",
    "filenames= pd.concat([data_df.file_name]*2, ignore_index=True) \n",
    "labels= pd.concat([data_df.label]*2, ignore_index=True) \n",
    "features = []\n",
    "tot = range(list(data_df.index)[-1]*2)\n",
    "tot_m = (list(data_df.index)[-1]*2)\n",
    "\n",
    "for index,file in tqdm(zip(tot,filenames)):\n",
    "    if index <= tot_m//2:\n",
    "        train_data.loc[index] = [file, return_features('EMOVO_dataset/'+file,max), labels[index]]\n",
    "    else:\n",
    "        train_data.loc[index] = [file, return_features2('EMOVO_dataset/'+file,max), labels[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle(\"pitch_functional_emovo.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
