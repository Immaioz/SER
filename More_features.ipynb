{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import librosa\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from typing import Tuple, Union\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"EMOVO_dataset/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_min(files):\n",
    "    min_, max_ = 100, 0\n",
    "    for file in files:\n",
    "        sound_file, samplerate = librosa.load(file)\n",
    "        t = sound_file.shape[0] / samplerate\n",
    "        if t < min_:\n",
    "            min_ = t\n",
    "        if t > max_:\n",
    "            max_ = t\n",
    "\n",
    "    return max_, min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_new(file,pad):\n",
    "    X, sample_rate = librosa.load(file)\n",
    "    max_ = X.shape[0] / sample_rate\n",
    "    if pad:\n",
    "        length = (max_ * sample_rate) - X.shape[0]\n",
    "        X = np.pad(X, (0, int(length)), 'constant')\n",
    "    \n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    result = np.array([])\n",
    "\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=50).T, axis=0)\n",
    "    result = np.hstack((result, mfccs))\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma))\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0) \n",
    "    result = np.hstack((result, mel))\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, contrast))\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file, pad):\n",
    "    X, sample_rate = librosa.load(file)\n",
    "    max_ = X.shape[0] / sample_rate\n",
    "    if pad:\n",
    "        length = (max_ * sample_rate) - X.shape[0]\n",
    "        X = np.pad(X, (0, int(length)), 'constant')\n",
    "\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "\n",
    "# fmin 和 fmax 对应于人类语音的最小最大基本频率\n",
    "    pitches, magnitudes = librosa.piptrack(y=X, sr=sample_rate, S=stft, fmin=70, fmax=400)\n",
    "    pitch = []\n",
    "    for i in range(magnitudes.shape[1]):\n",
    "        index = magnitudes[:, 1].argmax()\n",
    "        pitch.append(pitches[index, i])\n",
    "\n",
    "    pitch_tuning_offset = librosa.pitch_tuning(pitches)\n",
    "    pitchmean = np.mean(pitch)\n",
    "    pitchstd = np.std(pitch)\n",
    "    pitchmax = np.max(pitch)\n",
    "    pitchmin = np.min(pitch)\n",
    "\n",
    "# 频谱质心\n",
    "    cent = librosa.feature.spectral_centroid(y=X, sr=sample_rate)\n",
    "    cent = cent / np.sum(cent)\n",
    "    meancent = np.mean(cent)\n",
    "    stdcent = np.std(cent)\n",
    "    maxcent = np.max(cent)\n",
    "\n",
    "# 谱平面\n",
    "    flatness = np.mean(librosa.feature.spectral_flatness(y=X))\n",
    "    \n",
    "# 使用系数为50的MFCC特征\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=50).T, axis=0) #######\n",
    "    mfccsstd = np.std(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=50).T, axis=0)\n",
    "    mfccmax = np.max(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=50).T, axis=0)\n",
    "# 色谱图\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0) ######\n",
    "\n",
    "# 梅尔频率\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0) ######\n",
    "    print(mel.shape)\n",
    "\n",
    "# ottava对比\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0) ########\n",
    "\n",
    "# 过零率\n",
    "    zerocr = np.mean(librosa.feature.zero_crossing_rate(X)) ####\n",
    "\n",
    "    S, phase = librosa.magphase(stft)\n",
    "    meanMagnitude = np.mean(S)\n",
    "    stdMagnitude = np.std(S)\n",
    "    maxMagnitude = np.max(S)\n",
    "\n",
    "# 均方根能量\n",
    "    rmse = librosa.feature.rms(S=S)[0] ######\n",
    "    meanrms = np.mean(rmse)\n",
    "    stdrms = np.std(rmse)\n",
    "    maxrms = np.max(rmse)\n",
    "\n",
    "    ext_features = np.array([\n",
    "    flatness, zerocr, meanMagnitude, maxMagnitude, meancent, stdcent,\n",
    "    maxcent, stdMagnitude, pitchmean, pitchmax, pitchstd,\n",
    "    pitch_tuning_offset, meanrms, maxrms, stdrms\n",
    "    ])\n",
    "\n",
    "\n",
    "    ext_features = np.concatenate((ext_features, mfccs, mfccsstd, mfccmax, chroma, mel, contrast))\n",
    "\n",
    "    return ext_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "u = extract('EMOVO_dataset/'+data_df.file_name[0], max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "file = 'EMOVO_dataset/'+data_df.file_name[0] \n",
    "X, sample_rate = librosa.load(file)\n",
    "max_ = X.shape[0] / sample_rate\n",
    "if 1:\n",
    "    length = (max_ * sample_rate) - X.shape[0]\n",
    "    X = np.pad(X, (0, int(length)), 'constant')\n",
    "\n",
    "stft = np.abs(librosa.stft(X))\n",
    "mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0) ######\n",
    "print(mel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23fd6095fd0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max, min = get_max_min('EMOVO_dataset/'+data_df.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(columns=['filename', 'features', 'label'])\n",
    "\n",
    "features = []\n",
    "for index, file in zip(data_df.index, data_df.file_name):\n",
    "    train_data.loc[index] = [file, extract('EMOVO_dataset/'+file, max), data_df.label[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = list(train_data[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(fit)\n",
    "X = scaler.transform(fit)\n",
    "Y = list(train_data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(fit).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "data_classes = (list((train_data[\"label\"].unique())))\n",
    "Y = to_categorical(list((train_data[\"label\"].apply(data_classes.index))))\n",
    "X = np.stack(train_data[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588, 312)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=22)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (X_train.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423, 312)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.Sequential()\n",
    "kernel_sizes = [5, 5]\n",
    "model.add(keras.layers.Input(shape=(X_train.shape[1],1)))\n",
    "for size in kernel_sizes:\n",
    "    model.add(keras.layers.Conv1D(\n",
    "        filters = 32,\n",
    "        kernel_size = size,\n",
    "        padding = 'same'\n",
    "    ))  # 卷积层\n",
    "    model.add(keras.layers.BatchNormalization(axis=-1))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32))\n",
    "model.add(keras.layers.BatchNormalization(axis = -1))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))  # 分类层\n",
    "optimzer = keras.optimizers.Adam(learning_rate= 0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimzer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9984</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">319,520</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │         \u001b[38;5;34m5,152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9984\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │       \u001b[38;5;34m319,520\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m231\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">325,479</span> (1.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m325,479\u001b[0m (1.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">325,287</span> (1.24 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m325,287\u001b[0m (1.24 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 241ms/step - accuracy: 0.1732 - loss: 2.6485 - val_accuracy: 0.1604 - val_loss: 4.8462\n",
      "Epoch 2/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.1663 - loss: 2.6061 - val_accuracy: 0.1604 - val_loss: 4.2321\n",
      "Epoch 3/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.1915 - loss: 2.4732 - val_accuracy: 0.1698 - val_loss: 3.9447\n",
      "Epoch 4/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1799 - loss: 2.5184 - val_accuracy: 0.1792 - val_loss: 3.6874\n",
      "Epoch 5/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2030 - loss: 2.2758 - val_accuracy: 0.2075 - val_loss: 3.3878\n",
      "Epoch 6/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.1985 - loss: 2.3391 - val_accuracy: 0.2170 - val_loss: 3.1789\n",
      "Epoch 7/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1904 - loss: 2.3100 - val_accuracy: 0.2170 - val_loss: 2.9787\n",
      "Epoch 8/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2103 - loss: 2.2548 - val_accuracy: 0.2547 - val_loss: 2.8385\n",
      "Epoch 9/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.2185 - loss: 2.3589 - val_accuracy: 0.2547 - val_loss: 2.7313\n",
      "Epoch 10/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2423 - loss: 2.1770 - val_accuracy: 0.2642 - val_loss: 2.6414\n",
      "Epoch 11/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2381 - loss: 2.2068 - val_accuracy: 0.2642 - val_loss: 2.5550\n",
      "Epoch 12/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2928 - loss: 2.0412 - val_accuracy: 0.2642 - val_loss: 2.5017\n",
      "Epoch 13/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2556 - loss: 2.0914 - val_accuracy: 0.2547 - val_loss: 2.4687\n",
      "Epoch 14/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2727 - loss: 2.1129 - val_accuracy: 0.2453 - val_loss: 2.4476\n",
      "Epoch 15/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2803 - loss: 1.9910 - val_accuracy: 0.2453 - val_loss: 2.4332\n",
      "Epoch 16/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2845 - loss: 2.0545 - val_accuracy: 0.2264 - val_loss: 2.3951\n",
      "Epoch 17/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2693 - loss: 1.9852 - val_accuracy: 0.2264 - val_loss: 2.3726\n",
      "Epoch 18/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2897 - loss: 1.9184 - val_accuracy: 0.2264 - val_loss: 2.3458\n",
      "Epoch 19/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2701 - loss: 1.9265 - val_accuracy: 0.2358 - val_loss: 2.3384\n",
      "Epoch 20/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2892 - loss: 1.9495 - val_accuracy: 0.2358 - val_loss: 2.3384\n",
      "Epoch 21/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3158 - loss: 1.8729 - val_accuracy: 0.2358 - val_loss: 2.3447\n",
      "Epoch 22/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3293 - loss: 1.8356 - val_accuracy: 0.2358 - val_loss: 2.3554\n",
      "Epoch 23/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3169 - loss: 1.8435 - val_accuracy: 0.2264 - val_loss: 2.3601\n",
      "Epoch 24/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3321 - loss: 1.7892 - val_accuracy: 0.2264 - val_loss: 2.3704\n",
      "Epoch 25/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2900 - loss: 1.8256 - val_accuracy: 0.2264 - val_loss: 2.3785\n",
      "Epoch 26/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3146 - loss: 1.7649 - val_accuracy: 0.2170 - val_loss: 2.3822\n",
      "Epoch 27/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3195 - loss: 1.7246 - val_accuracy: 0.2170 - val_loss: 2.3851\n",
      "Epoch 28/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3149 - loss: 1.7678 - val_accuracy: 0.2170 - val_loss: 2.3926\n",
      "Epoch 29/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3418 - loss: 1.7459 - val_accuracy: 0.2075 - val_loss: 2.3897\n",
      "Epoch 30/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3408 - loss: 1.7441 - val_accuracy: 0.2170 - val_loss: 2.3802\n",
      "Epoch 31/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3169 - loss: 1.7864 - val_accuracy: 0.2358 - val_loss: 2.3756\n",
      "Epoch 32/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3279 - loss: 1.7435 - val_accuracy: 0.2264 - val_loss: 2.3641\n",
      "Epoch 33/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4080 - loss: 1.6166 - val_accuracy: 0.2264 - val_loss: 2.3497\n",
      "Epoch 34/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.3635 - loss: 1.6741 - val_accuracy: 0.2453 - val_loss: 2.3304\n",
      "Epoch 35/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3374 - loss: 1.6294 - val_accuracy: 0.2547 - val_loss: 2.2999\n",
      "Epoch 36/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3780 - loss: 1.6305 - val_accuracy: 0.2925 - val_loss: 2.2614\n",
      "Epoch 37/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3463 - loss: 1.6889 - val_accuracy: 0.2925 - val_loss: 2.2232\n",
      "Epoch 38/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3473 - loss: 1.6032 - val_accuracy: 0.2925 - val_loss: 2.1898\n",
      "Epoch 39/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3903 - loss: 1.5906 - val_accuracy: 0.2925 - val_loss: 2.1540\n",
      "Epoch 40/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3936 - loss: 1.5905 - val_accuracy: 0.2925 - val_loss: 2.1282\n",
      "Epoch 41/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3769 - loss: 1.6032 - val_accuracy: 0.2925 - val_loss: 2.0992\n",
      "Epoch 42/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4288 - loss: 1.5312 - val_accuracy: 0.3113 - val_loss: 2.0648\n",
      "Epoch 43/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3439 - loss: 1.6208 - val_accuracy: 0.3113 - val_loss: 2.0372\n",
      "Epoch 44/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4099 - loss: 1.5720 - val_accuracy: 0.3019 - val_loss: 2.0103\n",
      "Epoch 45/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3848 - loss: 1.6146 - val_accuracy: 0.3019 - val_loss: 1.9846\n",
      "Epoch 46/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4262 - loss: 1.5573 - val_accuracy: 0.3019 - val_loss: 1.9594\n",
      "Epoch 47/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4022 - loss: 1.5837 - val_accuracy: 0.3113 - val_loss: 1.9371\n",
      "Epoch 48/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3868 - loss: 1.5477 - val_accuracy: 0.3113 - val_loss: 1.9209\n",
      "Epoch 49/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4164 - loss: 1.5518 - val_accuracy: 0.3113 - val_loss: 1.9044\n",
      "Epoch 50/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3937 - loss: 1.5329 - val_accuracy: 0.3113 - val_loss: 1.8840\n",
      "Epoch 51/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3900 - loss: 1.4675 - val_accuracy: 0.3113 - val_loss: 1.8598\n",
      "Epoch 52/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4101 - loss: 1.4783 - val_accuracy: 0.3208 - val_loss: 1.8302\n",
      "Epoch 53/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4279 - loss: 1.5058 - val_accuracy: 0.3208 - val_loss: 1.8045\n",
      "Epoch 54/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3898 - loss: 1.4757 - val_accuracy: 0.3302 - val_loss: 1.7835\n",
      "Epoch 55/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4500 - loss: 1.4769 - val_accuracy: 0.3302 - val_loss: 1.7649\n",
      "Epoch 56/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4311 - loss: 1.4683 - val_accuracy: 0.3113 - val_loss: 1.7497\n",
      "Epoch 57/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3654 - loss: 1.5347 - val_accuracy: 0.3113 - val_loss: 1.7336\n",
      "Epoch 58/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4463 - loss: 1.4224 - val_accuracy: 0.3113 - val_loss: 1.7173\n",
      "Epoch 59/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4764 - loss: 1.4211 - val_accuracy: 0.3019 - val_loss: 1.6999\n",
      "Epoch 60/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4034 - loss: 1.4763 - val_accuracy: 0.3019 - val_loss: 1.6788\n",
      "Epoch 61/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4351 - loss: 1.4771 - val_accuracy: 0.3208 - val_loss: 1.6549\n",
      "Epoch 62/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4484 - loss: 1.3717 - val_accuracy: 0.3491 - val_loss: 1.6310\n",
      "Epoch 63/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4469 - loss: 1.4081 - val_accuracy: 0.3585 - val_loss: 1.6068\n",
      "Epoch 64/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4410 - loss: 1.4060 - val_accuracy: 0.3585 - val_loss: 1.5854\n",
      "Epoch 65/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4709 - loss: 1.4151 - val_accuracy: 0.3774 - val_loss: 1.5662\n",
      "Epoch 66/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4531 - loss: 1.4224 - val_accuracy: 0.3774 - val_loss: 1.5501\n",
      "Epoch 67/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4471 - loss: 1.3604 - val_accuracy: 0.3774 - val_loss: 1.5358\n",
      "Epoch 68/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4555 - loss: 1.4132 - val_accuracy: 0.3868 - val_loss: 1.5243\n",
      "Epoch 69/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4602 - loss: 1.3947 - val_accuracy: 0.3868 - val_loss: 1.5112\n",
      "Epoch 70/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4669 - loss: 1.3560 - val_accuracy: 0.3962 - val_loss: 1.4941\n",
      "Epoch 71/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4608 - loss: 1.3730 - val_accuracy: 0.4151 - val_loss: 1.4720\n",
      "Epoch 72/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4639 - loss: 1.3673 - val_accuracy: 0.4245 - val_loss: 1.4454\n",
      "Epoch 73/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5011 - loss: 1.3231 - val_accuracy: 0.4528 - val_loss: 1.4193\n",
      "Epoch 74/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4885 - loss: 1.3453 - val_accuracy: 0.4528 - val_loss: 1.3949\n",
      "Epoch 75/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4741 - loss: 1.3584 - val_accuracy: 0.4717 - val_loss: 1.3699\n",
      "Epoch 76/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4835 - loss: 1.3166 - val_accuracy: 0.4811 - val_loss: 1.3445\n",
      "Epoch 77/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5096 - loss: 1.3192 - val_accuracy: 0.5283 - val_loss: 1.3203\n",
      "Epoch 78/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4856 - loss: 1.3387 - val_accuracy: 0.5472 - val_loss: 1.2973\n",
      "Epoch 79/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5005 - loss: 1.3196 - val_accuracy: 0.5472 - val_loss: 1.2771\n",
      "Epoch 80/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5257 - loss: 1.3136 - val_accuracy: 0.5755 - val_loss: 1.2577\n",
      "Epoch 81/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4856 - loss: 1.3112 - val_accuracy: 0.5849 - val_loss: 1.2402\n",
      "Epoch 82/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5311 - loss: 1.2893 - val_accuracy: 0.5849 - val_loss: 1.2257\n",
      "Epoch 83/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4877 - loss: 1.3261 - val_accuracy: 0.5849 - val_loss: 1.2132\n",
      "Epoch 84/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5157 - loss: 1.2879 - val_accuracy: 0.5849 - val_loss: 1.2012\n",
      "Epoch 85/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5185 - loss: 1.2995 - val_accuracy: 0.5943 - val_loss: 1.1900\n",
      "Epoch 86/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5037 - loss: 1.2867 - val_accuracy: 0.5943 - val_loss: 1.1809\n",
      "Epoch 87/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5076 - loss: 1.2779 - val_accuracy: 0.6226 - val_loss: 1.1718\n",
      "Epoch 88/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5126 - loss: 1.2733 - val_accuracy: 0.6038 - val_loss: 1.1636\n",
      "Epoch 89/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5505 - loss: 1.2970 - val_accuracy: 0.6038 - val_loss: 1.1553\n",
      "Epoch 90/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5479 - loss: 1.2420 - val_accuracy: 0.6132 - val_loss: 1.1487\n",
      "Epoch 91/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5453 - loss: 1.2123 - val_accuracy: 0.6226 - val_loss: 1.1432\n",
      "Epoch 92/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.4738 - loss: 1.3100 - val_accuracy: 0.6321 - val_loss: 1.1369\n",
      "Epoch 93/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5160 - loss: 1.2856 - val_accuracy: 0.6321 - val_loss: 1.1304\n",
      "Epoch 94/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4987 - loss: 1.3063 - val_accuracy: 0.6415 - val_loss: 1.1243\n",
      "Epoch 95/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5474 - loss: 1.2121 - val_accuracy: 0.6415 - val_loss: 1.1190\n",
      "Epoch 96/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5564 - loss: 1.2733 - val_accuracy: 0.6321 - val_loss: 1.1146\n",
      "Epoch 97/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5468 - loss: 1.2658 - val_accuracy: 0.6226 - val_loss: 1.1097\n",
      "Epoch 98/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5181 - loss: 1.2294 - val_accuracy: 0.6226 - val_loss: 1.1024\n",
      "Epoch 99/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5231 - loss: 1.2930 - val_accuracy: 0.6415 - val_loss: 1.0959\n",
      "Epoch 100/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5684 - loss: 1.2088 - val_accuracy: 0.6415 - val_loss: 1.0892\n",
      "Epoch 101/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4720 - loss: 1.2764 - val_accuracy: 0.6321 - val_loss: 1.0820\n",
      "Epoch 102/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5338 - loss: 1.2256 - val_accuracy: 0.6226 - val_loss: 1.0732\n",
      "Epoch 103/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5320 - loss: 1.2022 - val_accuracy: 0.6321 - val_loss: 1.0664\n",
      "Epoch 104/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5372 - loss: 1.2029 - val_accuracy: 0.6604 - val_loss: 1.0603\n",
      "Epoch 105/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5228 - loss: 1.2303 - val_accuracy: 0.6604 - val_loss: 1.0556\n",
      "Epoch 106/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5582 - loss: 1.2357 - val_accuracy: 0.6698 - val_loss: 1.0511\n",
      "Epoch 107/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5331 - loss: 1.1858 - val_accuracy: 0.6698 - val_loss: 1.0457\n",
      "Epoch 108/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5524 - loss: 1.1862 - val_accuracy: 0.6698 - val_loss: 1.0408\n",
      "Epoch 109/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5485 - loss: 1.1730 - val_accuracy: 0.6604 - val_loss: 1.0375\n",
      "Epoch 110/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5992 - loss: 1.1641 - val_accuracy: 0.6698 - val_loss: 1.0354\n",
      "Epoch 111/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5958 - loss: 1.1514 - val_accuracy: 0.6698 - val_loss: 1.0319\n",
      "Epoch 112/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5702 - loss: 1.1719 - val_accuracy: 0.6698 - val_loss: 1.0285\n",
      "Epoch 113/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6078 - loss: 1.1373 - val_accuracy: 0.6887 - val_loss: 1.0251\n",
      "Epoch 114/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5762 - loss: 1.1506 - val_accuracy: 0.6792 - val_loss: 1.0208\n",
      "Epoch 115/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5883 - loss: 1.1376 - val_accuracy: 0.6792 - val_loss: 1.0175\n",
      "Epoch 116/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5359 - loss: 1.1945 - val_accuracy: 0.6792 - val_loss: 1.0145\n",
      "Epoch 117/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5707 - loss: 1.1417 - val_accuracy: 0.6792 - val_loss: 1.0112\n",
      "Epoch 118/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6142 - loss: 1.0917 - val_accuracy: 0.6792 - val_loss: 1.0068\n",
      "Epoch 119/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6095 - loss: 1.0986 - val_accuracy: 0.6698 - val_loss: 1.0029\n",
      "Epoch 120/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6042 - loss: 1.1000 - val_accuracy: 0.6698 - val_loss: 1.0008\n",
      "Epoch 121/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5964 - loss: 1.1046 - val_accuracy: 0.6792 - val_loss: 0.9985\n",
      "Epoch 122/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5459 - loss: 1.1643 - val_accuracy: 0.6792 - val_loss: 0.9967\n",
      "Epoch 123/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5815 - loss: 1.1509 - val_accuracy: 0.6792 - val_loss: 0.9957\n",
      "Epoch 124/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5600 - loss: 1.1171 - val_accuracy: 0.6792 - val_loss: 0.9932\n",
      "Epoch 125/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6174 - loss: 1.0579 - val_accuracy: 0.6887 - val_loss: 0.9893\n",
      "Epoch 126/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6121 - loss: 1.0837 - val_accuracy: 0.6887 - val_loss: 0.9871\n",
      "Epoch 127/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6123 - loss: 1.0796 - val_accuracy: 0.6981 - val_loss: 0.9856\n",
      "Epoch 128/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5882 - loss: 1.1016 - val_accuracy: 0.6981 - val_loss: 0.9823\n",
      "Epoch 129/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6134 - loss: 1.0475 - val_accuracy: 0.7075 - val_loss: 0.9780\n",
      "Epoch 130/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6150 - loss: 1.0800 - val_accuracy: 0.7170 - val_loss: 0.9744\n",
      "Epoch 131/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5807 - loss: 1.1142 - val_accuracy: 0.7075 - val_loss: 0.9696\n",
      "Epoch 132/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6079 - loss: 1.0663 - val_accuracy: 0.7075 - val_loss: 0.9662\n",
      "Epoch 133/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6163 - loss: 1.0420 - val_accuracy: 0.7075 - val_loss: 0.9640\n",
      "Epoch 134/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6330 - loss: 1.0249 - val_accuracy: 0.7075 - val_loss: 0.9599\n",
      "Epoch 135/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6176 - loss: 1.0892 - val_accuracy: 0.7075 - val_loss: 0.9558\n",
      "Epoch 136/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6237 - loss: 1.0436 - val_accuracy: 0.6887 - val_loss: 0.9534\n",
      "Epoch 137/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5990 - loss: 1.0815 - val_accuracy: 0.6887 - val_loss: 0.9505\n",
      "Epoch 138/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6296 - loss: 1.0266 - val_accuracy: 0.6792 - val_loss: 0.9474\n",
      "Epoch 139/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6073 - loss: 1.0276 - val_accuracy: 0.6792 - val_loss: 0.9444\n",
      "Epoch 140/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6236 - loss: 1.0615 - val_accuracy: 0.6887 - val_loss: 0.9423\n",
      "Epoch 141/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6391 - loss: 1.0168 - val_accuracy: 0.6981 - val_loss: 0.9412\n",
      "Epoch 142/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6153 - loss: 1.0560 - val_accuracy: 0.6981 - val_loss: 0.9403\n",
      "Epoch 143/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6210 - loss: 1.0164 - val_accuracy: 0.6981 - val_loss: 0.9406\n",
      "Epoch 144/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6543 - loss: 1.0049 - val_accuracy: 0.6981 - val_loss: 0.9424\n",
      "Epoch 145/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5898 - loss: 1.0456 - val_accuracy: 0.7075 - val_loss: 0.9419\n",
      "Epoch 146/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6380 - loss: 1.0115 - val_accuracy: 0.7075 - val_loss: 0.9411\n",
      "Epoch 147/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6622 - loss: 0.9607 - val_accuracy: 0.7075 - val_loss: 0.9385\n",
      "Epoch 148/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6433 - loss: 0.9931 - val_accuracy: 0.6981 - val_loss: 0.9369\n",
      "Epoch 149/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6147 - loss: 1.0272 - val_accuracy: 0.6792 - val_loss: 0.9336\n",
      "Epoch 150/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6378 - loss: 0.9834 - val_accuracy: 0.6792 - val_loss: 0.9306\n",
      "Epoch 151/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6320 - loss: 1.0069 - val_accuracy: 0.6792 - val_loss: 0.9278\n",
      "Epoch 152/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6454 - loss: 0.9600 - val_accuracy: 0.6981 - val_loss: 0.9265\n",
      "Epoch 153/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6469 - loss: 0.9931 - val_accuracy: 0.6981 - val_loss: 0.9245\n",
      "Epoch 154/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6472 - loss: 0.9804 - val_accuracy: 0.6981 - val_loss: 0.9204\n",
      "Epoch 155/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6287 - loss: 0.9733 - val_accuracy: 0.6887 - val_loss: 0.9174\n",
      "Epoch 156/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6619 - loss: 0.9253 - val_accuracy: 0.6887 - val_loss: 0.9138\n",
      "Epoch 157/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6650 - loss: 0.9402 - val_accuracy: 0.7075 - val_loss: 0.9091\n",
      "Epoch 158/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6339 - loss: 0.9667 - val_accuracy: 0.7170 - val_loss: 0.9039\n",
      "Epoch 159/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6791 - loss: 0.9391 - val_accuracy: 0.6981 - val_loss: 0.9013\n",
      "Epoch 160/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7022 - loss: 0.8962 - val_accuracy: 0.6981 - val_loss: 0.9012\n",
      "Epoch 161/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6768 - loss: 0.9422 - val_accuracy: 0.6887 - val_loss: 0.9021\n",
      "Epoch 162/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6726 - loss: 0.9277 - val_accuracy: 0.6887 - val_loss: 0.9041\n",
      "Epoch 163/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6796 - loss: 0.9325 - val_accuracy: 0.6981 - val_loss: 0.9050\n",
      "Epoch 164/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6684 - loss: 0.9566 - val_accuracy: 0.6887 - val_loss: 0.9069\n",
      "Epoch 165/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6616 - loss: 0.9300 - val_accuracy: 0.6981 - val_loss: 0.9062\n",
      "Epoch 166/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6540 - loss: 0.9278 - val_accuracy: 0.6981 - val_loss: 0.9039\n",
      "Epoch 167/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6721 - loss: 0.9247 - val_accuracy: 0.6981 - val_loss: 0.9006\n",
      "Epoch 168/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6572 - loss: 0.9342 - val_accuracy: 0.6887 - val_loss: 0.8970\n",
      "Epoch 169/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6642 - loss: 0.9274 - val_accuracy: 0.6981 - val_loss: 0.8936\n",
      "Epoch 170/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6894 - loss: 0.8803 - val_accuracy: 0.6981 - val_loss: 0.8895\n",
      "Epoch 171/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6841 - loss: 0.8883 - val_accuracy: 0.7170 - val_loss: 0.8854\n",
      "Epoch 172/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7092 - loss: 0.8595 - val_accuracy: 0.7075 - val_loss: 0.8824\n",
      "Epoch 173/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6600 - loss: 0.9267 - val_accuracy: 0.7075 - val_loss: 0.8815\n",
      "Epoch 174/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6982 - loss: 0.8904 - val_accuracy: 0.7170 - val_loss: 0.8806\n",
      "Epoch 175/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6904 - loss: 0.8776 - val_accuracy: 0.7075 - val_loss: 0.8800\n",
      "Epoch 176/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6816 - loss: 0.9128 - val_accuracy: 0.6887 - val_loss: 0.8792\n",
      "Epoch 177/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6744 - loss: 0.9033 - val_accuracy: 0.6981 - val_loss: 0.8771\n",
      "Epoch 178/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7053 - loss: 0.8172 - val_accuracy: 0.6981 - val_loss: 0.8741\n",
      "Epoch 179/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6491 - loss: 0.9293 - val_accuracy: 0.7170 - val_loss: 0.8709\n",
      "Epoch 180/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6700 - loss: 0.8990 - val_accuracy: 0.7075 - val_loss: 0.8694\n",
      "Epoch 181/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7025 - loss: 0.8536 - val_accuracy: 0.7170 - val_loss: 0.8675\n",
      "Epoch 182/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7245 - loss: 0.8009 - val_accuracy: 0.7170 - val_loss: 0.8655\n",
      "Epoch 183/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6546 - loss: 0.9192 - val_accuracy: 0.7075 - val_loss: 0.8621\n",
      "Epoch 184/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6896 - loss: 0.8522 - val_accuracy: 0.7075 - val_loss: 0.8598\n",
      "Epoch 185/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6978 - loss: 0.8444 - val_accuracy: 0.7075 - val_loss: 0.8569\n",
      "Epoch 186/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6825 - loss: 0.8527 - val_accuracy: 0.7264 - val_loss: 0.8508\n",
      "Epoch 187/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7336 - loss: 0.7699 - val_accuracy: 0.7264 - val_loss: 0.8445\n",
      "Epoch 188/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7025 - loss: 0.8375 - val_accuracy: 0.7358 - val_loss: 0.8396\n",
      "Epoch 189/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6902 - loss: 0.8728 - val_accuracy: 0.7264 - val_loss: 0.8345\n",
      "Epoch 190/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6986 - loss: 0.8615 - val_accuracy: 0.7170 - val_loss: 0.8278\n",
      "Epoch 191/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7441 - loss: 0.7862 - val_accuracy: 0.7170 - val_loss: 0.8201\n",
      "Epoch 192/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7095 - loss: 0.8251 - val_accuracy: 0.7170 - val_loss: 0.8140\n",
      "Epoch 193/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7266 - loss: 0.8216 - val_accuracy: 0.7264 - val_loss: 0.8103\n",
      "Epoch 194/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6975 - loss: 0.8479 - val_accuracy: 0.7264 - val_loss: 0.8082\n",
      "Epoch 195/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7190 - loss: 0.8254 - val_accuracy: 0.7358 - val_loss: 0.8077\n",
      "Epoch 196/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7197 - loss: 0.7815 - val_accuracy: 0.7264 - val_loss: 0.8084\n",
      "Epoch 197/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7148 - loss: 0.7830 - val_accuracy: 0.7358 - val_loss: 0.8101\n",
      "Epoch 198/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6977 - loss: 0.8273 - val_accuracy: 0.7358 - val_loss: 0.8132\n",
      "Epoch 199/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7085 - loss: 0.8144 - val_accuracy: 0.7453 - val_loss: 0.8157\n",
      "Epoch 200/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7111 - loss: 0.8208 - val_accuracy: 0.7358 - val_loss: 0.8174\n",
      "Epoch 201/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7211 - loss: 0.8122 - val_accuracy: 0.7358 - val_loss: 0.8169\n",
      "Epoch 202/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7006 - loss: 0.8110 - val_accuracy: 0.7453 - val_loss: 0.8148\n",
      "Epoch 203/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6723 - loss: 0.8355 - val_accuracy: 0.7358 - val_loss: 0.8120\n",
      "Epoch 204/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7030 - loss: 0.8202 - val_accuracy: 0.7453 - val_loss: 0.8110\n",
      "Epoch 205/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7475 - loss: 0.7621 - val_accuracy: 0.7358 - val_loss: 0.8128\n",
      "Epoch 206/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6870 - loss: 0.8273 - val_accuracy: 0.7358 - val_loss: 0.8151\n",
      "Epoch 207/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7232 - loss: 0.7779 - val_accuracy: 0.7358 - val_loss: 0.8171\n",
      "Epoch 208/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7329 - loss: 0.7518 - val_accuracy: 0.7358 - val_loss: 0.8188\n",
      "Epoch 209/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7256 - loss: 0.7974 - val_accuracy: 0.7358 - val_loss: 0.8194\n",
      "Epoch 210/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7569 - loss: 0.7410 - val_accuracy: 0.7358 - val_loss: 0.8198\n",
      "Epoch 211/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7081 - loss: 0.8032 - val_accuracy: 0.7453 - val_loss: 0.8188\n",
      "Epoch 212/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7218 - loss: 0.7798 - val_accuracy: 0.7358 - val_loss: 0.8174\n",
      "Epoch 213/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7381 - loss: 0.7523 - val_accuracy: 0.7453 - val_loss: 0.8151\n",
      "Epoch 214/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7621 - loss: 0.7294 - val_accuracy: 0.7453 - val_loss: 0.8141\n",
      "Epoch 214: early stopping\n",
      "Restoring model weights from the end of the best epoch: 194.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5830 - loss: 0.9354 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5830 - loss: 0.9354 \n",
      "Loss : 0.9224976897239685, Accuracy : 0.5932203531265259\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"ser_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=256,\n",
    "                       epochs=1000,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {model.evaluate(X_test,y_test)[0]}, Accuracy : {model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.panel.rocket import Rocket\n",
    "Xn = train_data[\"features\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming your DataFrame is named 'df' and the column containing NumPy arrays is 'array_column'\n",
    "def convert_to_rows(array):\n",
    "    \"\"\"Converts a NumPy array to a Pandas Series.\"\"\"\n",
    "    return pd.Series(array)\n",
    "\n",
    "X = (train_data['features'].apply(convert_to_rows)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=22)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588, 312)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.03913940e-01,  1.16918945e-01,  4.98591036e-01,  6.91306839e+01,\n",
       "        1.25000000e-02,  4.91027145e-03,  3.18350586e-02,  1.93383539e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  1.10000000e-01,\n",
       "        3.31350169e-02,  1.41323665e-01,  2.91760249e-02, -2.88435181e+02,\n",
       "        5.50728378e+01, -4.01296387e+01,  1.95592842e+01, -8.34246254e+00,\n",
       "       -1.37986317e+01, -2.29263191e+01,  8.45240593e-01, -1.28851871e+01,\n",
       "       -2.78754950e+00, -1.07358627e+01, -9.34252262e-01, -8.63516998e+00,\n",
       "        2.62261248e+00, -1.72914658e+01, -1.19062510e+01, -2.32286954e+00,\n",
       "       -8.86913967e+00,  6.83052778e-01,  9.12650299e+00,  8.85004330e+00,\n",
       "        1.62932949e+01,  1.13906841e+01,  5.32557487e+00, -4.46631342e-01,\n",
       "        4.71856403e+00,  2.21630859e+00,  1.03134451e+01,  3.46971959e-01,\n",
       "       -4.57345307e-01, -3.10386157e+00,  3.33023000e+00, -3.00312817e-01,\n",
       "       -2.89699078e-01, -3.21450281e+00, -2.06911898e+00, -2.18551540e+00,\n",
       "        1.14130723e+00, -2.00545359e+00, -3.13496590e-01,  1.10832226e+00,\n",
       "        3.39565921e+00,  9.28300560e-01,  1.00052774e+00, -3.14110070e-01,\n",
       "        2.60366058e+00, -8.87646377e-01, -1.51433980e+00, -7.49387264e-01,\n",
       "        2.70266604e+00,  1.60680084e+02,  3.48526382e+01,  3.29249344e+01,\n",
       "        1.72689877e+01,  1.39117174e+01,  1.36071405e+01,  1.42336264e+01,\n",
       "        9.62306023e+00,  1.29906082e+01,  7.94324875e+00,  9.90756321e+00,\n",
       "        8.28493309e+00,  8.10078526e+00,  8.31924915e+00,  9.83293915e+00,\n",
       "        8.08720875e+00,  6.94255495e+00,  1.02651300e+01,  1.32324324e+01,\n",
       "        1.77622013e+01,  2.31403484e+01,  2.15791035e+01,  2.07186909e+01,\n",
       "        1.64140549e+01,  1.37335386e+01,  1.35843191e+01,  1.05363617e+01,\n",
       "        1.02290039e+01,  1.26427574e+01,  1.08115025e+01,  1.09351940e+01,\n",
       "        8.45606518e+00,  7.68664122e+00,  9.91499424e+00,  6.80511904e+00,\n",
       "        8.43671894e+00,  5.16490269e+00,  6.04529428e+00,  6.80793858e+00,\n",
       "        1.03497314e+01,  8.45401573e+00,  9.64417171e+00,  9.70510292e+00,\n",
       "        5.19490910e+00,  4.91799927e+00,  7.03726149e+00,  6.01651859e+00,\n",
       "        6.51398945e+00,  6.23337126e+00,  6.22393322e+00, -5.44272804e+01,\n",
       "        1.34378204e+02,  2.63559608e+01,  5.31587906e+01,  1.86446609e+01,\n",
       "        1.28267536e+01,  1.26519465e+00,  2.61750145e+01,  2.08424854e+01,\n",
       "        1.27549610e+01,  9.29808807e+00,  1.55908175e+01,  9.72610283e+00,\n",
       "        1.75576496e+01,  6.09524667e-01,  1.43840337e+00,  1.69253082e+01,\n",
       "        1.98237858e+01,  4.21723366e+01,  5.14402008e+01,  5.61456718e+01,\n",
       "        6.16259079e+01,  5.59925842e+01,  3.41081314e+01,  2.99961796e+01,\n",
       "        4.57962799e+01,  2.68791809e+01,  4.50047073e+01,  4.43120461e+01,\n",
       "        3.50182877e+01,  2.64940529e+01,  2.76254673e+01,  1.62212639e+01,\n",
       "        2.12140617e+01,  1.82981300e+01,  1.17608490e+01,  8.48513508e+00,\n",
       "        1.51604452e+01,  1.28926134e+01,  3.69803543e+01,  2.87326050e+01,\n",
       "        3.06169910e+01,  2.27951164e+01,  1.38758545e+01,  1.17551556e+01,\n",
       "        2.59968224e+01,  1.57751665e+01,  2.24002018e+01,  2.02643642e+01,\n",
       "        1.79243469e+01,  4.98143852e-01,  5.02133846e-01,  4.85139519e-01,\n",
       "        6.38595462e-01,  5.71473479e-01,  4.67894793e-01,  3.79897654e-01,\n",
       "        4.07858372e-01,  4.47479576e-01,  3.98258448e-01,  4.29743946e-01,\n",
       "        4.95639861e-01,  7.57400692e-02,  3.30325738e-02,  7.85214361e-03,\n",
       "        8.75852443e-03,  1.07888114e-02,  1.50663108e-02,  1.83245447e-02,\n",
       "        3.24636400e-01,  4.23277330e+00,  9.74141502e+00,  6.62728024e+00,\n",
       "        6.50348663e+00,  6.31391764e+00,  3.40050626e+00,  1.06590497e+00,\n",
       "        2.65951782e-01,  8.65520462e-02,  2.11428449e-01,  5.04553199e-01,\n",
       "        1.17218041e+00,  1.19060874e+00,  7.54670143e-01,  1.40997338e+00,\n",
       "        1.18863802e+01,  1.37736940e+01,  3.26773071e+00,  5.01166391e+00,\n",
       "        2.66356087e+00,  1.52573228e+00,  1.00694036e+00,  1.05121827e+00,\n",
       "        1.13423884e+00,  3.70008409e-01,  4.82146516e-02,  3.20302807e-02,\n",
       "        1.15666568e-01,  1.94439918e-01,  4.21659172e-01,  8.03121567e-01,\n",
       "        1.87524891e+00,  9.43680286e-01,  5.02278924e-01,  5.70207953e-01,\n",
       "        3.59326839e-01,  3.36728394e-01,  2.56220788e-01,  2.63741434e-01,\n",
       "        3.52352142e-01,  2.10258096e-01,  5.43732755e-02,  1.88808799e-01,\n",
       "        1.49393395e-01,  7.48099387e-02,  6.20570555e-02,  6.43828064e-02,\n",
       "        2.44026333e-01,  8.10612082e-01,  1.45526218e+00,  9.27237153e-01,\n",
       "        5.27841389e-01,  5.97147644e-01,  1.03357446e+00,  1.39569545e+00,\n",
       "        1.33311331e+00,  1.71274638e+00,  1.08515036e+00,  1.55873501e+00,\n",
       "        2.54942203e+00,  4.35852146e+00,  1.09135115e+00,  3.05342734e-01,\n",
       "        2.60499179e-01,  7.08897889e-01,  1.00252211e+00,  1.19157779e+00,\n",
       "        2.49598786e-01,  2.98021495e-01,  5.09518445e-01,  3.26295078e-01,\n",
       "        2.34920740e-01,  2.40991384e-01,  4.60388660e-01,  2.84434885e-01,\n",
       "        1.48536414e-01,  8.50593224e-02,  4.82253991e-02,  1.20611638e-02,\n",
       "        1.33153815e-02,  2.01814827e-02,  1.14661064e-02,  1.03277955e-02,\n",
       "        1.62117742e-02,  2.23827511e-02,  2.10431125e-02,  2.76315995e-02,\n",
       "        3.80571038e-02,  4.97721955e-02,  5.06108031e-02,  3.69902775e-02,\n",
       "        1.73625387e-02,  2.23700814e-02,  1.24842059e-02,  6.73372531e-03,\n",
       "        5.79996733e-03,  4.93001565e-03,  5.91254327e-03,  3.47586791e-03,\n",
       "        3.45689058e-03,  3.78994574e-03,  7.03109894e-03,  1.14623532e-02,\n",
       "        1.91804599e-02,  1.60668455e-02,  1.37975235e-02,  9.77584627e-03,\n",
       "        4.89621656e-03,  2.76169367e-03,  1.40506960e-03,  1.00408797e-03,\n",
       "        1.37667055e-03,  1.14288204e-03,  1.18390250e-03,  1.41001679e-03,\n",
       "        2.27638776e-03,  7.68848695e-04,  9.18900769e-04,  6.08060393e-04,\n",
       "        1.01344915e-04,  1.25719304e+01,  2.08337217e+01,  2.19385769e+01,\n",
       "        1.95014464e+01,  1.89543045e+01,  1.97197179e+01,  4.91538803e+01])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1024)\n"
     ]
    }
   ],
   "source": [
    "trf = Rocket(num_kernels=512) \n",
    "trf.fit(X_train) \n",
    "X_train = trf.transform(X_train) \n",
    "X_test = trf.transform(X_test) \n",
    "X_val = trf.transform(X_val) \n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.464945</td>\n",
       "      <td>20.515377</td>\n",
       "      <td>0.486998</td>\n",
       "      <td>13.475472</td>\n",
       "      <td>0.512545</td>\n",
       "      <td>13.781878</td>\n",
       "      <td>0.498607</td>\n",
       "      <td>12.969245</td>\n",
       "      <td>0.482269</td>\n",
       "      <td>10.576056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51773</td>\n",
       "      <td>16.585114</td>\n",
       "      <td>0.401891</td>\n",
       "      <td>6.140023</td>\n",
       "      <td>0.484634</td>\n",
       "      <td>12.625414</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>31.429398</td>\n",
       "      <td>0.449173</td>\n",
       "      <td>9.29497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0          1         2          3         4          5         6     \\\n",
       "0  0.464945  20.515377  0.486998  13.475472  0.512545  13.781878  0.498607   \n",
       "\n",
       "        7         8          9     ...     1014       1015      1016  \\\n",
       "0  12.969245  0.482269  10.576056  ...  0.51773  16.585114  0.401891   \n",
       "\n",
       "       1017      1018       1019      1020       1021      1022     1023  \n",
       "0  6.140023  0.484634  12.625414  0.555556  31.429398  0.449173  9.29497  \n",
       "\n",
       "[1 rows x 1024 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.Sequential()\n",
    "kernel_sizes = [5, 5]\n",
    "model.add(keras.layers.Input(shape=(X_train.shape[1],1)))\n",
    "for size in kernel_sizes:\n",
    "    model.add(keras.layers.Conv1D(\n",
    "        filters = 32,\n",
    "        kernel_size = size,\n",
    "        padding = 'same'\n",
    "    ))  # 卷积层\n",
    "    model.add(keras.layers.BatchNormalization(axis=-1))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32))\n",
    "model.add(keras.layers.BatchNormalization(axis = -1))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))  # 分类层\n",
    "optimzer = keras.optimizers.Adam(learning_rate= 0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimzer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 1\n'y' sizes: 423\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 17\u001b[0m\n\u001b[0;32m      2\u001b[0m name \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mser_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM_\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[0;32m      4\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(  \n\u001b[0;32m      6\u001b[0m         monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     )\n\u001b[0;32m     13\u001b[0m ]\n\u001b[1;32m---> 17\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mevaluate(X_test,y_test)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Accuracy : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mevaluate(X_test,y_test)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\anton\\Documents\\PhD\\Speech_Emotion_Recognition\\EMOVO_dataset\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\anton\\Documents\\PhD\\Speech_Emotion_Recognition\\EMOVO_dataset\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\data_adapter_utils.py:114\u001b[0m, in \u001b[0;36mcheck_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    110\u001b[0m     sizes \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[0;32m    112\u001b[0m     )\n\u001b[0;32m    113\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 1\n'y' sizes: 423\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"ser_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       epochs=1000,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {model.evaluate(X_test,y_test)[0]}, Accuracy : {model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423, 312)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "def get_model():\n",
    "    inputs = layers.Input(shape=(X_train.shape[1],1))\n",
    "    encoder = layers.LSTM(128)(inputs)\n",
    "    drop = layers.Dropout(0.3)(encoder)\n",
    "    hidden = layers.Dense(32, activation='relu')(drop)\n",
    "    outputs = layers.Dense(7, activation='softmax')(hidden)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">312</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_18 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m312\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m66,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_18 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m231\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,919</span> (277.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70,919\u001b[0m (277.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,919</span> (277.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,919\u001b[0m (277.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "LSTM_model = get_model()\n",
    "LSTM_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.1282 - loss: 2.0847 - val_accuracy: 0.1132 - val_loss: 1.9534\n",
      "Epoch 2/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.1376 - loss: 1.9695 - val_accuracy: 0.1509 - val_loss: 1.9527\n",
      "Epoch 3/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 104ms/step - accuracy: 0.1371 - loss: 1.9475 - val_accuracy: 0.1792 - val_loss: 1.9482\n",
      "Epoch 4/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.1251 - loss: 1.9580 - val_accuracy: 0.2170 - val_loss: 1.9407\n",
      "Epoch 5/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.1578 - loss: 1.9562 - val_accuracy: 0.1792 - val_loss: 1.9336\n",
      "Epoch 6/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.1665 - loss: 1.9395 - val_accuracy: 0.1698 - val_loss: 1.9355\n",
      "Epoch 7/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.1362 - loss: 1.9406 - val_accuracy: 0.2358 - val_loss: 1.9280\n",
      "Epoch 8/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.1418 - loss: 1.9410 - val_accuracy: 0.1604 - val_loss: 1.9386\n",
      "Epoch 9/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 112ms/step - accuracy: 0.2222 - loss: 1.9273 - val_accuracy: 0.2264 - val_loss: 1.9238\n",
      "Epoch 10/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.1503 - loss: 1.9322 - val_accuracy: 0.3019 - val_loss: 1.9207\n",
      "Epoch 11/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.2037 - loss: 1.9226 - val_accuracy: 0.1698 - val_loss: 1.9339\n",
      "Epoch 12/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 110ms/step - accuracy: 0.1509 - loss: 1.9455 - val_accuracy: 0.2547 - val_loss: 1.9208\n",
      "Epoch 13/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.1922 - loss: 1.9258 - val_accuracy: 0.1226 - val_loss: 1.9464\n",
      "Epoch 14/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.1566 - loss: 1.9411 - val_accuracy: 0.2264 - val_loss: 1.9180\n",
      "Epoch 15/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.1964 - loss: 1.9102 - val_accuracy: 0.1321 - val_loss: 1.9171\n",
      "Epoch 16/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.2311 - loss: 1.9108 - val_accuracy: 0.2547 - val_loss: 1.8761\n",
      "Epoch 17/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.2126 - loss: 1.8963 - val_accuracy: 0.2547 - val_loss: 1.8486\n",
      "Epoch 18/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.2117 - loss: 1.8906 - val_accuracy: 0.2547 - val_loss: 1.8448\n",
      "Epoch 19/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.2085 - loss: 1.8954 - val_accuracy: 0.2264 - val_loss: 1.8735\n",
      "Epoch 20/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.1955 - loss: 1.9164 - val_accuracy: 0.2358 - val_loss: 1.8681\n",
      "Epoch 21/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.2236 - loss: 1.9087 - val_accuracy: 0.2642 - val_loss: 1.8740\n",
      "Epoch 22/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.2023 - loss: 1.8935 - val_accuracy: 0.2642 - val_loss: 1.8182\n",
      "Epoch 23/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.2334 - loss: 1.8454 - val_accuracy: 0.2547 - val_loss: 1.7940\n",
      "Epoch 24/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.2064 - loss: 1.8756 - val_accuracy: 0.2830 - val_loss: 1.8001\n",
      "Epoch 25/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.2107 - loss: 1.8411 - val_accuracy: 0.2642 - val_loss: 1.8513\n",
      "Epoch 26/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.2151 - loss: 1.8631 - val_accuracy: 0.2830 - val_loss: 1.7859\n",
      "Epoch 27/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.2492 - loss: 1.8268 - val_accuracy: 0.3019 - val_loss: 1.7711\n",
      "Epoch 28/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.2318 - loss: 1.8135 - val_accuracy: 0.2642 - val_loss: 1.8111\n",
      "Epoch 29/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.2174 - loss: 1.8737 - val_accuracy: 0.2925 - val_loss: 1.7890\n",
      "Epoch 30/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.2223 - loss: 1.8468 - val_accuracy: 0.2830 - val_loss: 1.8081\n",
      "Epoch 31/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.2420 - loss: 1.8324 - val_accuracy: 0.2925 - val_loss: 1.7633\n",
      "Epoch 32/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.2283 - loss: 1.8565 - val_accuracy: 0.2642 - val_loss: 1.7913\n",
      "Epoch 33/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.2114 - loss: 1.8612 - val_accuracy: 0.3208 - val_loss: 1.7911\n",
      "Epoch 34/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 106ms/step - accuracy: 0.2137 - loss: 1.8647 - val_accuracy: 0.2264 - val_loss: 1.8555\n",
      "Epoch 35/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.2311 - loss: 1.8568 - val_accuracy: 0.2925 - val_loss: 1.7720\n",
      "Epoch 36/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.2399 - loss: 1.8092 - val_accuracy: 0.2925 - val_loss: 1.7651\n",
      "Epoch 37/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.2284 - loss: 1.8211 - val_accuracy: 0.2642 - val_loss: 1.7810\n",
      "Epoch 38/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.2246 - loss: 1.8285 - val_accuracy: 0.3302 - val_loss: 1.7668\n",
      "Epoch 39/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.2424 - loss: 1.8129 - val_accuracy: 0.2642 - val_loss: 1.7786\n",
      "Epoch 40/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.2327 - loss: 1.8603 - val_accuracy: 0.3208 - val_loss: 1.7535\n",
      "Epoch 41/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.2367 - loss: 1.8295 - val_accuracy: 0.3113 - val_loss: 1.7463\n",
      "Epoch 42/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 101ms/step - accuracy: 0.2000 - loss: 1.8044 - val_accuracy: 0.3113 - val_loss: 1.7502\n",
      "Epoch 43/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.2467 - loss: 1.8435 - val_accuracy: 0.2453 - val_loss: 1.8053\n",
      "Epoch 44/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.2195 - loss: 1.8397 - val_accuracy: 0.1604 - val_loss: 1.8532\n",
      "Epoch 45/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.2475 - loss: 1.8183 - val_accuracy: 0.3302 - val_loss: 1.7549\n",
      "Epoch 46/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.2267 - loss: 1.8290 - val_accuracy: 0.3208 - val_loss: 1.7455\n",
      "Epoch 47/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.2463 - loss: 1.8044 - val_accuracy: 0.2925 - val_loss: 1.7772\n",
      "Epoch 48/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.2259 - loss: 1.8190 - val_accuracy: 0.3302 - val_loss: 1.7635\n",
      "Epoch 49/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.2742 - loss: 1.7534 - val_accuracy: 0.3396 - val_loss: 1.7602\n",
      "Epoch 50/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.2099 - loss: 1.8318 - val_accuracy: 0.3491 - val_loss: 1.7579\n",
      "Epoch 51/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.2298 - loss: 1.8341 - val_accuracy: 0.3113 - val_loss: 1.7359\n",
      "Epoch 52/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.2470 - loss: 1.8250 - val_accuracy: 0.3208 - val_loss: 1.7537\n",
      "Epoch 53/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.2169 - loss: 1.8048 - val_accuracy: 0.3491 - val_loss: 1.7428\n",
      "Epoch 54/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.2587 - loss: 1.7881 - val_accuracy: 0.3302 - val_loss: 1.7415\n",
      "Epoch 55/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.2655 - loss: 1.7624 - val_accuracy: 0.3491 - val_loss: 1.7235\n",
      "Epoch 56/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.2309 - loss: 1.8425 - val_accuracy: 0.3396 - val_loss: 1.6844\n",
      "Epoch 57/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.2736 - loss: 1.7776 - val_accuracy: 0.2830 - val_loss: 1.7641\n",
      "Epoch 58/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 102ms/step - accuracy: 0.2578 - loss: 1.7631 - val_accuracy: 0.3491 - val_loss: 1.6815\n",
      "Epoch 59/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.2896 - loss: 1.7534 - val_accuracy: 0.3396 - val_loss: 1.6900\n",
      "Epoch 60/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.2613 - loss: 1.7372 - val_accuracy: 0.3396 - val_loss: 1.7365\n",
      "Epoch 61/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.2319 - loss: 1.7831 - val_accuracy: 0.1981 - val_loss: 1.8846\n",
      "Epoch 62/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.2377 - loss: 1.8699 - val_accuracy: 0.2358 - val_loss: 1.8325\n",
      "Epoch 63/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.2451 - loss: 1.8172 - val_accuracy: 0.3491 - val_loss: 1.7114\n",
      "Epoch 64/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.2290 - loss: 1.8132 - val_accuracy: 0.3302 - val_loss: 1.6919\n",
      "Epoch 65/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.2706 - loss: 1.7803 - val_accuracy: 0.3396 - val_loss: 1.6832\n",
      "Epoch 66/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.2520 - loss: 1.7451 - val_accuracy: 0.3302 - val_loss: 1.6905\n",
      "Epoch 67/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.2821 - loss: 1.7683 - val_accuracy: 0.3774 - val_loss: 1.6652\n",
      "Epoch 68/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.2687 - loss: 1.7570 - val_accuracy: 0.3491 - val_loss: 1.6746\n",
      "Epoch 69/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.2426 - loss: 1.8096 - val_accuracy: 0.3302 - val_loss: 1.6731\n",
      "Epoch 70/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.3007 - loss: 1.7380 - val_accuracy: 0.3396 - val_loss: 1.6545\n",
      "Epoch 71/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.2935 - loss: 1.7093 - val_accuracy: 0.3491 - val_loss: 1.6572\n",
      "Epoch 72/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.2592 - loss: 1.7424 - val_accuracy: 0.3208 - val_loss: 1.7471\n",
      "Epoch 73/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.2614 - loss: 1.7745 - val_accuracy: 0.3679 - val_loss: 1.7267\n",
      "Epoch 74/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.2756 - loss: 1.7426 - val_accuracy: 0.3396 - val_loss: 1.6569\n",
      "Epoch 75/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.2596 - loss: 1.7528 - val_accuracy: 0.3679 - val_loss: 1.6553\n",
      "Epoch 76/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.3112 - loss: 1.6740 - val_accuracy: 0.3774 - val_loss: 1.6482\n",
      "Epoch 77/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.3397 - loss: 1.6863 - val_accuracy: 0.3679 - val_loss: 1.6376\n",
      "Epoch 78/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.3033 - loss: 1.7285 - val_accuracy: 0.3396 - val_loss: 1.6792\n",
      "Epoch 79/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.3017 - loss: 1.7338 - val_accuracy: 0.3491 - val_loss: 1.6616\n",
      "Epoch 80/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.2895 - loss: 1.7350 - val_accuracy: 0.2453 - val_loss: 1.8124\n",
      "Epoch 81/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.2618 - loss: 1.7884 - val_accuracy: 0.3491 - val_loss: 1.7143\n",
      "Epoch 82/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.3086 - loss: 1.7103 - val_accuracy: 0.3396 - val_loss: 1.6599\n",
      "Epoch 83/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.2900 - loss: 1.7079 - val_accuracy: 0.3679 - val_loss: 1.6560\n",
      "Epoch 84/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.3389 - loss: 1.7086 - val_accuracy: 0.3396 - val_loss: 1.6886\n",
      "Epoch 85/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.2923 - loss: 1.7683 - val_accuracy: 0.3208 - val_loss: 1.6943\n",
      "Epoch 86/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.2514 - loss: 1.8023 - val_accuracy: 0.3679 - val_loss: 1.6482\n",
      "Epoch 87/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.2959 - loss: 1.7143 - val_accuracy: 0.3774 - val_loss: 1.6616\n",
      "Epoch 88/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.3150 - loss: 1.7059 - val_accuracy: 0.3868 - val_loss: 1.6379\n",
      "Epoch 89/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.2884 - loss: 1.7462 - val_accuracy: 0.3302 - val_loss: 1.7073\n",
      "Epoch 90/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.2557 - loss: 1.7369 - val_accuracy: 0.3491 - val_loss: 1.6320\n",
      "Epoch 91/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.2721 - loss: 1.7109 - val_accuracy: 0.3962 - val_loss: 1.6304\n",
      "Epoch 92/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.3182 - loss: 1.6893 - val_accuracy: 0.3774 - val_loss: 1.6170\n",
      "Epoch 93/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.2945 - loss: 1.7184 - val_accuracy: 0.3396 - val_loss: 1.6463\n",
      "Epoch 94/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.2921 - loss: 1.7334 - val_accuracy: 0.3679 - val_loss: 1.6442\n",
      "Epoch 95/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.2688 - loss: 1.7609 - val_accuracy: 0.3396 - val_loss: 1.6427\n",
      "Epoch 96/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.3024 - loss: 1.6594 - val_accuracy: 0.3868 - val_loss: 1.6142\n",
      "Epoch 97/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.2740 - loss: 1.7166 - val_accuracy: 0.3491 - val_loss: 1.6277\n",
      "Epoch 98/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.2605 - loss: 1.7131 - val_accuracy: 0.3396 - val_loss: 1.6269\n",
      "Epoch 99/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.2951 - loss: 1.6920 - val_accuracy: 0.3774 - val_loss: 1.6198\n",
      "Epoch 100/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.3451 - loss: 1.6996 - val_accuracy: 0.3585 - val_loss: 1.6238\n",
      "Epoch 101/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.3063 - loss: 1.6891 - val_accuracy: 0.3679 - val_loss: 1.6309\n",
      "Epoch 102/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.3301 - loss: 1.6883 - val_accuracy: 0.3679 - val_loss: 1.6174\n",
      "Epoch 103/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.2822 - loss: 1.7402 - val_accuracy: 0.3679 - val_loss: 1.6122\n",
      "Epoch 104/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.2992 - loss: 1.6950 - val_accuracy: 0.3396 - val_loss: 1.6383\n",
      "Epoch 105/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.2745 - loss: 1.7273 - val_accuracy: 0.3396 - val_loss: 1.6224\n",
      "Epoch 106/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.3015 - loss: 1.7218 - val_accuracy: 0.3396 - val_loss: 1.6365\n",
      "Epoch 107/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.2650 - loss: 1.6916 - val_accuracy: 0.3113 - val_loss: 1.6310\n",
      "Epoch 108/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.2802 - loss: 1.7373 - val_accuracy: 0.3396 - val_loss: 1.6088\n",
      "Epoch 109/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.3014 - loss: 1.7180 - val_accuracy: 0.3679 - val_loss: 1.6114\n",
      "Epoch 110/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.3268 - loss: 1.6480 - val_accuracy: 0.3396 - val_loss: 1.6102\n",
      "Epoch 111/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.2924 - loss: 1.6724 - val_accuracy: 0.3208 - val_loss: 1.6650\n",
      "Epoch 112/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.3096 - loss: 1.7146 - val_accuracy: 0.3302 - val_loss: 1.6390\n",
      "Epoch 113/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.2731 - loss: 1.7018 - val_accuracy: 0.3491 - val_loss: 1.6347\n",
      "Epoch 114/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.2697 - loss: 1.7098 - val_accuracy: 0.3679 - val_loss: 1.6093\n",
      "Epoch 115/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.2861 - loss: 1.6981 - val_accuracy: 0.3774 - val_loss: 1.5879\n",
      "Epoch 116/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.3464 - loss: 1.6338 - val_accuracy: 0.3396 - val_loss: 1.5977\n",
      "Epoch 117/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.2780 - loss: 1.6884 - val_accuracy: 0.3679 - val_loss: 1.6264\n",
      "Epoch 118/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.3049 - loss: 1.7030 - val_accuracy: 0.3774 - val_loss: 1.5837\n",
      "Epoch 119/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.2715 - loss: 1.7257 - val_accuracy: 0.3208 - val_loss: 1.6244\n",
      "Epoch 120/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.3067 - loss: 1.7035 - val_accuracy: 0.3396 - val_loss: 1.6501\n",
      "Epoch 121/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.2526 - loss: 1.7061 - val_accuracy: 0.3491 - val_loss: 1.6144\n",
      "Epoch 122/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.2979 - loss: 1.7071 - val_accuracy: 0.3396 - val_loss: 1.5948\n",
      "Epoch 123/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.2779 - loss: 1.7395 - val_accuracy: 0.4057 - val_loss: 1.5843\n",
      "Epoch 124/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.3098 - loss: 1.6565 - val_accuracy: 0.3774 - val_loss: 1.6195\n",
      "Epoch 125/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.2708 - loss: 1.6733 - val_accuracy: 0.3962 - val_loss: 1.6092\n",
      "Epoch 126/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.2977 - loss: 1.7269 - val_accuracy: 0.2830 - val_loss: 1.6914\n",
      "Epoch 127/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.2372 - loss: 1.7703 - val_accuracy: 0.3208 - val_loss: 1.6189\n",
      "Epoch 128/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.2780 - loss: 1.7237 - val_accuracy: 0.3113 - val_loss: 1.6258\n",
      "Epoch 129/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.3072 - loss: 1.6796 - val_accuracy: 0.3585 - val_loss: 1.5687\n",
      "Epoch 130/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.3172 - loss: 1.6676 - val_accuracy: 0.3396 - val_loss: 1.5714\n",
      "Epoch 131/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.2757 - loss: 1.6737 - val_accuracy: 0.3774 - val_loss: 1.5694\n",
      "Epoch 132/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.2797 - loss: 1.7488 - val_accuracy: 0.3396 - val_loss: 1.5845\n",
      "Epoch 133/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.3226 - loss: 1.6439 - val_accuracy: 0.3396 - val_loss: 1.5742\n",
      "Epoch 134/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.3006 - loss: 1.6424 - val_accuracy: 0.3679 - val_loss: 1.5623\n",
      "Epoch 135/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.2949 - loss: 1.6494 - val_accuracy: 0.3208 - val_loss: 1.5670\n",
      "Epoch 136/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.3478 - loss: 1.6511 - val_accuracy: 0.3774 - val_loss: 1.5937\n",
      "Epoch 137/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.2881 - loss: 1.6511 - val_accuracy: 0.3679 - val_loss: 1.5228\n",
      "Epoch 138/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.3085 - loss: 1.6284 - val_accuracy: 0.3491 - val_loss: 1.5754\n",
      "Epoch 139/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.3426 - loss: 1.6174 - val_accuracy: 0.3962 - val_loss: 1.5387\n",
      "Epoch 140/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.2927 - loss: 1.6711 - val_accuracy: 0.3774 - val_loss: 1.5213\n",
      "Epoch 141/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.3299 - loss: 1.5930 - val_accuracy: 0.3491 - val_loss: 1.5181\n",
      "Epoch 142/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.3187 - loss: 1.6014 - val_accuracy: 0.3208 - val_loss: 1.5802\n",
      "Epoch 143/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.3055 - loss: 1.6511 - val_accuracy: 0.3019 - val_loss: 1.6941\n",
      "Epoch 144/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.2678 - loss: 1.7117 - val_accuracy: 0.3491 - val_loss: 1.6152\n",
      "Epoch 145/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.2954 - loss: 1.6729 - val_accuracy: 0.3302 - val_loss: 1.6271\n",
      "Epoch 146/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.3412 - loss: 1.6397 - val_accuracy: 0.2925 - val_loss: 1.6418\n",
      "Epoch 147/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.3089 - loss: 1.6389 - val_accuracy: 0.3585 - val_loss: 1.5449\n",
      "Epoch 148/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.3466 - loss: 1.6103 - val_accuracy: 0.3302 - val_loss: 1.5450\n",
      "Epoch 149/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.3021 - loss: 1.6939 - val_accuracy: 0.3491 - val_loss: 1.5536\n",
      "Epoch 150/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.2917 - loss: 1.6522 - val_accuracy: 0.3491 - val_loss: 1.5636\n",
      "Epoch 151/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.2988 - loss: 1.6307 - val_accuracy: 0.3868 - val_loss: 1.4959\n",
      "Epoch 152/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.2921 - loss: 1.6182 - val_accuracy: 0.3491 - val_loss: 1.5422\n",
      "Epoch 153/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.2759 - loss: 1.7116 - val_accuracy: 0.3491 - val_loss: 1.6012\n",
      "Epoch 154/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.2965 - loss: 1.6652 - val_accuracy: 0.3585 - val_loss: 1.5114\n",
      "Epoch 155/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.3074 - loss: 1.6302 - val_accuracy: 0.3679 - val_loss: 1.4976\n",
      "Epoch 156/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.3355 - loss: 1.5756 - val_accuracy: 0.3679 - val_loss: 1.4700\n",
      "Epoch 157/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.3292 - loss: 1.6038 - val_accuracy: 0.3868 - val_loss: 1.4852\n",
      "Epoch 158/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.3452 - loss: 1.5735 - val_accuracy: 0.3962 - val_loss: 1.5174\n",
      "Epoch 159/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.3888 - loss: 1.6001 - val_accuracy: 0.4245 - val_loss: 1.4855\n",
      "Epoch 160/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.3236 - loss: 1.5934 - val_accuracy: 0.4057 - val_loss: 1.4281\n",
      "Epoch 161/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 107ms/step - accuracy: 0.3482 - loss: 1.6047 - val_accuracy: 0.4057 - val_loss: 1.5148\n",
      "Epoch 162/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 97ms/step - accuracy: 0.3580 - loss: 1.5129 - val_accuracy: 0.3868 - val_loss: 1.5414\n",
      "Epoch 163/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - accuracy: 0.2981 - loss: 1.6496 - val_accuracy: 0.3868 - val_loss: 1.5955\n",
      "Epoch 164/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 96ms/step - accuracy: 0.3139 - loss: 1.6207 - val_accuracy: 0.3962 - val_loss: 1.5060\n",
      "Epoch 165/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.2837 - loss: 1.7158 - val_accuracy: 0.3113 - val_loss: 1.6878\n",
      "Epoch 166/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.2999 - loss: 1.6584 - val_accuracy: 0.3585 - val_loss: 1.5314\n",
      "Epoch 167/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.3318 - loss: 1.6356 - val_accuracy: 0.3019 - val_loss: 1.5218\n",
      "Epoch 168/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.3290 - loss: 1.6356 - val_accuracy: 0.3774 - val_loss: 1.5188\n",
      "Epoch 169/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.2929 - loss: 1.6196 - val_accuracy: 0.3679 - val_loss: 1.5108\n",
      "Epoch 170/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.3155 - loss: 1.5868 - val_accuracy: 0.4057 - val_loss: 1.4938\n",
      "Epoch 171/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.3123 - loss: 1.5968 - val_accuracy: 0.3302 - val_loss: 1.4956\n",
      "Epoch 172/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.3335 - loss: 1.6269 - val_accuracy: 0.3396 - val_loss: 1.5374\n",
      "Epoch 173/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.2992 - loss: 1.5992 - val_accuracy: 0.3396 - val_loss: 1.5363\n",
      "Epoch 174/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.3694 - loss: 1.5764 - val_accuracy: 0.3491 - val_loss: 1.5395\n",
      "Epoch 175/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.3023 - loss: 1.6068 - val_accuracy: 0.4151 - val_loss: 1.5222\n",
      "Epoch 176/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.3314 - loss: 1.6128 - val_accuracy: 0.3868 - val_loss: 1.5364\n",
      "Epoch 177/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.3202 - loss: 1.5615 - val_accuracy: 0.3585 - val_loss: 1.5215\n",
      "Epoch 178/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.3332 - loss: 1.5535 - val_accuracy: 0.4057 - val_loss: 1.5102\n",
      "Epoch 179/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.3733 - loss: 1.5418 - val_accuracy: 0.4245 - val_loss: 1.4395\n",
      "Epoch 180/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.3545 - loss: 1.5486 - val_accuracy: 0.3868 - val_loss: 1.4984\n",
      "Epoch 180: early stopping\n",
      "Restoring model weights from the end of the best epoch: 160.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2641 - loss: 1.5708\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2641 - loss: 1.5708\n",
      "Loss : 1.5665912628173828, Accuracy : 0.2711864411830902\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"ser_lstm_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "LSTM_history = LSTM_model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=32,\n",
    "                       epochs=1000,\n",
    "                       verbose=1,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {LSTM_model.evaluate(X_test,y_test)[0]}, Accuracy : {LSTM_model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
