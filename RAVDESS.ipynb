{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy, scipy as sklearn, librosa, urllib\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import json \n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score\n",
    "import keras\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_curve, auc, silhouette_score,roc_auc_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"RAVDESS/data.csv\", 'r+') as f:\n",
    "    f.truncate(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setLabel(name):\n",
    "    subname= name[:3]\n",
    "    if subname==\"dis\":\n",
    "        return \"disgust\";\n",
    "    elif subname==\"sor\":\n",
    "        return \"surprise\";\n",
    "    elif subname==\"pau\":\n",
    "        return \"fear\";\n",
    "    elif subname==\"rab\":\n",
    "        return \"anger\";\n",
    "    elif subname==\"gio\":\n",
    "        return \"joy\";\n",
    "    elif subname==\"tri\":\n",
    "        return \"sadness\";\n",
    "    else:\n",
    "        return \"neutrality\";\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setLabel(i): \n",
    "    emotions = [\"neutral\", \"calm\", \"happy\", \"sad\", \"angry\", \"fearful\", \"disgust\", \"surprised\"] #calm è extra\n",
    "    return emotions[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setLabel(i): \n",
    "    emotions = [\"neutrality\", \"calm\", \"joy\", \"sadness\", \"anger\", \"fear\", \"disgust\", \"surprise\"] #calm è extra\n",
    "    return emotions[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"RAVDESS\"\n",
    "with open('RAVDESS/data.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['file_name', 'label','actor']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for index,dir in enumerate(os.listdir(main_dir)):\n",
    "        actual = os.path.join(main_dir,dir)\n",
    "        if dir == \"data.csv\":\n",
    "            continue\n",
    "        if int(dir.split(\"_\")[-1]) % 2 == 0:\n",
    "            actor = \"f\" + str((index//2) +1)    \n",
    "        else:\n",
    "            actor = \"m\" + str((index//2) +1)\n",
    "        for audio in os.listdir(actual):\n",
    "            emo = int(audio.split(\"-\")[2]) \n",
    "            writer.writerow({'file_name':os.path.join(dir,audio),'label':setLabel(emo-1),'actor':actor})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"RAVDESS/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(data_df[data_df['label'] == \"calm\"].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_min(files):\n",
    "    min_, max_ = 100, 0\n",
    "    for file in files:\n",
    "        sound_file, samplerate = librosa.load(file)\n",
    "        t = sound_file.shape[0] / samplerate\n",
    "        if t < min_:\n",
    "            min_ = t\n",
    "        if t > max_:\n",
    "            max_ = t\n",
    "\n",
    "    return max_, min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_new(file,pad):\n",
    "    X, sample_rate = librosa.load(file)\n",
    "    max_ = X.shape[0] / sample_rate\n",
    "    if pad:\n",
    "        length = (max_ * sample_rate) - X.shape[0]\n",
    "        X = np.pad(X, (0, int(length)), 'constant')\n",
    "    \n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    # result = np.array([])\n",
    "    result = []\n",
    "\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=50).T, axis=0)\n",
    "    # result = np.hstack((result, mfccs))\n",
    "    result.append((mfccs))\n",
    "\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    # result = np.hstack((result, chroma))\n",
    "    result.append(chroma)\n",
    "\n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0) \n",
    "    # result = np.hstack((result, mel))\n",
    "    result.append(mel)\n",
    "    \n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0)\n",
    "    # result = np.hstack((result, contrast))\n",
    "    result.append(contrast)\n",
    "\n",
    "    # tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    # result = np.hstack((result, tonnetz))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "max, min = get_max_min('RAVDESS/'+data_df.file_name)\n",
    "train_data = pd.DataFrame(columns=['filename', 'features', 'label'])\n",
    "\n",
    "features = []\n",
    "for index, file in zip(data_df.index, data_df.file_name):\n",
    "    train_data.loc[index] = [file, extract_new('RAVDESS/'+file, max), data_df.label[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.empty((0, 50))\n",
    "X2 = np.empty((0, 12))\n",
    "X3 = np.empty((0, 128))\n",
    "X4 = np.empty((0, 7))\n",
    "\n",
    "\n",
    "for data in train_data[\"features\"]:\n",
    "    X1 = np.vstack((X1, data[0]))\n",
    "    X2 = np.vstack((X2, data[1]))\n",
    "    X3 = np.vstack((X3, data[2]))\n",
    "    X4 = np.vstack((X4, data[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classes = (list((train_data[\"label\"].unique())))\n",
    "Y = keras.utils.to_categorical(list((train_data[\"label\"].apply(data_classes.index))))\n",
    "# X = np.stack(train_data[\"features\"])\n",
    "X = np.hstack([X1,X2,X3,X4])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=22)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "kernel_sizes = [5, 5]\n",
    "model.add(keras.layers.Input(shape=(X_train.shape[1],1)))\n",
    "for size in kernel_sizes:\n",
    "    model.add(keras.layers.Conv1D(\n",
    "        filters = 32,\n",
    "        kernel_size = size,\n",
    "        padding = 'same'\n",
    "    ))  # 卷积层\n",
    "    model.add(keras.layers.BatchNormalization(axis=-1))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32))\n",
    "model.add(keras.layers.BatchNormalization(axis = -1))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))  # 分类层\n",
    "optimzer = keras.optimizers.Adam(learning_rate= 0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimzer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1491 - loss: 2.5217\n",
      "Epoch 1: val_loss improved from inf to 2.64083, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.1496 - loss: 2.5179 - val_accuracy: 0.1511 - val_loss: 2.6408\n",
      "Epoch 2/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1562 - loss: 2.4253\n",
      "Epoch 2: val_loss improved from 2.64083 to 2.46668, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1557 - loss: 2.4284 - val_accuracy: 0.0800 - val_loss: 2.4667\n",
      "Epoch 3/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1684 - loss: 2.4380\n",
      "Epoch 3: val_loss improved from 2.46668 to 2.40112, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.1665 - loss: 2.4294 - val_accuracy: 0.0756 - val_loss: 2.4011\n",
      "Epoch 4/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1827 - loss: 2.3225\n",
      "Epoch 4: val_loss improved from 2.40112 to 2.33878, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1842 - loss: 2.3158 - val_accuracy: 0.0889 - val_loss: 2.3388\n",
      "Epoch 5/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1899 - loss: 2.2121\n",
      "Epoch 5: val_loss improved from 2.33878 to 2.27829, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.1901 - loss: 2.2137 - val_accuracy: 0.2222 - val_loss: 2.2783\n",
      "Epoch 6/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2007 - loss: 2.1964\n",
      "Epoch 6: val_loss improved from 2.27829 to 2.25476, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2055 - loss: 2.1800 - val_accuracy: 0.2489 - val_loss: 2.2548\n",
      "Epoch 7/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1706 - loss: 2.1518\n",
      "Epoch 7: val_loss improved from 2.25476 to 2.24242, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.1741 - loss: 2.1525 - val_accuracy: 0.2756 - val_loss: 2.2424\n",
      "Epoch 8/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2153 - loss: 2.0622\n",
      "Epoch 8: val_loss improved from 2.24242 to 2.15219, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2177 - loss: 2.0590 - val_accuracy: 0.2711 - val_loss: 2.1522\n",
      "Epoch 9/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2174 - loss: 2.0394\n",
      "Epoch 9: val_loss improved from 2.15219 to 2.05620, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2196 - loss: 2.0395 - val_accuracy: 0.2800 - val_loss: 2.0562\n",
      "Epoch 10/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2216 - loss: 2.0397\n",
      "Epoch 10: val_loss improved from 2.05620 to 2.00739, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2214 - loss: 2.0415 - val_accuracy: 0.2800 - val_loss: 2.0074\n",
      "Epoch 11/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2033 - loss: 1.9736\n",
      "Epoch 11: val_loss improved from 2.00739 to 1.97397, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2098 - loss: 1.9724 - val_accuracy: 0.2933 - val_loss: 1.9740\n",
      "Epoch 12/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2361 - loss: 1.9648\n",
      "Epoch 12: val_loss improved from 1.97397 to 1.94835, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2392 - loss: 1.9544 - val_accuracy: 0.2933 - val_loss: 1.9483\n",
      "Epoch 13/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2342 - loss: 1.9228\n",
      "Epoch 13: val_loss improved from 1.94835 to 1.93308, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.2354 - loss: 1.9174 - val_accuracy: 0.3022 - val_loss: 1.9331\n",
      "Epoch 14/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2550 - loss: 1.8743\n",
      "Epoch 14: val_loss improved from 1.93308 to 1.92187, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2519 - loss: 1.8774 - val_accuracy: 0.3067 - val_loss: 1.9219\n",
      "Epoch 15/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2368 - loss: 1.9004\n",
      "Epoch 15: val_loss did not improve from 1.92187\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2463 - loss: 1.8860 - val_accuracy: 0.2889 - val_loss: 1.9241\n",
      "Epoch 16/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2721 - loss: 1.8044\n",
      "Epoch 16: val_loss did not improve from 1.92187\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2697 - loss: 1.8131 - val_accuracy: 0.2933 - val_loss: 1.9332\n",
      "Epoch 17/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2737 - loss: 1.8289\n",
      "Epoch 17: val_loss did not improve from 1.92187\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2720 - loss: 1.8202 - val_accuracy: 0.3022 - val_loss: 1.9394\n",
      "Epoch 18/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2891 - loss: 1.7655\n",
      "Epoch 18: val_loss did not improve from 1.92187\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2924 - loss: 1.7705 - val_accuracy: 0.3156 - val_loss: 1.9475\n",
      "Epoch 19/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2812 - loss: 1.7953\n",
      "Epoch 19: val_loss did not improve from 1.92187\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.2846 - loss: 1.7921 - val_accuracy: 0.3111 - val_loss: 1.9508\n",
      "Epoch 20/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2541 - loss: 1.7888\n",
      "Epoch 20: val_loss did not improve from 1.92187\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2638 - loss: 1.7867 - val_accuracy: 0.3200 - val_loss: 1.9456\n",
      "Epoch 21/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3288 - loss: 1.7580\n",
      "Epoch 21: val_loss did not improve from 1.92187\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3276 - loss: 1.7594 - val_accuracy: 0.3156 - val_loss: 1.9359\n",
      "Epoch 22/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3292 - loss: 1.7022\n",
      "Epoch 22: val_loss did not improve from 1.92187\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3187 - loss: 1.7248 - val_accuracy: 0.2933 - val_loss: 1.9275\n",
      "Epoch 23/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2977 - loss: 1.7749\n",
      "Epoch 23: val_loss improved from 1.92187 to 1.91408, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2967 - loss: 1.7736 - val_accuracy: 0.2889 - val_loss: 1.9141\n",
      "Epoch 24/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3351 - loss: 1.7135\n",
      "Epoch 24: val_loss improved from 1.91408 to 1.90243, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3316 - loss: 1.7236 - val_accuracy: 0.2756 - val_loss: 1.9024\n",
      "Epoch 25/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2999 - loss: 1.7614\n",
      "Epoch 25: val_loss improved from 1.90243 to 1.89291, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.2984 - loss: 1.7614 - val_accuracy: 0.2667 - val_loss: 1.8929\n",
      "Epoch 26/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2945 - loss: 1.7574\n",
      "Epoch 26: val_loss improved from 1.89291 to 1.87857, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.3005 - loss: 1.7491 - val_accuracy: 0.2667 - val_loss: 1.8786\n",
      "Epoch 27/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2975 - loss: 1.7490\n",
      "Epoch 27: val_loss improved from 1.87857 to 1.86010, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3046 - loss: 1.7376 - val_accuracy: 0.2578 - val_loss: 1.8601\n",
      "Epoch 28/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3149 - loss: 1.7440\n",
      "Epoch 28: val_loss improved from 1.86010 to 1.83917, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3199 - loss: 1.7367 - val_accuracy: 0.2622 - val_loss: 1.8392\n",
      "Epoch 29/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3490 - loss: 1.6623\n",
      "Epoch 29: val_loss improved from 1.83917 to 1.82105, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3461 - loss: 1.6681 - val_accuracy: 0.2622 - val_loss: 1.8211\n",
      "Epoch 30/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3461 - loss: 1.6838\n",
      "Epoch 30: val_loss improved from 1.82105 to 1.80576, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3444 - loss: 1.6841 - val_accuracy: 0.2800 - val_loss: 1.8058\n",
      "Epoch 31/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3030 - loss: 1.7417\n",
      "Epoch 31: val_loss improved from 1.80576 to 1.78827, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3078 - loss: 1.7284 - val_accuracy: 0.2978 - val_loss: 1.7883\n",
      "Epoch 32/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2865 - loss: 1.7093\n",
      "Epoch 32: val_loss improved from 1.78827 to 1.77252, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2935 - loss: 1.7025 - val_accuracy: 0.2978 - val_loss: 1.7725\n",
      "Epoch 33/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3409 - loss: 1.6675\n",
      "Epoch 33: val_loss improved from 1.77252 to 1.75994, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3373 - loss: 1.6716 - val_accuracy: 0.2933 - val_loss: 1.7599\n",
      "Epoch 34/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2882 - loss: 1.7284\n",
      "Epoch 34: val_loss improved from 1.75994 to 1.75027, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2918 - loss: 1.7187 - val_accuracy: 0.2978 - val_loss: 1.7503\n",
      "Epoch 35/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3626 - loss: 1.6595\n",
      "Epoch 35: val_loss improved from 1.75027 to 1.74067, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3548 - loss: 1.6650 - val_accuracy: 0.3067 - val_loss: 1.7407\n",
      "Epoch 36/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3539 - loss: 1.6809\n",
      "Epoch 36: val_loss improved from 1.74067 to 1.73080, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3496 - loss: 1.6783 - val_accuracy: 0.3022 - val_loss: 1.7308\n",
      "Epoch 37/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3047 - loss: 1.6901\n",
      "Epoch 37: val_loss improved from 1.73080 to 1.72091, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3084 - loss: 1.6894 - val_accuracy: 0.3111 - val_loss: 1.7209\n",
      "Epoch 38/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3168 - loss: 1.6877\n",
      "Epoch 38: val_loss improved from 1.72091 to 1.71490, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.3251 - loss: 1.6742 - val_accuracy: 0.3067 - val_loss: 1.7149\n",
      "Epoch 39/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3761 - loss: 1.6265\n",
      "Epoch 39: val_loss improved from 1.71490 to 1.70797, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3691 - loss: 1.6309 - val_accuracy: 0.3022 - val_loss: 1.7080\n",
      "Epoch 40/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3600 - loss: 1.6073\n",
      "Epoch 40: val_loss improved from 1.70797 to 1.70651, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3572 - loss: 1.6212 - val_accuracy: 0.2933 - val_loss: 1.7065\n",
      "Epoch 41/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3581 - loss: 1.6427\n",
      "Epoch 41: val_loss improved from 1.70651 to 1.70071, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.3569 - loss: 1.6466 - val_accuracy: 0.2933 - val_loss: 1.7007\n",
      "Epoch 42/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3581 - loss: 1.6231\n",
      "Epoch 42: val_loss improved from 1.70071 to 1.68744, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3574 - loss: 1.6290 - val_accuracy: 0.3067 - val_loss: 1.6874\n",
      "Epoch 43/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3522 - loss: 1.6552\n",
      "Epoch 43: val_loss improved from 1.68744 to 1.67579, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3490 - loss: 1.6497 - val_accuracy: 0.3156 - val_loss: 1.6758\n",
      "Epoch 44/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3672 - loss: 1.5971\n",
      "Epoch 44: val_loss improved from 1.67579 to 1.66558, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3646 - loss: 1.6062 - val_accuracy: 0.3156 - val_loss: 1.6656\n",
      "Epoch 45/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.3583 - loss: 1.6311\n",
      "Epoch 45: val_loss improved from 1.66558 to 1.65333, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3593 - loss: 1.6287 - val_accuracy: 0.3022 - val_loss: 1.6533\n",
      "Epoch 46/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3750 - loss: 1.6176\n",
      "Epoch 46: val_loss improved from 1.65333 to 1.64102, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3773 - loss: 1.6165 - val_accuracy: 0.3022 - val_loss: 1.6410\n",
      "Epoch 47/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3587 - loss: 1.6300\n",
      "Epoch 47: val_loss improved from 1.64102 to 1.63462, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3653 - loss: 1.6234 - val_accuracy: 0.3067 - val_loss: 1.6346\n",
      "Epoch 48/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3351 - loss: 1.6278\n",
      "Epoch 48: val_loss improved from 1.63462 to 1.63011, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.3440 - loss: 1.6162 - val_accuracy: 0.3156 - val_loss: 1.6301\n",
      "Epoch 49/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3965 - loss: 1.5787\n",
      "Epoch 49: val_loss improved from 1.63011 to 1.62703, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3920 - loss: 1.5913 - val_accuracy: 0.3200 - val_loss: 1.6270\n",
      "Epoch 50/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3401 - loss: 1.6293\n",
      "Epoch 50: val_loss improved from 1.62703 to 1.62587, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.3484 - loss: 1.6174 - val_accuracy: 0.3111 - val_loss: 1.6259\n",
      "Epoch 51/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.3340 - loss: 1.6473\n",
      "Epoch 51: val_loss improved from 1.62587 to 1.62498, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3483 - loss: 1.6259 - val_accuracy: 0.3111 - val_loss: 1.6250\n",
      "Epoch 52/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3737 - loss: 1.5888\n",
      "Epoch 52: val_loss improved from 1.62498 to 1.62185, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3761 - loss: 1.5868 - val_accuracy: 0.3289 - val_loss: 1.6218\n",
      "Epoch 53/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3746 - loss: 1.6262\n",
      "Epoch 53: val_loss improved from 1.62185 to 1.61888, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3780 - loss: 1.6151 - val_accuracy: 0.3289 - val_loss: 1.6189\n",
      "Epoch 54/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3908 - loss: 1.5679\n",
      "Epoch 54: val_loss improved from 1.61888 to 1.61778, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.3882 - loss: 1.5680 - val_accuracy: 0.3333 - val_loss: 1.6178\n",
      "Epoch 55/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4021 - loss: 1.5573\n",
      "Epoch 55: val_loss did not improve from 1.61778\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3950 - loss: 1.5603 - val_accuracy: 0.3378 - val_loss: 1.6199\n",
      "Epoch 56/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3772 - loss: 1.5724\n",
      "Epoch 56: val_loss did not improve from 1.61778\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3826 - loss: 1.5690 - val_accuracy: 0.3467 - val_loss: 1.6228\n",
      "Epoch 57/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3776 - loss: 1.5848\n",
      "Epoch 57: val_loss did not improve from 1.61778\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3789 - loss: 1.5800 - val_accuracy: 0.3511 - val_loss: 1.6256\n",
      "Epoch 58/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3778 - loss: 1.5850\n",
      "Epoch 58: val_loss did not improve from 1.61778\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3835 - loss: 1.5816 - val_accuracy: 0.3378 - val_loss: 1.6283\n",
      "Epoch 59/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.3722 - loss: 1.6139\n",
      "Epoch 59: val_loss did not improve from 1.61778\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3899 - loss: 1.5958 - val_accuracy: 0.3556 - val_loss: 1.6232\n",
      "Epoch 60/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4384 - loss: 1.5515\n",
      "Epoch 60: val_loss did not improve from 1.61778\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4274 - loss: 1.5566 - val_accuracy: 0.3467 - val_loss: 1.6195\n",
      "Epoch 61/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.3880 - loss: 1.5366\n",
      "Epoch 61: val_loss improved from 1.61778 to 1.61495, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.3896 - loss: 1.5428 - val_accuracy: 0.3378 - val_loss: 1.6149\n",
      "Epoch 62/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4047 - loss: 1.5785\n",
      "Epoch 62: val_loss improved from 1.61495 to 1.61325, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4036 - loss: 1.5670 - val_accuracy: 0.3333 - val_loss: 1.6133\n",
      "Epoch 63/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3800 - loss: 1.5655\n",
      "Epoch 63: val_loss improved from 1.61325 to 1.61249, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3817 - loss: 1.5593 - val_accuracy: 0.3422 - val_loss: 1.6125\n",
      "Epoch 64/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4167 - loss: 1.5359\n",
      "Epoch 64: val_loss improved from 1.61249 to 1.61209, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4153 - loss: 1.5333 - val_accuracy: 0.3511 - val_loss: 1.6121\n",
      "Epoch 65/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4086 - loss: 1.5253\n",
      "Epoch 65: val_loss improved from 1.61209 to 1.61185, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4069 - loss: 1.5227 - val_accuracy: 0.3556 - val_loss: 1.6119\n",
      "Epoch 66/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4171 - loss: 1.5391\n",
      "Epoch 66: val_loss improved from 1.61185 to 1.60925, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4062 - loss: 1.5437 - val_accuracy: 0.3556 - val_loss: 1.6093\n",
      "Epoch 67/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3809 - loss: 1.5258\n",
      "Epoch 67: val_loss improved from 1.60925 to 1.60654, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.3893 - loss: 1.5228 - val_accuracy: 0.3600 - val_loss: 1.6065\n",
      "Epoch 68/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4076 - loss: 1.5054\n",
      "Epoch 68: val_loss improved from 1.60654 to 1.60284, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4040 - loss: 1.5036 - val_accuracy: 0.3600 - val_loss: 1.6028\n",
      "Epoch 69/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3741 - loss: 1.5614\n",
      "Epoch 69: val_loss improved from 1.60284 to 1.60117, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.3728 - loss: 1.5606 - val_accuracy: 0.3644 - val_loss: 1.6012\n",
      "Epoch 70/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4297 - loss: 1.4765\n",
      "Epoch 70: val_loss improved from 1.60117 to 1.60073, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4240 - loss: 1.4797 - val_accuracy: 0.3689 - val_loss: 1.6007\n",
      "Epoch 71/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4112 - loss: 1.5204\n",
      "Epoch 71: val_loss improved from 1.60073 to 1.59496, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4116 - loss: 1.5140 - val_accuracy: 0.3733 - val_loss: 1.5950\n",
      "Epoch 72/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4191 - loss: 1.5248\n",
      "Epoch 72: val_loss improved from 1.59496 to 1.58880, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4198 - loss: 1.5242 - val_accuracy: 0.3822 - val_loss: 1.5888\n",
      "Epoch 73/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4106 - loss: 1.4910\n",
      "Epoch 73: val_loss improved from 1.58880 to 1.58625, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4156 - loss: 1.4886 - val_accuracy: 0.3778 - val_loss: 1.5862\n",
      "Epoch 74/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4130 - loss: 1.5058\n",
      "Epoch 74: val_loss improved from 1.58625 to 1.58295, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4179 - loss: 1.4941 - val_accuracy: 0.3689 - val_loss: 1.5830\n",
      "Epoch 75/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4043 - loss: 1.5064\n",
      "Epoch 75: val_loss improved from 1.58295 to 1.57767, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4034 - loss: 1.5050 - val_accuracy: 0.3733 - val_loss: 1.5777\n",
      "Epoch 76/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4112 - loss: 1.5112\n",
      "Epoch 76: val_loss improved from 1.57767 to 1.57553, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4129 - loss: 1.5064 - val_accuracy: 0.3689 - val_loss: 1.5755\n",
      "Epoch 77/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4360 - loss: 1.4593\n",
      "Epoch 77: val_loss improved from 1.57553 to 1.56999, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4380 - loss: 1.4566 - val_accuracy: 0.3644 - val_loss: 1.5700\n",
      "Epoch 78/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4627 - loss: 1.4307\n",
      "Epoch 78: val_loss improved from 1.56999 to 1.56724, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4576 - loss: 1.4433 - val_accuracy: 0.3644 - val_loss: 1.5672\n",
      "Epoch 79/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4273 - loss: 1.4716\n",
      "Epoch 79: val_loss improved from 1.56724 to 1.56326, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4248 - loss: 1.4740 - val_accuracy: 0.3556 - val_loss: 1.5633\n",
      "Epoch 80/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4390 - loss: 1.4403\n",
      "Epoch 80: val_loss improved from 1.56326 to 1.55954, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4327 - loss: 1.4592 - val_accuracy: 0.3600 - val_loss: 1.5595\n",
      "Epoch 81/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4375 - loss: 1.4908\n",
      "Epoch 81: val_loss improved from 1.55954 to 1.55412, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4376 - loss: 1.4906 - val_accuracy: 0.3733 - val_loss: 1.5541\n",
      "Epoch 82/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4735 - loss: 1.4412\n",
      "Epoch 82: val_loss improved from 1.55412 to 1.55155, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4623 - loss: 1.4557 - val_accuracy: 0.3600 - val_loss: 1.5516\n",
      "Epoch 83/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4392 - loss: 1.4656\n",
      "Epoch 83: val_loss improved from 1.55155 to 1.54805, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4399 - loss: 1.4609 - val_accuracy: 0.3733 - val_loss: 1.5481\n",
      "Epoch 84/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4288 - loss: 1.4816\n",
      "Epoch 84: val_loss improved from 1.54805 to 1.54380, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4292 - loss: 1.4736 - val_accuracy: 0.3733 - val_loss: 1.5438\n",
      "Epoch 85/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4473 - loss: 1.4313\n",
      "Epoch 85: val_loss improved from 1.54380 to 1.53992, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4425 - loss: 1.4331 - val_accuracy: 0.3556 - val_loss: 1.5399\n",
      "Epoch 86/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4722 - loss: 1.3853\n",
      "Epoch 86: val_loss improved from 1.53992 to 1.53669, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4691 - loss: 1.3996 - val_accuracy: 0.3511 - val_loss: 1.5367\n",
      "Epoch 87/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4464 - loss: 1.4870\n",
      "Epoch 87: val_loss improved from 1.53669 to 1.53534, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4433 - loss: 1.4798 - val_accuracy: 0.3600 - val_loss: 1.5353\n",
      "Epoch 88/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4425 - loss: 1.4636\n",
      "Epoch 88: val_loss improved from 1.53534 to 1.53456, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4423 - loss: 1.4604 - val_accuracy: 0.3644 - val_loss: 1.5346\n",
      "Epoch 89/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4462 - loss: 1.4243\n",
      "Epoch 89: val_loss improved from 1.53456 to 1.53228, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4468 - loss: 1.4257 - val_accuracy: 0.3644 - val_loss: 1.5323\n",
      "Epoch 90/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4527 - loss: 1.4141\n",
      "Epoch 90: val_loss did not improve from 1.53228\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4489 - loss: 1.4216 - val_accuracy: 0.3644 - val_loss: 1.5331\n",
      "Epoch 91/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4646 - loss: 1.3801\n",
      "Epoch 91: val_loss did not improve from 1.53228\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4601 - loss: 1.3907 - val_accuracy: 0.3644 - val_loss: 1.5325\n",
      "Epoch 92/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4251 - loss: 1.4455\n",
      "Epoch 92: val_loss improved from 1.53228 to 1.52360, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4235 - loss: 1.4445 - val_accuracy: 0.3600 - val_loss: 1.5236\n",
      "Epoch 93/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4375 - loss: 1.4241\n",
      "Epoch 93: val_loss improved from 1.52360 to 1.52118, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4438 - loss: 1.4161 - val_accuracy: 0.3689 - val_loss: 1.5212\n",
      "Epoch 94/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4542 - loss: 1.4375\n",
      "Epoch 94: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4520 - loss: 1.4318 - val_accuracy: 0.3733 - val_loss: 1.5242\n",
      "Epoch 95/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4336 - loss: 1.4322\n",
      "Epoch 95: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4330 - loss: 1.4311 - val_accuracy: 0.3778 - val_loss: 1.5284\n",
      "Epoch 96/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4770 - loss: 1.3669\n",
      "Epoch 96: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4688 - loss: 1.3736 - val_accuracy: 0.3644 - val_loss: 1.5321\n",
      "Epoch 97/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4868 - loss: 1.3633\n",
      "Epoch 97: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4831 - loss: 1.3640 - val_accuracy: 0.3689 - val_loss: 1.5377\n",
      "Epoch 98/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4609 - loss: 1.3983\n",
      "Epoch 98: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4583 - loss: 1.3987 - val_accuracy: 0.3689 - val_loss: 1.5402\n",
      "Epoch 99/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4464 - loss: 1.4003\n",
      "Epoch 99: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4491 - loss: 1.4015 - val_accuracy: 0.3644 - val_loss: 1.5415\n",
      "Epoch 100/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4494 - loss: 1.4350\n",
      "Epoch 100: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4567 - loss: 1.4199 - val_accuracy: 0.3733 - val_loss: 1.5436\n",
      "Epoch 101/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4533 - loss: 1.3822\n",
      "Epoch 101: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4493 - loss: 1.3893 - val_accuracy: 0.3644 - val_loss: 1.5475\n",
      "Epoch 102/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4911 - loss: 1.3899\n",
      "Epoch 102: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4800 - loss: 1.3991 - val_accuracy: 0.3689 - val_loss: 1.5480\n",
      "Epoch 103/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4631 - loss: 1.4009\n",
      "Epoch 103: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4614 - loss: 1.4022 - val_accuracy: 0.3778 - val_loss: 1.5410\n",
      "Epoch 104/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4620 - loss: 1.3944\n",
      "Epoch 104: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4661 - loss: 1.3853 - val_accuracy: 0.3867 - val_loss: 1.5350\n",
      "Epoch 105/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4638 - loss: 1.3950\n",
      "Epoch 105: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4707 - loss: 1.3850 - val_accuracy: 0.3911 - val_loss: 1.5287\n",
      "Epoch 106/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4918 - loss: 1.3780\n",
      "Epoch 106: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4973 - loss: 1.3729 - val_accuracy: 0.3867 - val_loss: 1.5302\n",
      "Epoch 107/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4612 - loss: 1.3600\n",
      "Epoch 107: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4598 - loss: 1.3752 - val_accuracy: 0.3867 - val_loss: 1.5302\n",
      "Epoch 108/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4740 - loss: 1.3664\n",
      "Epoch 108: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4737 - loss: 1.3685 - val_accuracy: 0.3822 - val_loss: 1.5290\n",
      "Epoch 109/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4950 - loss: 1.3453\n",
      "Epoch 109: val_loss did not improve from 1.52118\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4930 - loss: 1.3519 - val_accuracy: 0.3733 - val_loss: 1.5213\n",
      "Epoch 110/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4863 - loss: 1.3603\n",
      "Epoch 110: val_loss improved from 1.52118 to 1.51082, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.4869 - loss: 1.3690 - val_accuracy: 0.3689 - val_loss: 1.5108\n",
      "Epoch 111/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4581 - loss: 1.3588\n",
      "Epoch 111: val_loss improved from 1.51082 to 1.50400, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4584 - loss: 1.3673 - val_accuracy: 0.3644 - val_loss: 1.5040\n",
      "Epoch 112/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4601 - loss: 1.3943\n",
      "Epoch 112: val_loss improved from 1.50400 to 1.50246, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4703 - loss: 1.3817 - val_accuracy: 0.3600 - val_loss: 1.5025\n",
      "Epoch 113/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4698 - loss: 1.3872\n",
      "Epoch 113: val_loss did not improve from 1.50246\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4659 - loss: 1.3863 - val_accuracy: 0.3689 - val_loss: 1.5067\n",
      "Epoch 114/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4933 - loss: 1.3491\n",
      "Epoch 114: val_loss did not improve from 1.50246\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4955 - loss: 1.3482 - val_accuracy: 0.3733 - val_loss: 1.5048\n",
      "Epoch 115/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4970 - loss: 1.3395\n",
      "Epoch 115: val_loss did not improve from 1.50246\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4977 - loss: 1.3404 - val_accuracy: 0.3822 - val_loss: 1.5061\n",
      "Epoch 116/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5158 - loss: 1.3147\n",
      "Epoch 116: val_loss did not improve from 1.50246\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5077 - loss: 1.3231 - val_accuracy: 0.3867 - val_loss: 1.5040\n",
      "Epoch 117/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4670 - loss: 1.3664\n",
      "Epoch 117: val_loss improved from 1.50246 to 1.50086, saving model to SER_RAVDESS_1d_30_09_2024_17_06_27.keras\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4691 - loss: 1.3590 - val_accuracy: 0.3867 - val_loss: 1.5009\n",
      "Epoch 118/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5072 - loss: 1.3025\n",
      "Epoch 118: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4981 - loss: 1.3163 - val_accuracy: 0.3867 - val_loss: 1.5039\n",
      "Epoch 119/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4722 - loss: 1.3530\n",
      "Epoch 119: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4749 - loss: 1.3507 - val_accuracy: 0.3867 - val_loss: 1.5070\n",
      "Epoch 120/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4922 - loss: 1.3516\n",
      "Epoch 120: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4926 - loss: 1.3512 - val_accuracy: 0.3778 - val_loss: 1.5187\n",
      "Epoch 121/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5122 - loss: 1.3231\n",
      "Epoch 121: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5126 - loss: 1.3195 - val_accuracy: 0.3778 - val_loss: 1.5289\n",
      "Epoch 122/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5098 - loss: 1.2939\n",
      "Epoch 122: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5063 - loss: 1.2946 - val_accuracy: 0.3644 - val_loss: 1.5379\n",
      "Epoch 123/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4883 - loss: 1.3558\n",
      "Epoch 123: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4925 - loss: 1.3349 - val_accuracy: 0.3556 - val_loss: 1.5445\n",
      "Epoch 124/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4737 - loss: 1.3501\n",
      "Epoch 124: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4798 - loss: 1.3446 - val_accuracy: 0.3556 - val_loss: 1.5552\n",
      "Epoch 125/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4792 - loss: 1.3567\n",
      "Epoch 125: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4857 - loss: 1.3574 - val_accuracy: 0.3600 - val_loss: 1.5637\n",
      "Epoch 126/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4763 - loss: 1.3615\n",
      "Epoch 126: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4796 - loss: 1.3508 - val_accuracy: 0.3644 - val_loss: 1.5645\n",
      "Epoch 127/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5093 - loss: 1.3042\n",
      "Epoch 127: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5109 - loss: 1.3067 - val_accuracy: 0.3644 - val_loss: 1.5624\n",
      "Epoch 128/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4818 - loss: 1.3351\n",
      "Epoch 128: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4935 - loss: 1.3348 - val_accuracy: 0.3689 - val_loss: 1.5596\n",
      "Epoch 129/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5078 - loss: 1.2788\n",
      "Epoch 129: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5034 - loss: 1.2881 - val_accuracy: 0.3689 - val_loss: 1.5574\n",
      "Epoch 130/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5293 - loss: 1.2394\n",
      "Epoch 130: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5216 - loss: 1.2634 - val_accuracy: 0.3600 - val_loss: 1.5587\n",
      "Epoch 131/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4731 - loss: 1.3156\n",
      "Epoch 131: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4807 - loss: 1.3102 - val_accuracy: 0.3600 - val_loss: 1.5632\n",
      "Epoch 132/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5380 - loss: 1.2478\n",
      "Epoch 132: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5326 - loss: 1.2549 - val_accuracy: 0.3556 - val_loss: 1.5560\n",
      "Epoch 133/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5117 - loss: 1.2599\n",
      "Epoch 133: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5146 - loss: 1.2706 - val_accuracy: 0.3644 - val_loss: 1.5514\n",
      "Epoch 134/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.4781 - loss: 1.3444\n",
      "Epoch 134: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.4802 - loss: 1.3335 - val_accuracy: 0.3778 - val_loss: 1.5485\n",
      "Epoch 135/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5115 - loss: 1.3052\n",
      "Epoch 135: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5118 - loss: 1.2999 - val_accuracy: 0.3867 - val_loss: 1.5458\n",
      "Epoch 136/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5154 - loss: 1.2958\n",
      "Epoch 136: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5101 - loss: 1.2896 - val_accuracy: 0.3822 - val_loss: 1.5424\n",
      "Epoch 137/1000\n",
      "\u001b[1m3/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4913 - loss: 1.3168\n",
      "Epoch 137: val_loss did not improve from 1.50086\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4939 - loss: 1.3098 - val_accuracy: 0.3911 - val_loss: 1.5350\n",
      "Epoch 137: early stopping\n",
      "Restoring model weights from the end of the best epoch: 117.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4154 - loss: 1.5214 \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4154 - loss: 1.5214 \n",
      "Loss : 1.5229425430297852, Accuracy : 0.42399999499320984\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"SER_RAVDESS_1d_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=256,\n",
    "                       epochs=1000,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {model.evaluate(X_test,y_test)[0]}, Accuracy : {model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"EMOVO_dataset/data.csv\")\n",
    "\n",
    "train_data = pd.DataFrame(columns=['filename', 'features', 'label'])\n",
    "\n",
    "features = []\n",
    "for index, file in zip(data_df.index, data_df.file_name):\n",
    "    train_data.loc[index] = [file, extract_new('EMOVO_dataset/'+file, max), data_df.label[index]]\n",
    "\n",
    "\n",
    "X1 = np.empty((0, 50))\n",
    "X2 = np.empty((0, 12))\n",
    "X3 = np.empty((0, 128))\n",
    "X4 = np.empty((0, 7))\n",
    "\n",
    "\n",
    "for data in train_data[\"features\"]:\n",
    "    X1 = np.vstack((X1, data[0]))\n",
    "    X2 = np.vstack((X2, data[1]))\n",
    "    X3 = np.vstack((X3, data[2]))\n",
    "    X4 = np.vstack((X4, data[3]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_classes = (list((train_data[\"label\"].unique())))\n",
    "Y = keras.utils.to_categorical(list((train_data[\"label\"].apply(data_classes.index))))\n",
    "# X = np.stack(train_data[\"features\"])\n",
    "X = np.hstack([X1,X2,X3,X4])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=22)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1425 - loss: 2.8680 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1425 - loss: 2.8680 \n",
      "Loss : 2.8005177974700928, Accuracy : 0.1355932205915451\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss : {model.evaluate(X_test,y_test)[0]}, Accuracy : {model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_df(X):\n",
    "    X_df = pd.DataFrame(columns=['filename', 'features', 'label'])\n",
    "\n",
    "    for index, file in zip(data_df.index, data_df.file_name):\n",
    "        X_df.loc[index] = [file, pd.Series(X[index]), data_df.label[index]]\n",
    "    X = pd.DataFrame(X_df[\"features\"])\n",
    "    return X\n",
    "\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "\n",
    "def get_rocket(X):\n",
    "    trf = Rocket(num_kernels=512) \n",
    "    trf.fit(X) \n",
    "    X_ = trf.transform(X)\n",
    "    return X_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_ = get_rocket(obtain_df(X1)).to_numpy()\n",
    "X2_ = get_rocket(obtain_df(X2)).to_numpy()\n",
    "X3_ = get_rocket(obtain_df(X3)).to_numpy()\n",
    "X4_ = get_rocket(obtain_df(X4)).to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classes = (list((train_data[\"label\"].unique())))\n",
    "Y = keras.utils.to_categorical(list((train_data[\"label\"].apply(data_classes.index))))\n",
    "# X = np.stack(train_data[\"features\"])\n",
    "X_ = np.hstack([X1_,X2_,X3_,X4_])\n",
    "\n",
    "X_train_, X_test_, y_train_, y_test_ = train_test_split(X_, Y, test_size=0.1, random_state=22)\n",
    "X_train_, X_val_, y_train_, y_val_ = train_test_split(X_train_, y_train_, test_size=0.2, random_state=22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.Sequential()\n",
    "kernel_sizes = [5, 5]\n",
    "model.add(keras.layers.Input(shape=(X_train_.shape[1],1)))\n",
    "for size in kernel_sizes:\n",
    "    model.add(keras.layers.Conv1D(\n",
    "        filters = 32,\n",
    "        kernel_size = size,\n",
    "        padding = 'same'\n",
    "    ))  # 卷积层\n",
    "    model.add(keras.layers.BatchNormalization(axis=-1))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32))\n",
    "model.add(keras.layers.BatchNormalization(axis = -1))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(8, activation='softmax')) \n",
    "optimzer = keras.optimizers.Adam(learning_rate= 0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimzer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 342ms/step - accuracy: 0.1438 - loss: 2.5767 - val_accuracy: 0.1269 - val_loss: 6.4232\n",
      "Epoch 2/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 297ms/step - accuracy: 0.2023 - loss: 2.3074 - val_accuracy: 0.1192 - val_loss: 7.9273\n",
      "Epoch 3/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 300ms/step - accuracy: 0.2240 - loss: 2.1809 - val_accuracy: 0.1192 - val_loss: 6.7272\n",
      "Epoch 4/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 305ms/step - accuracy: 0.2563 - loss: 2.0891 - val_accuracy: 0.1192 - val_loss: 6.2217\n",
      "Epoch 5/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 305ms/step - accuracy: 0.2471 - loss: 2.0664 - val_accuracy: 0.1192 - val_loss: 6.0132\n",
      "Epoch 6/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 0.2263 - loss: 2.0727 - val_accuracy: 0.1231 - val_loss: 5.4377\n",
      "Epoch 7/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 0.2530 - loss: 2.0059 - val_accuracy: 0.1231 - val_loss: 4.9031\n",
      "Epoch 8/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 301ms/step - accuracy: 0.2796 - loss: 1.9672 - val_accuracy: 0.1231 - val_loss: 4.0409\n",
      "Epoch 9/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 305ms/step - accuracy: 0.2820 - loss: 1.9472 - val_accuracy: 0.1423 - val_loss: 3.3290\n",
      "Epoch 10/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 309ms/step - accuracy: 0.2713 - loss: 1.9351 - val_accuracy: 0.1385 - val_loss: 2.8503\n",
      "Epoch 11/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 304ms/step - accuracy: 0.3090 - loss: 1.9046 - val_accuracy: 0.1538 - val_loss: 2.4744\n",
      "Epoch 12/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 309ms/step - accuracy: 0.3010 - loss: 1.8554 - val_accuracy: 0.1923 - val_loss: 2.2176\n",
      "Epoch 13/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 306ms/step - accuracy: 0.3082 - loss: 1.8579 - val_accuracy: 0.2077 - val_loss: 2.1017\n",
      "Epoch 14/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 312ms/step - accuracy: 0.3227 - loss: 1.8326 - val_accuracy: 0.2192 - val_loss: 2.0637\n",
      "Epoch 15/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320ms/step - accuracy: 0.3096 - loss: 1.8117 - val_accuracy: 0.2423 - val_loss: 2.0375\n",
      "Epoch 16/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 315ms/step - accuracy: 0.3238 - loss: 1.8112 - val_accuracy: 0.2385 - val_loss: 1.9616\n",
      "Epoch 17/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320ms/step - accuracy: 0.3017 - loss: 1.8222 - val_accuracy: 0.2462 - val_loss: 1.8951\n",
      "Epoch 18/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 316ms/step - accuracy: 0.3201 - loss: 1.7518 - val_accuracy: 0.2538 - val_loss: 1.8719\n",
      "Epoch 19/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 319ms/step - accuracy: 0.3097 - loss: 1.7946 - val_accuracy: 0.2538 - val_loss: 1.8634\n",
      "Epoch 20/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322ms/step - accuracy: 0.3348 - loss: 1.7749 - val_accuracy: 0.2692 - val_loss: 1.8679\n",
      "Epoch 21/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 318ms/step - accuracy: 0.3257 - loss: 1.7681 - val_accuracy: 0.2615 - val_loss: 1.8699\n",
      "Epoch 22/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 316ms/step - accuracy: 0.3362 - loss: 1.7366 - val_accuracy: 0.2731 - val_loss: 1.8627\n",
      "Epoch 23/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 321ms/step - accuracy: 0.3156 - loss: 1.7518 - val_accuracy: 0.2962 - val_loss: 1.8457\n",
      "Epoch 24/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 323ms/step - accuracy: 0.3441 - loss: 1.7190 - val_accuracy: 0.3077 - val_loss: 1.8241\n",
      "Epoch 25/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 317ms/step - accuracy: 0.3483 - loss: 1.7059 - val_accuracy: 0.2962 - val_loss: 1.8187\n",
      "Epoch 26/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320ms/step - accuracy: 0.3374 - loss: 1.7366 - val_accuracy: 0.3115 - val_loss: 1.8190\n",
      "Epoch 27/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 321ms/step - accuracy: 0.3306 - loss: 1.7444 - val_accuracy: 0.2962 - val_loss: 1.8047\n",
      "Epoch 28/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 319ms/step - accuracy: 0.3584 - loss: 1.6859 - val_accuracy: 0.2885 - val_loss: 1.8123\n",
      "Epoch 29/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 320ms/step - accuracy: 0.3395 - loss: 1.6896 - val_accuracy: 0.2962 - val_loss: 1.8166\n",
      "Epoch 30/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325ms/step - accuracy: 0.3581 - loss: 1.7070 - val_accuracy: 0.3269 - val_loss: 1.7799\n",
      "Epoch 31/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 318ms/step - accuracy: 0.3550 - loss: 1.6581 - val_accuracy: 0.3500 - val_loss: 1.7617\n",
      "Epoch 32/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 337ms/step - accuracy: 0.3816 - loss: 1.6700 - val_accuracy: 0.3462 - val_loss: 1.7545\n",
      "Epoch 33/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 340ms/step - accuracy: 0.3609 - loss: 1.6190 - val_accuracy: 0.3462 - val_loss: 1.7488\n",
      "Epoch 34/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - accuracy: 0.3755 - loss: 1.6658 - val_accuracy: 0.3615 - val_loss: 1.7467\n",
      "Epoch 35/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 340ms/step - accuracy: 0.3836 - loss: 1.6613 - val_accuracy: 0.3308 - val_loss: 1.7466\n",
      "Epoch 36/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - accuracy: 0.4198 - loss: 1.5779 - val_accuracy: 0.3346 - val_loss: 1.7375\n",
      "Epoch 37/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - accuracy: 0.3665 - loss: 1.6349 - val_accuracy: 0.3385 - val_loss: 1.7409\n",
      "Epoch 38/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 334ms/step - accuracy: 0.3996 - loss: 1.5898 - val_accuracy: 0.3385 - val_loss: 1.7447\n",
      "Epoch 39/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 330ms/step - accuracy: 0.3723 - loss: 1.6162 - val_accuracy: 0.3500 - val_loss: 1.7463\n",
      "Epoch 40/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 339ms/step - accuracy: 0.3686 - loss: 1.6411 - val_accuracy: 0.3538 - val_loss: 1.7452\n",
      "Epoch 41/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325ms/step - accuracy: 0.3890 - loss: 1.6026 - val_accuracy: 0.3500 - val_loss: 1.7513\n",
      "Epoch 42/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 323ms/step - accuracy: 0.3651 - loss: 1.6472 - val_accuracy: 0.3269 - val_loss: 1.7610\n",
      "Epoch 43/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322ms/step - accuracy: 0.4076 - loss: 1.5951 - val_accuracy: 0.3231 - val_loss: 1.7547\n",
      "Epoch 44/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 324ms/step - accuracy: 0.3787 - loss: 1.6230 - val_accuracy: 0.3231 - val_loss: 1.7434\n",
      "Epoch 45/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 324ms/step - accuracy: 0.4049 - loss: 1.5501 - val_accuracy: 0.3154 - val_loss: 1.7429\n",
      "Epoch 46/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 324ms/step - accuracy: 0.4062 - loss: 1.5734 - val_accuracy: 0.2923 - val_loss: 1.7503\n",
      "Epoch 47/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 322ms/step - accuracy: 0.3900 - loss: 1.5845 - val_accuracy: 0.2962 - val_loss: 1.7720\n",
      "Epoch 48/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 327ms/step - accuracy: 0.4152 - loss: 1.5136 - val_accuracy: 0.3000 - val_loss: 1.7733\n",
      "Epoch 49/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 328ms/step - accuracy: 0.3990 - loss: 1.5684 - val_accuracy: 0.3077 - val_loss: 1.7635\n",
      "Epoch 50/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325ms/step - accuracy: 0.4134 - loss: 1.5376 - val_accuracy: 0.3115 - val_loss: 1.7550\n",
      "Epoch 51/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 323ms/step - accuracy: 0.4407 - loss: 1.5377 - val_accuracy: 0.3000 - val_loss: 1.7541\n",
      "Epoch 52/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 325ms/step - accuracy: 0.4319 - loss: 1.4999 - val_accuracy: 0.3192 - val_loss: 1.7607\n",
      "Epoch 53/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - accuracy: 0.4421 - loss: 1.5200 - val_accuracy: 0.3269 - val_loss: 1.7664\n",
      "Epoch 54/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 332ms/step - accuracy: 0.4566 - loss: 1.5341 - val_accuracy: 0.3115 - val_loss: 1.7680\n",
      "Epoch 55/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 328ms/step - accuracy: 0.4353 - loss: 1.4892 - val_accuracy: 0.3115 - val_loss: 1.7790\n",
      "Epoch 56/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 329ms/step - accuracy: 0.4512 - loss: 1.5089 - val_accuracy: 0.3038 - val_loss: 1.7986\n",
      "Epoch 57/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 336ms/step - accuracy: 0.4311 - loss: 1.5178 - val_accuracy: 0.2731 - val_loss: 1.8213\n",
      "Epoch 58/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 332ms/step - accuracy: 0.4385 - loss: 1.4917 - val_accuracy: 0.2846 - val_loss: 1.8230\n",
      "Epoch 59/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 339ms/step - accuracy: 0.4387 - loss: 1.5061 - val_accuracy: 0.3077 - val_loss: 1.8006\n",
      "Epoch 60/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 336ms/step - accuracy: 0.4094 - loss: 1.5426 - val_accuracy: 0.3000 - val_loss: 1.7899\n",
      "Epoch 61/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 332ms/step - accuracy: 0.4155 - loss: 1.5251 - val_accuracy: 0.3269 - val_loss: 1.7662\n",
      "Epoch 62/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - accuracy: 0.4316 - loss: 1.4933 - val_accuracy: 0.3231 - val_loss: 1.7504\n",
      "Epoch 63/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - accuracy: 0.4307 - loss: 1.5317 - val_accuracy: 0.3423 - val_loss: 1.7507\n",
      "Epoch 64/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 335ms/step - accuracy: 0.4500 - loss: 1.4965 - val_accuracy: 0.3385 - val_loss: 1.7520\n",
      "Epoch 65/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - accuracy: 0.4511 - loss: 1.4565 - val_accuracy: 0.3346 - val_loss: 1.7475\n",
      "Epoch 66/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 330ms/step - accuracy: 0.4593 - loss: 1.4721 - val_accuracy: 0.3192 - val_loss: 1.7482\n",
      "Epoch 67/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - accuracy: 0.4369 - loss: 1.4869 - val_accuracy: 0.3154 - val_loss: 1.7547\n",
      "Epoch 68/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 331ms/step - accuracy: 0.4300 - loss: 1.4785 - val_accuracy: 0.3269 - val_loss: 1.7587\n",
      "Epoch 69/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 330ms/step - accuracy: 0.4580 - loss: 1.4797 - val_accuracy: 0.3269 - val_loss: 1.7572\n",
      "Epoch 70/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 340ms/step - accuracy: 0.4688 - loss: 1.4393 - val_accuracy: 0.3423 - val_loss: 1.7567\n",
      "Epoch 71/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 334ms/step - accuracy: 0.4306 - loss: 1.4694 - val_accuracy: 0.3269 - val_loss: 1.7602\n",
      "Epoch 72/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 342ms/step - accuracy: 0.4302 - loss: 1.4850 - val_accuracy: 0.3231 - val_loss: 1.7632\n",
      "Epoch 73/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 335ms/step - accuracy: 0.4331 - loss: 1.4644 - val_accuracy: 0.3154 - val_loss: 1.7598\n",
      "Epoch 74/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 333ms/step - accuracy: 0.4585 - loss: 1.4552 - val_accuracy: 0.3269 - val_loss: 1.7579\n",
      "Epoch 75/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 331ms/step - accuracy: 0.4259 - loss: 1.4814 - val_accuracy: 0.3385 - val_loss: 1.7698\n",
      "Epoch 76/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 336ms/step - accuracy: 0.4232 - loss: 1.4708 - val_accuracy: 0.3500 - val_loss: 1.7634\n",
      "Epoch 76: early stopping\n",
      "Restoring model weights from the end of the best epoch: 36.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2773 - loss: 1.8133\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2773 - loss: 1.8133 \n",
      "Loss : 1.7990152835845947, Accuracy : 0.3125\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"ser_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=40,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(X_train_, y_train_, \n",
    "                       validation_data=(X_val_,y_val_), \n",
    "                       batch_size=256,\n",
    "                       epochs=1000,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {model.evaluate(X_test_,y_test_)[0]}, Accuracy : {model.evaluate(X_test_,y_test_)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "def get_model(X_train):\n",
    "    inputs = layers.Input(shape=(X_train.shape[1],1))\n",
    "    encoder = layers.LSTM(128)(inputs)\n",
    "    drop = layers.Dropout(0.3)(encoder)\n",
    "    hidden = layers.Dense(32, activation='relu')(drop)\n",
    "    outputs = layers.Dense(8, activation='softmax')(hidden)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_86\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_86\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">197</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m197\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m66,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,952</span> (277.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70,952\u001b[0m (277.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,952</span> (277.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,952\u001b[0m (277.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.1101 - loss: 2.1408 - val_accuracy: 0.1154 - val_loss: 2.0746\n",
      "Epoch 2/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.1573 - loss: 2.0885 - val_accuracy: 0.1192 - val_loss: 2.0928\n",
      "Epoch 3/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.1527 - loss: 2.0576 - val_accuracy: 0.1346 - val_loss: 2.0657\n",
      "Epoch 4/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.1369 - loss: 2.0647 - val_accuracy: 0.1115 - val_loss: 2.0717\n",
      "Epoch 5/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.1680 - loss: 2.0638 - val_accuracy: 0.1500 - val_loss: 2.0798\n",
      "Epoch 6/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.1561 - loss: 2.0601 - val_accuracy: 0.1192 - val_loss: 2.0715\n",
      "Epoch 7/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.1557 - loss: 2.0650 - val_accuracy: 0.1577 - val_loss: 2.0667\n",
      "Epoch 8/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.1545 - loss: 2.0542 - val_accuracy: 0.1346 - val_loss: 2.0810\n",
      "Epoch 9/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.1466 - loss: 2.0618 - val_accuracy: 0.1423 - val_loss: 2.0446\n",
      "Epoch 10/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.1823 - loss: 2.0329 - val_accuracy: 0.1423 - val_loss: 2.0576\n",
      "Epoch 11/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.1753 - loss: 2.0202 - val_accuracy: 0.1808 - val_loss: 2.0500\n",
      "Epoch 12/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.1669 - loss: 2.0373 - val_accuracy: 0.1500 - val_loss: 2.0311\n",
      "Epoch 13/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.1468 - loss: 2.0377 - val_accuracy: 0.1885 - val_loss: 2.0177\n",
      "Epoch 14/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.1859 - loss: 1.9833 - val_accuracy: 0.1462 - val_loss: 2.0340\n",
      "Epoch 15/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.1802 - loss: 1.9918 - val_accuracy: 0.1615 - val_loss: 1.9986\n",
      "Epoch 16/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.1870 - loss: 2.0003 - val_accuracy: 0.1692 - val_loss: 2.0012\n",
      "Epoch 17/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.1763 - loss: 2.0043 - val_accuracy: 0.1692 - val_loss: 1.9959\n",
      "Epoch 18/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.1888 - loss: 1.9952 - val_accuracy: 0.1577 - val_loss: 2.0344\n",
      "Epoch 19/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.2015 - loss: 1.9932 - val_accuracy: 0.1654 - val_loss: 2.0022\n",
      "Epoch 20/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2385 - loss: 1.9644 - val_accuracy: 0.1808 - val_loss: 2.0050\n",
      "Epoch 21/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2229 - loss: 1.9816 - val_accuracy: 0.1769 - val_loss: 2.0016\n",
      "Epoch 22/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.2035 - loss: 1.9731 - val_accuracy: 0.1731 - val_loss: 2.0167\n",
      "Epoch 23/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.1884 - loss: 1.9908 - val_accuracy: 0.1538 - val_loss: 2.0008\n",
      "Epoch 24/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.1877 - loss: 1.9961 - val_accuracy: 0.1769 - val_loss: 1.9996\n",
      "Epoch 25/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2229 - loss: 1.9648 - val_accuracy: 0.1115 - val_loss: 2.2633\n",
      "Epoch 26/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.1286 - loss: 2.1644 - val_accuracy: 0.1500 - val_loss: 2.0132\n",
      "Epoch 27/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.1650 - loss: 2.0245 - val_accuracy: 0.2346 - val_loss: 1.9810\n",
      "Epoch 28/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.1866 - loss: 2.0295 - val_accuracy: 0.2000 - val_loss: 1.9896\n",
      "Epoch 29/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.2073 - loss: 2.0293 - val_accuracy: 0.1962 - val_loss: 2.0029\n",
      "Epoch 30/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.1688 - loss: 2.0260 - val_accuracy: 0.1962 - val_loss: 2.0046\n",
      "Epoch 31/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.1966 - loss: 2.0090 - val_accuracy: 0.1962 - val_loss: 1.9930\n",
      "Epoch 32/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2113 - loss: 2.0091 - val_accuracy: 0.2077 - val_loss: 1.9842\n",
      "Epoch 33/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.2262 - loss: 1.9874 - val_accuracy: 0.1962 - val_loss: 1.9784\n",
      "Epoch 34/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.1957 - loss: 2.0021 - val_accuracy: 0.1846 - val_loss: 1.9843\n",
      "Epoch 35/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2011 - loss: 1.9880 - val_accuracy: 0.2038 - val_loss: 1.9682\n",
      "Epoch 36/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2102 - loss: 1.9760 - val_accuracy: 0.1923 - val_loss: 1.9708\n",
      "Epoch 37/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2201 - loss: 1.9608 - val_accuracy: 0.2000 - val_loss: 1.9817\n",
      "Epoch 38/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2246 - loss: 1.9538 - val_accuracy: 0.1885 - val_loss: 2.0209\n",
      "Epoch 39/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.2019 - loss: 1.9656 - val_accuracy: 0.1885 - val_loss: 1.9883\n",
      "Epoch 40/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.2326 - loss: 1.9416 - val_accuracy: 0.2308 - val_loss: 1.9513\n",
      "Epoch 41/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.2064 - loss: 1.9487 - val_accuracy: 0.2346 - val_loss: 1.9403\n",
      "Epoch 42/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2216 - loss: 1.9601 - val_accuracy: 0.2346 - val_loss: 1.9426\n",
      "Epoch 43/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.2039 - loss: 1.9768 - val_accuracy: 0.1923 - val_loss: 1.9646\n",
      "Epoch 44/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.2233 - loss: 1.9621 - val_accuracy: 0.2615 - val_loss: 1.9037\n",
      "Epoch 45/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.2307 - loss: 1.9908 - val_accuracy: 0.2538 - val_loss: 1.9297\n",
      "Epoch 46/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.2646 - loss: 1.9407 - val_accuracy: 0.2423 - val_loss: 1.9304\n",
      "Epoch 47/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2284 - loss: 1.9663 - val_accuracy: 0.2000 - val_loss: 1.9938\n",
      "Epoch 48/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2214 - loss: 1.9710 - val_accuracy: 0.2808 - val_loss: 1.9164\n",
      "Epoch 49/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.2417 - loss: 1.9494 - val_accuracy: 0.2654 - val_loss: 1.9066\n",
      "Epoch 50/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.2711 - loss: 1.9176 - val_accuracy: 0.2231 - val_loss: 1.9318\n",
      "Epoch 51/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.2429 - loss: 1.9140 - val_accuracy: 0.2192 - val_loss: 1.9559\n",
      "Epoch 52/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.2276 - loss: 1.9566 - val_accuracy: 0.2500 - val_loss: 1.8959\n",
      "Epoch 53/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.2331 - loss: 1.9228 - val_accuracy: 0.2500 - val_loss: 1.8942\n",
      "Epoch 54/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.2376 - loss: 1.9193 - val_accuracy: 0.2654 - val_loss: 1.8923\n",
      "Epoch 55/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.2387 - loss: 1.9178 - val_accuracy: 0.2500 - val_loss: 1.9189\n",
      "Epoch 56/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2545 - loss: 1.9167 - val_accuracy: 0.2346 - val_loss: 1.9386\n",
      "Epoch 57/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2425 - loss: 1.9446 - val_accuracy: 0.2038 - val_loss: 1.9695\n",
      "Epoch 58/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.2264 - loss: 1.9432 - val_accuracy: 0.2308 - val_loss: 1.9418\n",
      "Epoch 59/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2494 - loss: 1.9232 - val_accuracy: 0.2577 - val_loss: 1.8902\n",
      "Epoch 60/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2110 - loss: 1.9463 - val_accuracy: 0.2577 - val_loss: 1.8902\n",
      "Epoch 61/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.2341 - loss: 1.9396 - val_accuracy: 0.2615 - val_loss: 1.8872\n",
      "Epoch 62/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - accuracy: 0.2441 - loss: 1.9251 - val_accuracy: 0.2538 - val_loss: 1.9073\n",
      "Epoch 63/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.2324 - loss: 1.9511 - val_accuracy: 0.2500 - val_loss: 1.8799\n",
      "Epoch 64/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.2647 - loss: 1.9127 - val_accuracy: 0.2192 - val_loss: 1.9193\n",
      "Epoch 65/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.2513 - loss: 1.9182 - val_accuracy: 0.2385 - val_loss: 1.8998\n",
      "Epoch 66/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.2403 - loss: 1.9419 - val_accuracy: 0.2500 - val_loss: 1.8589\n",
      "Epoch 67/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2240 - loss: 1.9256 - val_accuracy: 0.2462 - val_loss: 1.8544\n",
      "Epoch 68/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2439 - loss: 1.9013 - val_accuracy: 0.2154 - val_loss: 1.9001\n",
      "Epoch 69/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.2519 - loss: 1.9185 - val_accuracy: 0.2615 - val_loss: 1.8547\n",
      "Epoch 70/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.2591 - loss: 1.9138 - val_accuracy: 0.2346 - val_loss: 1.8807\n",
      "Epoch 71/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.2349 - loss: 1.9048 - val_accuracy: 0.2538 - val_loss: 1.8551\n",
      "Epoch 72/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2341 - loss: 1.9271 - val_accuracy: 0.2462 - val_loss: 1.8434\n",
      "Epoch 73/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.2633 - loss: 1.8901 - val_accuracy: 0.2808 - val_loss: 1.8269\n",
      "Epoch 74/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2900 - loss: 1.8638 - val_accuracy: 0.2231 - val_loss: 1.8915\n",
      "Epoch 75/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.2686 - loss: 1.9155 - val_accuracy: 0.2808 - val_loss: 1.8571\n",
      "Epoch 76/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2549 - loss: 1.8973 - val_accuracy: 0.3000 - val_loss: 1.8310\n",
      "Epoch 77/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2140 - loss: 1.8850 - val_accuracy: 0.2846 - val_loss: 1.8170\n",
      "Epoch 78/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2431 - loss: 1.8645 - val_accuracy: 0.2615 - val_loss: 1.8164\n",
      "Epoch 79/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2231 - loss: 1.8842 - val_accuracy: 0.2846 - val_loss: 1.7944\n",
      "Epoch 80/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2463 - loss: 1.8895 - val_accuracy: 0.2385 - val_loss: 1.8742\n",
      "Epoch 81/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2382 - loss: 1.9057 - val_accuracy: 0.2500 - val_loss: 1.8321\n",
      "Epoch 82/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.2516 - loss: 1.8566 - val_accuracy: 0.2577 - val_loss: 1.8533\n",
      "Epoch 83/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2502 - loss: 1.8666 - val_accuracy: 0.2808 - val_loss: 1.8212\n",
      "Epoch 84/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2572 - loss: 1.8851 - val_accuracy: 0.2885 - val_loss: 1.8030\n",
      "Epoch 85/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2612 - loss: 1.8707 - val_accuracy: 0.2654 - val_loss: 1.7989\n",
      "Epoch 86/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.2660 - loss: 1.8122 - val_accuracy: 0.2423 - val_loss: 1.8168\n",
      "Epoch 87/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.2834 - loss: 1.8196 - val_accuracy: 0.2192 - val_loss: 1.8169\n",
      "Epoch 88/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2848 - loss: 1.7993 - val_accuracy: 0.2462 - val_loss: 1.8080\n",
      "Epoch 89/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2540 - loss: 1.8413 - val_accuracy: 0.2615 - val_loss: 1.7853\n",
      "Epoch 90/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.2749 - loss: 1.8286 - val_accuracy: 0.2231 - val_loss: 1.8703\n",
      "Epoch 91/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2652 - loss: 1.8522 - val_accuracy: 0.2385 - val_loss: 1.8306\n",
      "Epoch 92/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2898 - loss: 1.8459 - val_accuracy: 0.2538 - val_loss: 1.7833\n",
      "Epoch 93/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2960 - loss: 1.8075 - val_accuracy: 0.2385 - val_loss: 1.8215\n",
      "Epoch 94/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2844 - loss: 1.8098 - val_accuracy: 0.2269 - val_loss: 1.8621\n",
      "Epoch 95/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2664 - loss: 1.8401 - val_accuracy: 0.2500 - val_loss: 1.8075\n",
      "Epoch 96/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2918 - loss: 1.7919 - val_accuracy: 0.2308 - val_loss: 1.8585\n",
      "Epoch 97/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2851 - loss: 1.7759 - val_accuracy: 0.2615 - val_loss: 1.9361\n",
      "Epoch 98/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.2414 - loss: 1.9066 - val_accuracy: 0.2500 - val_loss: 1.8438\n",
      "Epoch 99/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.2884 - loss: 1.7815 - val_accuracy: 0.2654 - val_loss: 1.8220\n",
      "Epoch 100/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2885 - loss: 1.7812 - val_accuracy: 0.2385 - val_loss: 1.8514\n",
      "Epoch 101/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.3056 - loss: 1.7803 - val_accuracy: 0.2500 - val_loss: 1.8498\n",
      "Epoch 102/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2999 - loss: 1.7921 - val_accuracy: 0.2462 - val_loss: 1.8145\n",
      "Epoch 103/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2999 - loss: 1.7751 - val_accuracy: 0.2692 - val_loss: 1.8032\n",
      "Epoch 104/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2837 - loss: 1.7803 - val_accuracy: 0.2423 - val_loss: 1.8121\n",
      "Epoch 105/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.3097 - loss: 1.7399 - val_accuracy: 0.2769 - val_loss: 1.8498\n",
      "Epoch 106/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.2780 - loss: 1.7673 - val_accuracy: 0.2346 - val_loss: 1.8488\n",
      "Epoch 107/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.3261 - loss: 1.7457 - val_accuracy: 0.2577 - val_loss: 1.8788\n",
      "Epoch 108/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.3107 - loss: 1.7209 - val_accuracy: 0.2192 - val_loss: 1.9553\n",
      "Epoch 109/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.2563 - loss: 1.9297 - val_accuracy: 0.2077 - val_loss: 1.9303\n",
      "Epoch 110/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2447 - loss: 1.9051 - val_accuracy: 0.2538 - val_loss: 1.8852\n",
      "Epoch 111/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2961 - loss: 1.8599 - val_accuracy: 0.2692 - val_loss: 1.8790\n",
      "Epoch 112/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.2221 - loss: 1.9530 - val_accuracy: 0.2192 - val_loss: 2.0228\n",
      "Epoch 112: early stopping\n",
      "Restoring model weights from the end of the best epoch: 92.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2789 - loss: 1.8608\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2789 - loss: 1.8608\n",
      "Loss : 1.8534024953842163, Accuracy : 0.2847222089767456\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = get_model(X_train)\n",
    "LSTM_model.summary()\n",
    "\n",
    "\n",
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"ser_lstm_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "LSTM_history = LSTM_model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=32,\n",
    "                       epochs=1000,\n",
    "                       verbose=1,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {LSTM_model.evaluate(X_test,y_test)[0]}, Accuracy : {LSTM_model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_87\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_87\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m, \u001b[38;5;34m1\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m66,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,952</span> (277.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m70,952\u001b[0m (277.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">70,952</span> (277.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m70,952\u001b[0m (277.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.1467 - loss: 2.0815 - val_accuracy: 0.1115 - val_loss: 2.0795\n",
      "Epoch 2/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1322 - loss: 2.0666 - val_accuracy: 0.1077 - val_loss: 2.0730\n",
      "Epoch 3/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1350 - loss: 2.0676 - val_accuracy: 0.1192 - val_loss: 2.0797\n",
      "Epoch 4/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1420 - loss: 2.0600 - val_accuracy: 0.1231 - val_loss: 2.0687\n",
      "Epoch 5/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1446 - loss: 2.0593 - val_accuracy: 0.1308 - val_loss: 2.0678\n",
      "Epoch 6/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1392 - loss: 2.0516 - val_accuracy: 0.1038 - val_loss: 2.0715\n",
      "Epoch 7/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1447 - loss: 2.0529 - val_accuracy: 0.1423 - val_loss: 2.0655\n",
      "Epoch 8/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.1358 - loss: 2.0559 - val_accuracy: 0.1692 - val_loss: 2.0675\n",
      "Epoch 9/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1566 - loss: 2.0538 - val_accuracy: 0.1577 - val_loss: 2.0655\n",
      "Epoch 10/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1716 - loss: 2.0424 - val_accuracy: 0.1538 - val_loss: 2.0509\n",
      "Epoch 11/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1556 - loss: 2.0612 - val_accuracy: 0.0923 - val_loss: 2.0648\n",
      "Epoch 12/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1446 - loss: 2.0513 - val_accuracy: 0.1500 - val_loss: 2.0609\n",
      "Epoch 13/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.1466 - loss: 2.0550 - val_accuracy: 0.1231 - val_loss: 2.0667\n",
      "Epoch 14/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.1636 - loss: 2.0532 - val_accuracy: 0.1654 - val_loss: 2.0617\n",
      "Epoch 15/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1718 - loss: 2.0442 - val_accuracy: 0.1346 - val_loss: 2.0628\n",
      "Epoch 16/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.1680 - loss: 2.0391 - val_accuracy: 0.1538 - val_loss: 2.0561\n",
      "Epoch 17/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1857 - loss: 2.0368 - val_accuracy: 0.1731 - val_loss: 2.0565\n",
      "Epoch 18/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1801 - loss: 2.0349 - val_accuracy: 0.1231 - val_loss: 2.0564\n",
      "Epoch 19/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.1307 - loss: 2.0361 - val_accuracy: 0.1308 - val_loss: 2.0681\n",
      "Epoch 20/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.1634 - loss: 2.0476 - val_accuracy: 0.1577 - val_loss: 2.0538\n",
      "Epoch 21/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1638 - loss: 2.0425 - val_accuracy: 0.1615 - val_loss: 2.0526\n",
      "Epoch 22/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.1428 - loss: 2.0406 - val_accuracy: 0.1500 - val_loss: 2.0494\n",
      "Epoch 23/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1888 - loss: 2.0359 - val_accuracy: 0.1538 - val_loss: 2.0514\n",
      "Epoch 24/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1713 - loss: 2.0233 - val_accuracy: 0.1385 - val_loss: 2.0493\n",
      "Epoch 25/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1482 - loss: 2.0414 - val_accuracy: 0.1577 - val_loss: 2.0465\n",
      "Epoch 26/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1797 - loss: 2.0136 - val_accuracy: 0.1577 - val_loss: 2.0416\n",
      "Epoch 27/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1761 - loss: 2.0201 - val_accuracy: 0.1577 - val_loss: 2.0470\n",
      "Epoch 28/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1754 - loss: 2.0171 - val_accuracy: 0.1538 - val_loss: 2.0418\n",
      "Epoch 29/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1675 - loss: 2.0180 - val_accuracy: 0.1462 - val_loss: 2.0326\n",
      "Epoch 30/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.1837 - loss: 2.0030 - val_accuracy: 0.1538 - val_loss: 2.0269\n",
      "Epoch 31/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.1842 - loss: 2.0056 - val_accuracy: 0.1808 - val_loss: 2.0265\n",
      "Epoch 32/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1971 - loss: 2.0080 - val_accuracy: 0.1769 - val_loss: 2.0255\n",
      "Epoch 33/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.1748 - loss: 2.0194 - val_accuracy: 0.1615 - val_loss: 2.0333\n",
      "Epoch 34/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.1714 - loss: 2.0277 - val_accuracy: 0.1538 - val_loss: 2.0264\n",
      "Epoch 35/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.2028 - loss: 1.9989 - val_accuracy: 0.1846 - val_loss: 2.0240\n",
      "Epoch 36/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.1918 - loss: 1.9956 - val_accuracy: 0.1538 - val_loss: 2.0307\n",
      "Epoch 37/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.1953 - loss: 2.0024 - val_accuracy: 0.1846 - val_loss: 2.0170\n",
      "Epoch 38/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1957 - loss: 2.0009 - val_accuracy: 0.1731 - val_loss: 2.0300\n",
      "Epoch 39/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1895 - loss: 2.0084 - val_accuracy: 0.1769 - val_loss: 2.0223\n",
      "Epoch 40/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1705 - loss: 1.9991 - val_accuracy: 0.1846 - val_loss: 2.0228\n",
      "Epoch 41/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1739 - loss: 2.0153 - val_accuracy: 0.1808 - val_loss: 2.0308\n",
      "Epoch 42/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1827 - loss: 2.0038 - val_accuracy: 0.1577 - val_loss: 2.0182\n",
      "Epoch 43/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1772 - loss: 1.9895 - val_accuracy: 0.1808 - val_loss: 2.0182\n",
      "Epoch 44/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1968 - loss: 1.9965 - val_accuracy: 0.1885 - val_loss: 2.0192\n",
      "Epoch 45/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2032 - loss: 2.0075 - val_accuracy: 0.2038 - val_loss: 2.0176\n",
      "Epoch 46/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1826 - loss: 1.9973 - val_accuracy: 0.1846 - val_loss: 2.0266\n",
      "Epoch 47/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2044 - loss: 1.9977 - val_accuracy: 0.1808 - val_loss: 2.0172\n",
      "Epoch 48/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1966 - loss: 1.9773 - val_accuracy: 0.1692 - val_loss: 2.0201\n",
      "Epoch 49/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2108 - loss: 1.9931 - val_accuracy: 0.1962 - val_loss: 2.0230\n",
      "Epoch 50/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.1941 - loss: 2.0004 - val_accuracy: 0.2115 - val_loss: 2.0231\n",
      "Epoch 51/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2050 - loss: 1.9580 - val_accuracy: 0.1692 - val_loss: 2.0215\n",
      "Epoch 52/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2079 - loss: 1.9855 - val_accuracy: 0.2000 - val_loss: 2.0282\n",
      "Epoch 53/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2282 - loss: 1.9759 - val_accuracy: 0.1885 - val_loss: 2.0217\n",
      "Epoch 54/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2265 - loss: 1.9620 - val_accuracy: 0.1885 - val_loss: 2.0144\n",
      "Epoch 55/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1842 - loss: 2.0004 - val_accuracy: 0.1885 - val_loss: 2.0243\n",
      "Epoch 56/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.1953 - loss: 1.9911 - val_accuracy: 0.2038 - val_loss: 2.0233\n",
      "Epoch 57/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2056 - loss: 1.9867 - val_accuracy: 0.1731 - val_loss: 2.0130\n",
      "Epoch 58/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2284 - loss: 1.9733 - val_accuracy: 0.2000 - val_loss: 2.0336\n",
      "Epoch 59/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2075 - loss: 1.9837 - val_accuracy: 0.1885 - val_loss: 2.0229\n",
      "Epoch 60/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.2042 - loss: 1.9623 - val_accuracy: 0.1846 - val_loss: 2.0130\n",
      "Epoch 61/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2031 - loss: 1.9972 - val_accuracy: 0.1769 - val_loss: 2.0272\n",
      "Epoch 62/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.2305 - loss: 1.9794 - val_accuracy: 0.1885 - val_loss: 2.0181\n",
      "Epoch 63/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2329 - loss: 1.9493 - val_accuracy: 0.1808 - val_loss: 2.0179\n",
      "Epoch 64/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2064 - loss: 1.9768 - val_accuracy: 0.2077 - val_loss: 2.0104\n",
      "Epoch 65/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2319 - loss: 1.9695 - val_accuracy: 0.1654 - val_loss: 2.0218\n",
      "Epoch 66/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2077 - loss: 1.9676 - val_accuracy: 0.1923 - val_loss: 2.0269\n",
      "Epoch 67/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.2369 - loss: 1.9639 - val_accuracy: 0.1962 - val_loss: 2.0114\n",
      "Epoch 68/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2256 - loss: 1.9701 - val_accuracy: 0.2038 - val_loss: 2.0104\n",
      "Epoch 69/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.2127 - loss: 1.9709 - val_accuracy: 0.2115 - val_loss: 2.0136\n",
      "Epoch 70/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2138 - loss: 1.9712 - val_accuracy: 0.1923 - val_loss: 2.0078\n",
      "Epoch 71/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2138 - loss: 1.9657 - val_accuracy: 0.1846 - val_loss: 2.0207\n",
      "Epoch 72/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2351 - loss: 1.9571 - val_accuracy: 0.2077 - val_loss: 2.0171\n",
      "Epoch 73/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2043 - loss: 1.9774 - val_accuracy: 0.2115 - val_loss: 2.0116\n",
      "Epoch 74/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2440 - loss: 1.9535 - val_accuracy: 0.1923 - val_loss: 2.0383\n",
      "Epoch 75/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.2103 - loss: 1.9699 - val_accuracy: 0.2038 - val_loss: 2.0079\n",
      "Epoch 76/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.2169 - loss: 1.9564 - val_accuracy: 0.2115 - val_loss: 2.0154\n",
      "Epoch 77/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.2176 - loss: 1.9726 - val_accuracy: 0.1615 - val_loss: 2.0372\n",
      "Epoch 78/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.2496 - loss: 1.9471 - val_accuracy: 0.1885 - val_loss: 2.0113\n",
      "Epoch 79/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2264 - loss: 1.9456 - val_accuracy: 0.1808 - val_loss: 2.0226\n",
      "Epoch 80/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2241 - loss: 1.9804 - val_accuracy: 0.2115 - val_loss: 2.0247\n",
      "Epoch 81/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2211 - loss: 1.9667 - val_accuracy: 0.1885 - val_loss: 2.0225\n",
      "Epoch 82/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2273 - loss: 1.9683 - val_accuracy: 0.2000 - val_loss: 2.0041\n",
      "Epoch 83/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.2241 - loss: 1.9536 - val_accuracy: 0.1731 - val_loss: 2.0397\n",
      "Epoch 84/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.2429 - loss: 1.9437 - val_accuracy: 0.2038 - val_loss: 2.0162\n",
      "Epoch 85/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2318 - loss: 1.9576 - val_accuracy: 0.2115 - val_loss: 2.0126\n",
      "Epoch 86/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.2203 - loss: 1.9717 - val_accuracy: 0.2385 - val_loss: 2.0149\n",
      "Epoch 87/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2575 - loss: 1.9539 - val_accuracy: 0.2192 - val_loss: 2.0259\n",
      "Epoch 88/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.2280 - loss: 1.9565 - val_accuracy: 0.1846 - val_loss: 2.0068\n",
      "Epoch 89/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.2125 - loss: 1.9653 - val_accuracy: 0.1846 - val_loss: 2.0268\n",
      "Epoch 90/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.2425 - loss: 1.9495 - val_accuracy: 0.1846 - val_loss: 2.0193\n",
      "Epoch 91/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.2375 - loss: 1.9274 - val_accuracy: 0.2077 - val_loss: 2.0037\n",
      "Epoch 92/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.2331 - loss: 1.9391 - val_accuracy: 0.1846 - val_loss: 2.0248\n",
      "Epoch 93/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.2153 - loss: 1.9505 - val_accuracy: 0.1808 - val_loss: 2.0180\n",
      "Epoch 94/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.2346 - loss: 1.9587 - val_accuracy: 0.1654 - val_loss: 2.0391\n",
      "Epoch 95/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - accuracy: 0.2633 - loss: 1.9093 - val_accuracy: 0.2038 - val_loss: 2.0165\n",
      "Epoch 96/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.2574 - loss: 1.9398 - val_accuracy: 0.1962 - val_loss: 1.9971\n",
      "Epoch 97/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.2268 - loss: 1.9433 - val_accuracy: 0.2154 - val_loss: 2.0045\n",
      "Epoch 98/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.2423 - loss: 1.9313 - val_accuracy: 0.1692 - val_loss: 2.0244\n",
      "Epoch 99/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2127 - loss: 1.9458 - val_accuracy: 0.1962 - val_loss: 2.0080\n",
      "Epoch 100/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2483 - loss: 1.9335 - val_accuracy: 0.2231 - val_loss: 2.0005\n",
      "Epoch 101/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2238 - loss: 1.9488 - val_accuracy: 0.2038 - val_loss: 2.0165\n",
      "Epoch 102/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 1s/step - accuracy: 0.2752 - loss: 1.9062 - val_accuracy: 0.2115 - val_loss: 1.9965\n",
      "Epoch 103/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2222 - loss: 1.9340 - val_accuracy: 0.1769 - val_loss: 2.0072\n",
      "Epoch 104/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.2384 - loss: 1.9392 - val_accuracy: 0.1846 - val_loss: 2.0169\n",
      "Epoch 105/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2308 - loss: 1.9277 - val_accuracy: 0.2038 - val_loss: 2.0247\n",
      "Epoch 106/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2198 - loss: 1.9652 - val_accuracy: 0.2269 - val_loss: 1.9868\n",
      "Epoch 107/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2421 - loss: 1.9151 - val_accuracy: 0.2038 - val_loss: 2.0059\n",
      "Epoch 108/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2449 - loss: 1.9505 - val_accuracy: 0.2077 - val_loss: 2.0071\n",
      "Epoch 109/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2445 - loss: 1.9277 - val_accuracy: 0.1962 - val_loss: 2.0123\n",
      "Epoch 110/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2327 - loss: 1.9202 - val_accuracy: 0.2038 - val_loss: 1.9994\n",
      "Epoch 111/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2599 - loss: 1.8872 - val_accuracy: 0.1962 - val_loss: 1.9886\n",
      "Epoch 112/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2571 - loss: 1.9148 - val_accuracy: 0.2231 - val_loss: 1.9965\n",
      "Epoch 113/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2524 - loss: 1.9332 - val_accuracy: 0.1731 - val_loss: 2.0431\n",
      "Epoch 114/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2537 - loss: 1.9585 - val_accuracy: 0.2038 - val_loss: 2.0087\n",
      "Epoch 115/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2272 - loss: 1.9140 - val_accuracy: 0.2000 - val_loss: 2.0174\n",
      "Epoch 116/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2374 - loss: 1.9503 - val_accuracy: 0.2038 - val_loss: 2.0083\n",
      "Epoch 117/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2533 - loss: 1.9139 - val_accuracy: 0.2077 - val_loss: 1.9807\n",
      "Epoch 118/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2482 - loss: 1.9214 - val_accuracy: 0.1885 - val_loss: 2.0305\n",
      "Epoch 119/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2380 - loss: 1.9241 - val_accuracy: 0.1962 - val_loss: 1.9929\n",
      "Epoch 120/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2330 - loss: 1.9040 - val_accuracy: 0.1923 - val_loss: 2.0235\n",
      "Epoch 121/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2172 - loss: 1.9045 - val_accuracy: 0.2115 - val_loss: 1.9998\n",
      "Epoch 122/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2729 - loss: 1.8800 - val_accuracy: 0.2154 - val_loss: 1.9914\n",
      "Epoch 123/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2349 - loss: 1.9085 - val_accuracy: 0.1769 - val_loss: 2.0479\n",
      "Epoch 124/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2471 - loss: 1.9139 - val_accuracy: 0.2077 - val_loss: 1.9991\n",
      "Epoch 125/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2317 - loss: 1.8913 - val_accuracy: 0.2000 - val_loss: 2.0163\n",
      "Epoch 126/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2444 - loss: 1.9324 - val_accuracy: 0.2000 - val_loss: 1.9940\n",
      "Epoch 127/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2648 - loss: 1.8703 - val_accuracy: 0.2154 - val_loss: 1.9901\n",
      "Epoch 128/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2313 - loss: 1.9404 - val_accuracy: 0.1846 - val_loss: 1.9967\n",
      "Epoch 129/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2513 - loss: 1.8985 - val_accuracy: 0.2346 - val_loss: 1.9936\n",
      "Epoch 130/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2413 - loss: 1.9295 - val_accuracy: 0.2038 - val_loss: 2.0133\n",
      "Epoch 131/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2628 - loss: 1.9151 - val_accuracy: 0.2077 - val_loss: 2.0016\n",
      "Epoch 132/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2258 - loss: 1.9264 - val_accuracy: 0.1923 - val_loss: 2.0281\n",
      "Epoch 133/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2195 - loss: 1.9290 - val_accuracy: 0.2192 - val_loss: 1.9879\n",
      "Epoch 134/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2598 - loss: 1.8844 - val_accuracy: 0.2038 - val_loss: 2.0114\n",
      "Epoch 135/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2626 - loss: 1.9080 - val_accuracy: 0.2077 - val_loss: 2.0243\n",
      "Epoch 136/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 1s/step - accuracy: 0.2559 - loss: 1.9133 - val_accuracy: 0.2115 - val_loss: 1.9829\n",
      "Epoch 137/1000\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.2702 - loss: 1.8752 - val_accuracy: 0.1923 - val_loss: 1.9905\n",
      "Epoch 137: early stopping\n",
      "Restoring model weights from the end of the best epoch: 117.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 379ms/step - accuracy: 0.3458 - loss: 1.9550\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 358ms/step - accuracy: 0.3458 - loss: 1.9550\n",
      "Loss : 1.9518640041351318, Accuracy : 0.3472222089767456\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = get_model(X_train_)\n",
    "LSTM_model.summary()\n",
    "\n",
    "\n",
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"ser_lstm_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "LSTM_history = LSTM_model.fit(X_train_, y_train_, \n",
    "                       validation_data=(X_val_,y_val_), \n",
    "                       batch_size=32,\n",
    "                       epochs=1000,\n",
    "                       verbose=1,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {LSTM_model.evaluate(X_test_,y_test_)[0]}, Accuracy : {LSTM_model.evaluate(X_test_,y_test_)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.save_model(LSTM_model, \"LSTM_rocket.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
