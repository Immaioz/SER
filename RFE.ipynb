{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy, scipy as sklearn, librosa, urllib\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import json \n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score\n",
    "import keras\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from os import path\n",
    "\n",
    "from itertools import cycle\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_curve, auc, silhouette_score,roc_auc_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "import opensmile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_features(file,pad):\n",
    "    X, sample_rate = librosa.load(file)\n",
    "    max_ = X.shape[0] / sample_rate\n",
    "    # if max_ < pad:\n",
    "    #     length = (pad * sample_rate) -  (X.shape[0] / sample_rate)\n",
    "    #     X = librosa.util.pad_center(X, size = length, mode = 'constant')\n",
    "    smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.eGeMAPSv02,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    "    )\n",
    "    y = smile.process_signal(X,sample_rate)\n",
    "    #  smile.process_file(file, end=3)\n",
    "    return y\n",
    "def get_max_min(files):\n",
    "    min_, max_ = 100, 0\n",
    "    for file in files:\n",
    "        sound_file, samplerate = librosa.load(file)\n",
    "        t = sound_file.shape[0] / samplerate\n",
    "        if t < min_:\n",
    "            min_ = t\n",
    "        if t >= max_:\n",
    "            max_ = t\n",
    "\n",
    "    return np.round(max_,2) + 0.01, min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"DEMoS/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(columns=['filename', 'features', 'label'])\n",
    "max, min = get_max_min('DEMoS/'+data_df.file_name)\n",
    "filenames= data_df.file_name\n",
    "labels= data_df.label\n",
    "\n",
    "tot = range(list(data_df.index)[-1])\n",
    "\n",
    "\n",
    "\n",
    "for index,file in tqdm(zip(tot,filenames)):\n",
    "    train_data.loc[index] = [file, return_features('DEMoS/'+file,max), labels[index]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle(\"clear_functional.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(\"clear_functional.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_val(train_data):\n",
    "    data_classes = (list((train_data[\"label\"].unique())))\n",
    "    Y = keras.utils.to_categorical(list((train_data[\"label\"].apply(data_classes.index))))\n",
    "    # X = np.concatenate([X1,X2,X3,X4], axis=2)\n",
    "    # X = np.stack(train_data[\"features\"])\n",
    "    # X = X.reshape(X.shape[0], X.shape[-1], -1)\n",
    "    # X = np.squeeze(X,-1)\n",
    "\n",
    "\n",
    "    X = pd.concat(train_data[\"features\"].tolist(), ignore_index=True)\n",
    "    _X = X\n",
    "    # _X= (X-X.min())/(X.max()-X.min())\n",
    "\n",
    "    print(X.shape)\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(_X, Y, test_size=0.1, random_state=22)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=22)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, _X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Input(shape=input_shape))\n",
    "\n",
    "    model.add(keras.layers.Conv1D(256, 3, activation='relu' ))\n",
    "    model.add(keras.layers.MaxPooling1D(padding='same'))\n",
    "    model.add(keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "    model.add(keras.layers.Conv1D(128, 3, activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling1D(padding='same'))\n",
    "    model.add(keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "\n",
    "    model.add(keras.layers.Conv1D(64, 3, activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling1D(padding='same'))\n",
    "    model.add(keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "    model.add(keras.layers.GlobalAveragePooling1D())\n",
    "    # model.add(keras.layers.Dense(4095, activation='relu'))\n",
    "    # model.add(keras.layers.Dense(2048, activation='relu'))\n",
    "    # model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "\n",
    "\n",
    "    # model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    # model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "    optimzer = keras.optimizers.Adam()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimzer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn(input_shape):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Input(shape=input_shape))\n",
    "\n",
    "    # model.add(keras.layers.Conv2D(256, 3, activation='relu' ))\n",
    "    # model.add(keras.layers.MaxPooling2D(padding='same'))\n",
    "    # model.add(keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "    # model.add(keras.layers.Conv2D(128, 3, activation='relu'))\n",
    "    # model.add(keras.layers.MaxPooling2D(padding='same'))\n",
    "    # model.add(keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "\n",
    "    # model.add(keras.layers.Conv2D(64, 3, activation='relu'))\n",
    "    # model.add(keras.layers.MaxPooling2D(padding='same'))\n",
    "    # model.add(keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "    # model.add(keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(keras.layers.Dense(4095, activation='relu'))\n",
    "    model.add(keras.layers.Dense(2048, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "\n",
    "\n",
    "    model.add(keras.layers.Dense(512, activation='relu'))\n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(8, activation='softmax'))\n",
    "\n",
    "    optimzer = keras.optimizers.Adam()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimzer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9696, 88)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4095</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">364,455</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,388,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4095\u001b[0m)           │       \u001b[38;5;34m364,455\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m8,388,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,550,863</span> (44.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,550,863\u001b[0m (44.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,550,863</span> (44.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,550,863\u001b[0m (44.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1398 - loss: 30.7527\n",
      "Epoch 1: val_loss improved from inf to 3.16932, saving model to model/SER_DEMoS_function_04_11_2024_15_22_53.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.1399 - loss: 30.6625 - val_accuracy: 0.1483 - val_loss: 3.1693\n",
      "Epoch 2/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1641 - loss: 9.5430\n",
      "Epoch 2: val_loss improved from 3.16932 to 2.34325, saving model to model/SER_DEMoS_function_04_11_2024_15_22_53.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.1641 - loss: 9.5747 - val_accuracy: 0.1569 - val_loss: 2.3432\n",
      "Epoch 3/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1524 - loss: 19.5805\n",
      "Epoch 3: val_loss improved from 2.34325 to 2.16850, saving model to model/SER_DEMoS_function_04_11_2024_15_22_53.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.1524 - loss: 19.5396 - val_accuracy: 0.1667 - val_loss: 2.1685\n",
      "Epoch 4/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1588 - loss: 2.3604\n",
      "Epoch 4: val_loss improved from 2.16850 to 2.15214, saving model to model/SER_DEMoS_function_04_11_2024_15_22_53.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.1588 - loss: 2.3602 - val_accuracy: 0.1672 - val_loss: 2.1521\n",
      "Epoch 5/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1729 - loss: 2.0979\n",
      "Epoch 5: val_loss improved from 2.15214 to 2.13565, saving model to model/SER_DEMoS_function_04_11_2024_15_22_53.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.1728 - loss: 2.0980 - val_accuracy: 0.1667 - val_loss: 2.1357\n",
      "Epoch 6/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1757 - loss: 2.0294\n",
      "Epoch 6: val_loss did not improve from 2.13565\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.1757 - loss: 2.0297 - val_accuracy: 0.1672 - val_loss: 2.1593\n",
      "Epoch 7/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1755 - loss: 2.5440\n",
      "Epoch 7: val_loss improved from 2.13565 to 2.03826, saving model to model/SER_DEMoS_function_04_11_2024_15_22_53.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.1753 - loss: 2.5427 - val_accuracy: 0.1684 - val_loss: 2.0383\n",
      "Epoch 8/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1631 - loss: 2.2083\n",
      "Epoch 8: val_loss did not improve from 2.03826\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1631 - loss: 2.2090 - val_accuracy: 0.1718 - val_loss: 2.0519\n",
      "Epoch 9/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1671 - loss: 2.1355\n",
      "Epoch 9: val_loss improved from 2.03826 to 2.03153, saving model to model/SER_DEMoS_function_04_11_2024_15_22_53.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.1671 - loss: 2.1359 - val_accuracy: 0.1678 - val_loss: 2.0315\n",
      "Epoch 10/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1693 - loss: 2.0456\n",
      "Epoch 10: val_loss did not improve from 2.03153\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.1693 - loss: 2.0456 - val_accuracy: 0.1735 - val_loss: 2.0657\n",
      "Epoch 11/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1705 - loss: 2.1220\n",
      "Epoch 11: val_loss improved from 2.03153 to 2.01017, saving model to model/SER_DEMoS_function_04_11_2024_15_22_53.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.1705 - loss: 2.1221 - val_accuracy: 0.1695 - val_loss: 2.0102\n",
      "Epoch 12/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1798 - loss: 2.1556\n",
      "Epoch 12: val_loss did not improve from 2.01017\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.1798 - loss: 2.1553 - val_accuracy: 0.1672 - val_loss: 2.0187\n",
      "Epoch 13/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1813 - loss: 2.1430\n",
      "Epoch 13: val_loss did not improve from 2.01017\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1813 - loss: 2.1452 - val_accuracy: 0.1793 - val_loss: 2.1632\n",
      "Epoch 14/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1897 - loss: 2.1463\n",
      "Epoch 14: val_loss did not improve from 2.01017\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.1896 - loss: 2.1504 - val_accuracy: 0.2050 - val_loss: 2.1942\n",
      "Epoch 15/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1938 - loss: 2.6465\n",
      "Epoch 15: val_loss did not improve from 2.01017\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1938 - loss: 2.6633 - val_accuracy: 0.1564 - val_loss: 2.1726\n",
      "Epoch 16/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1788 - loss: 2.1208\n",
      "Epoch 16: val_loss improved from 2.01017 to 2.00618, saving model to model/SER_DEMoS_function_04_11_2024_15_22_53.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.1788 - loss: 2.1203 - val_accuracy: 0.2108 - val_loss: 2.0062\n",
      "Epoch 17/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2137 - loss: 2.1771\n",
      "Epoch 17: val_loss did not improve from 2.00618\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.2137 - loss: 2.1762 - val_accuracy: 0.2188 - val_loss: 2.0214\n",
      "Epoch 18/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2153 - loss: 2.1283\n",
      "Epoch 18: val_loss improved from 2.00618 to 1.99388, saving model to model/SER_DEMoS_function_04_11_2024_15_22_53.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.2153 - loss: 2.1282 - val_accuracy: 0.2136 - val_loss: 1.9939\n",
      "Epoch 19/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2267 - loss: 2.0082\n",
      "Epoch 19: val_loss did not improve from 1.99388\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.2267 - loss: 2.0099 - val_accuracy: 0.2056 - val_loss: 2.6139\n",
      "Epoch 20/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2107 - loss: 63.2651\n",
      "Epoch 20: val_loss did not improve from 1.99388\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.2107 - loss: 63.3257 - val_accuracy: 0.2222 - val_loss: 2.0241\n",
      "Epoch 21/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1962 - loss: 12.4631\n",
      "Epoch 21: val_loss did not improve from 1.99388\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1962 - loss: 12.4378 - val_accuracy: 0.2159 - val_loss: 1.9989\n",
      "Epoch 22/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2092 - loss: 2.0459\n",
      "Epoch 22: val_loss improved from 1.99388 to 1.99180, saving model to model/SER_DEMoS_function_04_11_2024_15_22_53.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.2093 - loss: 2.0463 - val_accuracy: 0.2119 - val_loss: 1.9918\n",
      "Epoch 23/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2394 - loss: 3.1703\n",
      "Epoch 23: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.2394 - loss: 3.1778 - val_accuracy: 0.2199 - val_loss: 2.0567\n",
      "Epoch 24/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1955 - loss: 25.8870\n",
      "Epoch 24: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1955 - loss: 25.8274 - val_accuracy: 0.1867 - val_loss: 2.2496\n",
      "Epoch 25/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1989 - loss: 62.5432\n",
      "Epoch 25: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1987 - loss: 62.3955 - val_accuracy: 0.1781 - val_loss: 2.3861\n",
      "Epoch 26/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1718 - loss: 2.0507\n",
      "Epoch 26: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1719 - loss: 2.0510 - val_accuracy: 0.2027 - val_loss: 2.1236\n",
      "Epoch 27/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1854 - loss: 2.0359\n",
      "Epoch 27: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1854 - loss: 2.0360 - val_accuracy: 0.2027 - val_loss: 2.0968\n",
      "Epoch 28/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1892 - loss: 2.0451\n",
      "Epoch 28: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1893 - loss: 2.0450 - val_accuracy: 0.2096 - val_loss: 2.0720\n",
      "Epoch 29/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2078 - loss: 2.0139\n",
      "Epoch 29: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.2078 - loss: 2.0139 - val_accuracy: 0.2142 - val_loss: 2.0454\n",
      "Epoch 30/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2029 - loss: 2.0422\n",
      "Epoch 30: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.2029 - loss: 2.0427 - val_accuracy: 0.2108 - val_loss: 2.0502\n",
      "Epoch 31/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2282 - loss: 1.9874\n",
      "Epoch 31: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.2282 - loss: 1.9875 - val_accuracy: 0.2050 - val_loss: 2.0485\n",
      "Epoch 32/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2286 - loss: 1.9943\n",
      "Epoch 32: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.2286 - loss: 1.9942 - val_accuracy: 0.2239 - val_loss: 2.0184\n",
      "Epoch 33/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2298 - loss: 1.9717\n",
      "Epoch 33: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.2298 - loss: 1.9717 - val_accuracy: 0.2228 - val_loss: 2.0046\n",
      "Epoch 34/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2292 - loss: 1.9655\n",
      "Epoch 34: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.2292 - loss: 1.9655 - val_accuracy: 0.2171 - val_loss: 2.0065\n",
      "Epoch 35/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2366 - loss: 1.9577\n",
      "Epoch 35: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.2366 - loss: 1.9577 - val_accuracy: 0.2234 - val_loss: 2.0149\n",
      "Epoch 36/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2367 - loss: 2.0016\n",
      "Epoch 36: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.2367 - loss: 2.0029 - val_accuracy: 0.2153 - val_loss: 2.4698\n",
      "Epoch 37/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2390 - loss: 1.9912\n",
      "Epoch 37: val_loss did not improve from 1.99180\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.2389 - loss: 1.9911 - val_accuracy: 0.2125 - val_loss: 2.3971\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2028 - loss: 2.2285\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2028 - loss: 2.2285\n",
      "Loss : 2.3439478874206543, Accuracy : 0.21134020388126373\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"model/SER_DEMoS_function_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=15,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, X, Y  = split_train_test_val(train_data)\n",
    "\n",
    "model = get_cnn((X_train.shape[1:]))\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=32,\n",
    "                       epochs=1000,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {model.evaluate(X_test,y_test)[0]}, Accuracy : {model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9696, 88)\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n",
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n",
      "Fitting estimator with 20 features.\n",
      "Fitting estimator with 19 features.\n",
      "Fitting estimator with 18 features.\n",
      "Fitting estimator with 17 features.\n",
      "Fitting estimator with 16 features.\n",
      "Fitting estimator with 15 features.\n",
      "Fitting estimator with 14 features.\n",
      "Fitting estimator with 13 features.\n",
      "Fitting estimator with 12 features.\n",
      "Fitting estimator with 11 features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=RandomForestRegressor(max_depth=100, n_jobs=-1),\n",
       "    n_features_to_select=10, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RFE<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_selection.RFE.html\">?<span>Documentation for RFE</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RFE(estimator=RandomForestRegressor(max_depth=100, n_jobs=-1),\n",
       "    n_features_to_select=10, verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=100, n_jobs=-1)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;RandomForestRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">?<span>Documentation for RandomForestRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestRegressor(max_depth=100, n_jobs=-1)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=RandomForestRegressor(max_depth=100, n_jobs=-1),\n",
       "    n_features_to_select=10, verbose=3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, X, Y = split_train_test_val(train_data)\n",
    "\n",
    "\n",
    "# regressor = LogisticRegression(random_state=22)\n",
    "regressor = RandomForestRegressor(n_estimators=100, max_depth=100, n_jobs=-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "\n",
    "n_features_to_select = 10\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select=n_features_to_select, verbose=3)\n",
    "\n",
    "# rfe = RFECV(regressor, step=1, cv=5, verbose=3)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9696, 88)\n",
      "0.07743812627831259\n",
      "0.06307613161821557\n",
      "0.0616724408710736\n",
      "0.050061860908707345\n",
      "0.0498507262075476\n",
      "0.04795017393145251\n",
      "0.04502798984035783\n",
      "0.04424781456507354\n",
      "0.04223880272239944\n",
      "0.040992948078965696\n",
      "0.04079715930379324\n",
      "0.04044576106782749\n",
      "0.03999467031162807\n",
      "0.038020949140983085\n",
      "0.036581126816873866\n",
      "0.036432101844692255\n",
      "0.035478334507251574\n",
      "0.035323331879631326\n",
      "0.03490720278815296\n",
      "0.03484425131604718\n",
      "0.03482011722024447\n",
      "0.0342344739412761\n",
      "0.033076356373417326\n",
      "0.03139802443319528\n",
      "0.029419006488006882\n",
      "0.029412371871967657\n",
      "0.027620027704911454\n",
      "0.025905301638959433\n",
      "0.02541124389611671\n",
      "0.02540431277680444\n",
      "0.025131960985113277\n",
      "0.024735554336037247\n",
      "0.023759381115834977\n",
      "0.022386428227107125\n",
      "0.02197325993390331\n",
      "0.02127903502544637\n",
      "0.020765813787439136\n",
      "0.020482277141966154\n",
      "0.020442484952477802\n",
      "0.020179574646572718\n",
      "0.020079428175543423\n",
      "0.01996390235461032\n",
      "0.019842318162276218\n",
      "0.019809658960149967\n",
      "0.019555925450169376\n",
      "0.01899375022907357\n",
      "0.018908194621923613\n",
      "0.018820948375024127\n",
      "0.018493265760116895\n",
      "0.017650061292196373\n",
      "0.017347979018932147\n",
      "0.01702607345899887\n",
      "0.016746196230316812\n",
      "0.016548676705652632\n",
      "0.01648532495099575\n",
      "0.015973221256247783\n",
      "0.015514366046422534\n",
      "0.015034839888378837\n",
      "0.014278799195047487\n",
      "0.013458408575223402\n",
      "0.012677873820909458\n",
      "0.012677302923518763\n",
      "0.01265066783878721\n",
      "0.01219024061232643\n",
      "0.012189560323762283\n",
      "0.012143446545265224\n",
      "0.010408834215646756\n",
      "0.009798445962228897\n",
      "0.009697190742759432\n",
      "0.009503535678608177\n",
      "0.008909100086409882\n",
      "0.00860683087211811\n",
      "0.007981329245243085\n",
      "0.007945348486995574\n",
      "0.007189702077700311\n",
      "0.00701313031745876\n",
      "0.006727433005121686\n",
      "0.006423887276809648\n",
      "0.006018611186577427\n",
      "0.005437390885604021\n",
      "0.005353014963561442\n",
      "0.004251714275710139\n",
      "0.004105862891764733\n",
      "0.0031011902600490693\n",
      "0.002972974255862404\n",
      "0.001657196565059138\n",
      "0.0009205504868026182\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, X, Y = split_train_test_val(train_data)\n",
    "\n",
    "\n",
    "y = []\n",
    "for i in range(len(Y)):\n",
    "    y.append(np.argmax(Y[i]))\n",
    "\n",
    "Res = mutual_info_classif(X, y)\n",
    "from operator import itemgetter\n",
    "features = X_train.columns.to_list()\n",
    "best_features = []\n",
    "for x1, x2 in (sorted(zip(Res , features), key=itemgetter(0), reverse= True)):\n",
    "    # if x1 == 1:\n",
    "        print(x1)\n",
    "        best_features.append(x2)\n",
    "\n",
    "# best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mfcc1_sma3_stddevNorm',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',\n",
       " 'MeanVoicedSegmentLengthSec',\n",
       " 'StddevVoicedSegmentLengthSec',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_percentile80.0',\n",
       " 'mfcc1_sma3_amean',\n",
       " 'VoicedSegmentsPerSec',\n",
       " 'alphaRatioV_sma3nz_amean',\n",
       " 'loudnessPeaksPerSec',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_percentile50.0',\n",
       " 'F3amplitudeLogRelF0_sma3nz_amean',\n",
       " 'mfcc1V_sma3nz_amean',\n",
       " 'F3amplitudeLogRelF0_sma3nz_stddevNorm',\n",
       " 'StddevUnvoicedSegmentLength',\n",
       " 'F1amplitudeLogRelF0_sma3nz_stddevNorm',\n",
       " 'mfcc1V_sma3nz_stddevNorm',\n",
       " 'alphaRatioV_sma3nz_stddevNorm',\n",
       " 'MeanUnvoicedSegmentLength',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_stddevNorm',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_amean',\n",
       " 'mfcc3V_sma3nz_stddevNorm',\n",
       " 'mfcc2_sma3_stddevNorm',\n",
       " 'F2amplitudeLogRelF0_sma3nz_amean',\n",
       " 'mfcc3_sma3_stddevNorm',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_percentile20.0',\n",
       " 'F1amplitudeLogRelF0_sma3nz_amean',\n",
       " 'mfcc2V_sma3nz_stddevNorm',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope',\n",
       " 'slopeV500-1500_sma3nz_stddevNorm',\n",
       " 'slopeUV500-1500_sma3nz_amean',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope',\n",
       " 'hammarbergIndexV_sma3nz_amean',\n",
       " 'mfcc2_sma3_amean',\n",
       " 'F2bandwidth_sma3nz_amean',\n",
       " 'F2frequency_sma3nz_stddevNorm',\n",
       " 'F2amplitudeLogRelF0_sma3nz_stddevNorm',\n",
       " 'loudness_sma3_meanRisingSlope',\n",
       " 'mfcc3_sma3_amean',\n",
       " 'loudness_sma3_percentile20.0',\n",
       " 'mfcc3V_sma3nz_amean',\n",
       " 'F2bandwidth_sma3nz_stddevNorm',\n",
       " 'hammarbergIndexUV_sma3nz_amean',\n",
       " 'F3frequency_sma3nz_stddevNorm',\n",
       " 'slopeV500-1500_sma3nz_amean',\n",
       " 'logRelF0-H1-H2_sma3nz_stddevNorm',\n",
       " 'loudness_sma3_stddevNorm',\n",
       " 'loudness_sma3_stddevFallingSlope',\n",
       " 'HNRdBACF_sma3nz_stddevNorm',\n",
       " 'mfcc4V_sma3nz_amean',\n",
       " 'logRelF0-H1-A3_sma3nz_stddevNorm',\n",
       " 'HNRdBACF_sma3nz_amean',\n",
       " 'logRelF0-H1-A3_sma3nz_amean',\n",
       " 'spectralFluxV_sma3nz_stddevNorm',\n",
       " 'spectralFlux_sma3_stddevNorm',\n",
       " 'F3bandwidth_sma3nz_stddevNorm',\n",
       " 'F1frequency_sma3nz_stddevNorm',\n",
       " 'F1frequency_sma3nz_amean',\n",
       " 'loudness_sma3_amean',\n",
       " 'mfcc2V_sma3nz_amean',\n",
       " 'equivalentSoundLevel_dBp',\n",
       " 'loudness_sma3_stddevRisingSlope',\n",
       " 'F3bandwidth_sma3nz_amean',\n",
       " 'jitterLocal_sma3nz_stddevNorm',\n",
       " 'F1bandwidth_sma3nz_amean',\n",
       " 'hammarbergIndexV_sma3nz_stddevNorm',\n",
       " 'F1bandwidth_sma3nz_stddevNorm',\n",
       " 'shimmerLocaldB_sma3nz_stddevNorm',\n",
       " 'spectralFluxUV_sma3nz_amean',\n",
       " 'slopeV0-500_sma3nz_stddevNorm',\n",
       " 'mfcc4_sma3_stddevNorm',\n",
       " 'spectralFlux_sma3_amean',\n",
       " 'mfcc4V_sma3nz_stddevNorm',\n",
       " 'loudness_sma3_pctlrange0-2',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope',\n",
       " 'spectralFluxV_sma3nz_amean',\n",
       " 'slopeUV0-500_sma3nz_amean',\n",
       " 'F3frequency_sma3nz_amean',\n",
       " 'loudness_sma3_percentile80.0',\n",
       " 'mfcc4_sma3_amean',\n",
       " 'slopeV0-500_sma3nz_amean',\n",
       " 'loudness_sma3_meanFallingSlope',\n",
       " 'shimmerLocaldB_sma3nz_amean',\n",
       " 'F2frequency_sma3nz_amean',\n",
       " 'loudness_sma3_percentile50.0',\n",
       " 'alphaRatioUV_sma3nz_amean',\n",
       " 'jitterLocal_sma3nz_amean',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope',\n",
       " 'logRelF0-H1-H2_sma3nz_amean']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 88 artists>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(best_features, sorted(Res,reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = sorted(Res,reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26beac79790>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.cumsum(n)\n",
    "\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=100, n_features=10, n_informative=2, n_clusters_per_class=1,\n",
    "    shuffle=False, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.03483576 0.03481663 0.02935732 0.04113584 0.04987155 0.06303657\n 0.02582155 0.0012953  0.02514156 0.00876064 0.01508833 0.01910178\n 0.02042359 0.00312457 0.00641866 0.00797985 0.02087789 0.01258539\n 0.00533429 0.01892278 0.0089223  0.01655201 0.04796259 0.07742073\n 0.02363022 0.03423624 0.02055379 0.03140278 0.00602461 0.00951352\n 0.00155318 0.01275704 0.00429572 0.0103935  0.01735769 0.01891437\n 0.         0.01953111 0.01696023 0.01764156 0.01554565 0.01598774\n 0.01215418 0.01211573 0.02951054 0.03659959 0.00408939 0.02191438\n 0.02239066 0.02006259 0.03307206 0.02124733 0.00670958 0.01981661\n 0.01265731 0.01654741 0.04078126 0.04000712 0.04427316 0.03549342\n 0.02470877 0.012147   0.00538791 0.00965842 0.01984359 0.02540464\n 0.00715801 0.01669339 0.04042383 0.03638157 0.01433073 0.02764641\n 0.02019725 0.03486019 0.01850472 0.00858174 0.00302579 0.02004986\n 0.00682022 0.02533719 0.00973518 0.04085544 0.04531873 0.061134\n 0.04879755 0.02858384 0.03612395 0.013439  ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m      3\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m----> 4\u001b[0m norm \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# sorted(Res, reverse=True)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m norm\n",
      "File \u001b[1;32mc:\\Users\\anton\\Documents\\PhD\\Speech_Emotion_Recognition\\EMOVO_dataset\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:450\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anton\\Documents\\PhD\\Speech_Emotion_Recognition\\EMOVO_dataset\\.venv\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anton\\Documents\\PhD\\Speech_Emotion_Recognition\\EMOVO_dataset\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:490\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    487\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    489\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 490\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_array_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m data_min \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m    498\u001b[0m data_max \u001b[38;5;241m=\u001b[39m _array_api\u001b[38;5;241m.\u001b[39m_nanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, xp\u001b[38;5;241m=\u001b[39mxp)\n",
      "File \u001b[1;32mc:\\Users\\anton\\Documents\\PhD\\Speech_Emotion_Recognition\\EMOVO_dataset\\.venv\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\anton\\Documents\\PhD\\Speech_Emotion_Recognition\\EMOVO_dataset\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1050\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1044\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1045\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1046\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1047\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1048\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1049\u001b[0m             )\n\u001b[1;32m-> 1050\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1054\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1055\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1056\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0.03483576 0.03481663 0.02935732 0.04113584 0.04987155 0.06303657\n 0.02582155 0.0012953  0.02514156 0.00876064 0.01508833 0.01910178\n 0.02042359 0.00312457 0.00641866 0.00797985 0.02087789 0.01258539\n 0.00533429 0.01892278 0.0089223  0.01655201 0.04796259 0.07742073\n 0.02363022 0.03423624 0.02055379 0.03140278 0.00602461 0.00951352\n 0.00155318 0.01275704 0.00429572 0.0103935  0.01735769 0.01891437\n 0.         0.01953111 0.01696023 0.01764156 0.01554565 0.01598774\n 0.01215418 0.01211573 0.02951054 0.03659959 0.00408939 0.02191438\n 0.02239066 0.02006259 0.03307206 0.02124733 0.00670958 0.01981661\n 0.01265731 0.01654741 0.04078126 0.04000712 0.04427316 0.03549342\n 0.02470877 0.012147   0.00538791 0.00965842 0.01984359 0.02540464\n 0.00715801 0.01669339 0.04042383 0.03638157 0.01433073 0.02764641\n 0.02019725 0.03486019 0.01850472 0.00858174 0.00302579 0.02004986\n 0.00682022 0.02533719 0.00973518 0.04085544 0.04531873 0.061134\n 0.04879755 0.02858384 0.03612395 0.013439  ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "norm = scaler.fit(Res)\n",
    "# sorted(Res, reverse=True)\n",
    "norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mfcc1_sma3_stddevNorm\n",
      "F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2\n",
      "MeanVoicedSegmentLengthSec\n",
      "StddevVoicedSegmentLengthSec\n",
      "F0semitoneFrom27.5Hz_sma3nz_percentile80.0\n",
      "mfcc1_sma3_amean\n",
      "VoicedSegmentsPerSec\n",
      "alphaRatioV_sma3nz_amean\n",
      "loudnessPeaksPerSec\n",
      "F0semitoneFrom27.5Hz_sma3nz_percentile50.0\n",
      "F3amplitudeLogRelF0_sma3nz_amean\n",
      "mfcc1V_sma3nz_amean\n",
      "F3amplitudeLogRelF0_sma3nz_stddevNorm\n",
      "StddevUnvoicedSegmentLength\n",
      "F1amplitudeLogRelF0_sma3nz_stddevNorm\n",
      "mfcc1V_sma3nz_stddevNorm\n",
      "alphaRatioV_sma3nz_stddevNorm\n",
      "MeanUnvoicedSegmentLength\n",
      "F0semitoneFrom27.5Hz_sma3nz_stddevNorm\n",
      "F0semitoneFrom27.5Hz_sma3nz_amean\n",
      "mfcc3V_sma3nz_stddevNorm\n",
      "mfcc2_sma3_stddevNorm\n",
      "F2amplitudeLogRelF0_sma3nz_amean\n",
      "mfcc3_sma3_stddevNorm\n",
      "F0semitoneFrom27.5Hz_sma3nz_percentile20.0\n",
      "F1amplitudeLogRelF0_sma3nz_amean\n",
      "mfcc2V_sma3nz_stddevNorm\n",
      "F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope\n",
      "slopeV500-1500_sma3nz_stddevNorm\n",
      "slopeUV500-1500_sma3nz_amean\n",
      "F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope\n",
      "hammarbergIndexV_sma3nz_amean\n",
      "mfcc2_sma3_amean\n",
      "F2bandwidth_sma3nz_amean\n",
      "F2frequency_sma3nz_stddevNorm\n",
      "F2amplitudeLogRelF0_sma3nz_stddevNorm\n",
      "loudness_sma3_meanRisingSlope\n",
      "mfcc3_sma3_amean\n",
      "loudness_sma3_percentile20.0\n",
      "mfcc3V_sma3nz_amean\n",
      "F2bandwidth_sma3nz_stddevNorm\n",
      "hammarbergIndexUV_sma3nz_amean\n",
      "F3frequency_sma3nz_stddevNorm\n",
      "slopeV500-1500_sma3nz_amean\n",
      "logRelF0-H1-H2_sma3nz_stddevNorm\n",
      "loudness_sma3_stddevNorm\n",
      "loudness_sma3_stddevFallingSlope\n",
      "HNRdBACF_sma3nz_stddevNorm\n",
      "mfcc4V_sma3nz_amean\n",
      "logRelF0-H1-A3_sma3nz_stddevNorm\n",
      "HNRdBACF_sma3nz_amean\n",
      "logRelF0-H1-A3_sma3nz_amean\n",
      "spectralFluxV_sma3nz_stddevNorm\n",
      "spectralFlux_sma3_stddevNorm\n",
      "F3bandwidth_sma3nz_stddevNorm\n",
      "F1frequency_sma3nz_stddevNorm\n",
      "F1frequency_sma3nz_amean\n",
      "loudness_sma3_amean\n",
      "mfcc2V_sma3nz_amean\n",
      "equivalentSoundLevel_dBp\n",
      "loudness_sma3_stddevRisingSlope\n",
      "F3bandwidth_sma3nz_amean\n",
      "jitterLocal_sma3nz_stddevNorm\n",
      "F1bandwidth_sma3nz_amean\n",
      "hammarbergIndexV_sma3nz_stddevNorm\n",
      "F1bandwidth_sma3nz_stddevNorm\n",
      "shimmerLocaldB_sma3nz_stddevNorm\n",
      "spectralFluxUV_sma3nz_amean\n",
      "slopeV0-500_sma3nz_stddevNorm\n",
      "mfcc4_sma3_stddevNorm\n",
      "spectralFlux_sma3_amean\n",
      "mfcc4V_sma3nz_stddevNorm\n",
      "loudness_sma3_pctlrange0-2\n",
      "F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope\n",
      "spectralFluxV_sma3nz_amean\n",
      "slopeUV0-500_sma3nz_amean\n",
      "F3frequency_sma3nz_amean\n",
      "loudness_sma3_percentile80.0\n",
      "mfcc4_sma3_amean\n",
      "slopeV0-500_sma3nz_amean\n",
      "loudness_sma3_meanFallingSlope\n",
      "shimmerLocaldB_sma3nz_amean\n",
      "F2frequency_sma3nz_amean\n",
      "loudness_sma3_percentile50.0\n",
      "alphaRatioUV_sma3nz_amean\n",
      "jitterLocal_sma3nz_amean\n",
      "F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope\n",
      "logRelF0-H1-H2_sma3nz_amean\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(best_features)):\n",
    "    print(best_features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the dictionary to a .pkl file\n",
    "with open('rfe_cv_res.pkl', 'wb') as f:\n",
    "    pickle.dump(rfe.cv_results_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('rfe_cv_res.pkl', 'rb') as f:\n",
    "    loaded_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False, False,  True,  True, False,  True,  True,\n",
       "       False, False,  True, False, False, False,  True,  True,  True,\n",
       "       False,  True, False, False, False,  True, False, False,  True,\n",
       "       False, False, False, False,  True,  True,  True, False, False,\n",
       "        True,  True, False,  True, False,  True, False,  True, False,\n",
       "        True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "        True, False, False, False,  True,  True, False, False,  True,\n",
       "        True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        True, False,  True, False, False,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True, False])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.cv_results_[\"n_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44138013, -0.11624642, -0.03982877,  0.00340859,  0.03527924,\n",
       "        0.0612626 ,  0.0765724 ,  0.08637663,  0.09464394,  0.0976202 ,\n",
       "        0.10024621,  0.10771391,  0.11244751,  0.11304962,  0.11636096,\n",
       "        0.11767203,  0.11788883,  0.11891165,  0.12147895,  0.12210513,\n",
       "        0.12232049,  0.12366973,  0.12534541,  0.12512421,  0.12427082,\n",
       "        0.12509166,  0.12318506,  0.12359827,  0.12326011,  0.1238168 ,\n",
       "        0.12576028,  0.12346335,  0.12581792,  0.12513828,  0.12535521,\n",
       "        0.12602032,  0.12636592,  0.1261269 ,  0.12530722,  0.12653385,\n",
       "        0.1267975 ,  0.12387767,  0.1269857 ,  0.12563726,  0.12568236,\n",
       "        0.12513053,  0.12352363,  0.12548093,  0.12427338,  0.12396972,\n",
       "        0.12692782,  0.12563017,  0.12468076,  0.123686  ,  0.12534928,\n",
       "        0.126206  ,  0.12733905,  0.12488956,  0.12419654,  0.12361957,\n",
       "        0.12461671,  0.1263063 ,  0.12360567,  0.12565025,  0.12429756,\n",
       "        0.12645115,  0.12394007,  0.12523587,  0.12515193,  0.12659154,\n",
       "        0.12607481,  0.12499764,  0.12574765,  0.12611177,  0.12600909,\n",
       "        0.1263355 ,  0.12577844,  0.12609611,  0.12536954,  0.12430252,\n",
       "        0.12553967,  0.12750254,  0.12605018,  0.12530603,  0.1251238 ,\n",
       "        0.12757798,  0.12393561,  0.12552967])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 10.0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rfe.cv_results_[\"n_features\"], rfe.cv_results_[\"mean_test_score\"])\n",
    "plt.xlim([0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26be96dda00>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rfe.cv_results_[\"n_features\"], rfe.cv_results_[\"std_test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.74195657e-01, -1.18451734e-01, -4.91463685e-02,  2.31929503e-04,\n",
       "        3.18782743e-02,  5.23717196e-02,  7.42351963e-02,  8.73866565e-02,\n",
       "        9.09584682e-02,  9.64185551e-02,  1.01519664e-01,  1.03199815e-01,\n",
       "        1.08489345e-01,  1.11769425e-01,  1.16471586e-01,  1.17828768e-01,\n",
       "        1.14839780e-01,  1.17928529e-01,  1.10979179e-01,  1.14642285e-01,\n",
       "        1.15448081e-01,  1.23530314e-01,  1.18987941e-01,  1.23342076e-01,\n",
       "        1.19451213e-01,  1.17518712e-01,  1.18200061e-01,  1.21314130e-01,\n",
       "        1.21464965e-01,  1.19325138e-01,  1.24851226e-01,  1.25304580e-01,\n",
       "        1.20044729e-01,  1.22038460e-01,  1.25660700e-01,  1.23211596e-01,\n",
       "        1.24633992e-01,  1.24975646e-01,  1.21429547e-01,  1.25940986e-01,\n",
       "        1.19838571e-01,  1.24596101e-01,  1.24249409e-01,  1.23400925e-01,\n",
       "        1.22193120e-01,  1.24618301e-01,  1.22663015e-01,  1.23282922e-01,\n",
       "        1.24014878e-01,  1.25678741e-01,  1.31899434e-01,  1.21904705e-01,\n",
       "        1.23665636e-01,  1.27429324e-01,  1.26249081e-01,  1.21998534e-01,\n",
       "        1.25146115e-01,  1.25214908e-01,  1.24256545e-01,  1.20779842e-01,\n",
       "        1.25663038e-01,  1.24021112e-01,  1.22048330e-01,  1.24853140e-01,\n",
       "        1.24610421e-01,  1.26874654e-01,  1.24901949e-01,  1.28110233e-01,\n",
       "        1.20916370e-01,  1.27215693e-01,  1.24038403e-01,  1.26090684e-01,\n",
       "        1.25348962e-01,  1.26047992e-01,  1.23821137e-01,  1.26123577e-01,\n",
       "        1.24650716e-01,  1.23588478e-01,  1.25044760e-01,  1.26494780e-01,\n",
       "        1.25772073e-01,  1.28491874e-01,  1.27394438e-01,  1.28530814e-01,\n",
       "        1.24932197e-01,  1.24540743e-01,  1.24690186e-01,  1.28580839e-01])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.cv_results_[\"split0_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.45480798, -0.09720233, -0.01814443,  0.02621143,  0.04987701,\n",
       "        0.06652962,  0.09108209,  0.0982691 ,  0.10904384,  0.11445734,\n",
       "        0.11810646,  0.12345023,  0.12776509,  0.13000955,  0.12660003,\n",
       "        0.13300817,  0.13098281,  0.13144924,  0.13207675,  0.13842994,\n",
       "        0.13989325,  0.13804086,  0.13312308,  0.13957078,  0.14017838,\n",
       "        0.13578352,  0.13148983,  0.13729817,  0.13824553,  0.13791389,\n",
       "        0.13247549,  0.13527357,  0.13602193,  0.13486358,  0.13259121,\n",
       "        0.13979286,  0.13469701,  0.13593461,  0.13100858,  0.13167654,\n",
       "        0.13375996,  0.13483356,  0.13381519,  0.13338553,  0.13143245,\n",
       "        0.13084435,  0.13078988,  0.12987952,  0.12601562,  0.12869054,\n",
       "        0.1302639 ,  0.13412515,  0.13611996,  0.13020019,  0.12983651,\n",
       "        0.13420498,  0.12856629,  0.1307063 ,  0.13267933,  0.13059165,\n",
       "        0.13181475,  0.13600207,  0.13445411,  0.13096585,  0.13545133,\n",
       "        0.1332417 ,  0.1336003 ,  0.13650454,  0.13301235,  0.1279764 ,\n",
       "        0.1315981 ,  0.13729302,  0.13314714,  0.12839215,  0.12906135,\n",
       "        0.12946376,  0.12955336,  0.12992231,  0.13263044,  0.13165178,\n",
       "        0.13435248,  0.13125969,  0.13193509,  0.13708736,  0.13417381,\n",
       "        0.13732786,  0.134652  ,  0.13504816])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.cv_results_[\"split1_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44310448, -0.1167673 , -0.04236571,  0.00596806,  0.03385576,\n",
       "        0.0592359 ,  0.07500525,  0.08680241,  0.09383613,  0.10101742,\n",
       "        0.10323303,  0.10687312,  0.10978435,  0.11397482,  0.11622926,\n",
       "        0.11651882,  0.11889568,  0.11857176,  0.11995418,  0.11971247,\n",
       "        0.1237108 ,  0.12365064,  0.12562784,  0.12591407,  0.12350052,\n",
       "        0.1248098 ,  0.12435436,  0.12320699,  0.12117064,  0.12489312,\n",
       "        0.12444244,  0.12391816,  0.12643753,  0.12495227,  0.12370454,\n",
       "        0.12558722,  0.12806881,  0.12628235,  0.12541091,  0.12609042,\n",
       "        0.1263937 ,  0.12699974,  0.12671309,  0.12453339,  0.12457002,\n",
       "        0.12560456,  0.12651321,  0.12596824,  0.12459439,  0.12536629,\n",
       "        0.12490573,  0.12668812,  0.12596708,  0.12530043,  0.12593822,\n",
       "        0.1253537 ,  0.12527921,  0.12565386,  0.12684164,  0.12537114,\n",
       "        0.12375441,  0.12375272,  0.12528576,  0.12463616,  0.1251808 ,\n",
       "        0.12324888,  0.1254296 ,  0.12313662,  0.12574103,  0.12480327,\n",
       "        0.12694202,  0.12356167,  0.12451103,  0.12624114,  0.12550235,\n",
       "        0.12512385,  0.12587708,  0.12748648,  0.12588402,  0.12610034,\n",
       "        0.12787419,  0.12467278,  0.12551678,  0.12618354,  0.12746785,\n",
       "        0.12864463,  0.12569235,  0.1253319 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.cv_results_[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36,  1, 22, 30,  1,  1, 12,  1,  1,  9, 37,  1, 11, 32, 33,  1,  1,\n",
       "        1,  5,  1, 35, 14,  7,  1, 24, 10,  1, 23, 29, 20,  4,  1,  1,  1,\n",
       "       28, 19,  1,  1, 17,  1, 16,  1,  2,  1, 27,  1,  1,  1,  1,  1, 38,\n",
       "       31,  1,  1,  1, 18, 34, 15,  1,  1, 21, 13,  1,  1,  1,  1,  8,  1,\n",
       "        1,  1,  1,  1,  1,  3,  1,  6, 25,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, 26])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F0semitoneFrom27.5Hz_sma3nz_stddevNorm\n",
      "F0semitoneFrom27.5Hz_sma3nz_percentile80.0\n",
      "F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2\n",
      "F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope\n",
      "F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope\n",
      "loudness_sma3_stddevNorm\n",
      "loudness_sma3_pctlrange0-2\n",
      "loudness_sma3_meanRisingSlope\n",
      "loudness_sma3_stddevRisingSlope\n",
      "loudness_sma3_stddevFallingSlope\n",
      "mfcc1_sma3_stddevNorm\n",
      "mfcc3_sma3_amean\n",
      "jitterLocal_sma3nz_stddevNorm\n",
      "shimmerLocaldB_sma3nz_amean\n",
      "shimmerLocaldB_sma3nz_stddevNorm\n",
      "logRelF0-H1-H2_sma3nz_amean\n",
      "logRelF0-H1-H2_sma3nz_stddevNorm\n",
      "logRelF0-H1-A3_sma3nz_stddevNorm\n",
      "F1frequency_sma3nz_stddevNorm\n",
      "F1bandwidth_sma3nz_stddevNorm\n",
      "F1amplitudeLogRelF0_sma3nz_stddevNorm\n",
      "F2frequency_sma3nz_amean\n",
      "F2frequency_sma3nz_stddevNorm\n",
      "F2bandwidth_sma3nz_amean\n",
      "F2bandwidth_sma3nz_stddevNorm\n",
      "F3frequency_sma3nz_amean\n",
      "F3frequency_sma3nz_stddevNorm\n",
      "F3bandwidth_sma3nz_amean\n",
      "alphaRatioV_sma3nz_amean\n",
      "alphaRatioV_sma3nz_stddevNorm\n",
      "slopeV0-500_sma3nz_amean\n",
      "slopeV0-500_sma3nz_stddevNorm\n",
      "slopeV500-1500_sma3nz_amean\n",
      "slopeV500-1500_sma3nz_stddevNorm\n",
      "spectralFluxV_sma3nz_stddevNorm\n",
      "mfcc1V_sma3nz_amean\n",
      "mfcc1V_sma3nz_stddevNorm\n",
      "mfcc2V_sma3nz_amean\n",
      "mfcc2V_sma3nz_stddevNorm\n",
      "mfcc3V_sma3nz_amean\n",
      "mfcc4V_sma3nz_amean\n",
      "hammarbergIndexUV_sma3nz_amean\n",
      "slopeUV0-500_sma3nz_amean\n",
      "slopeUV500-1500_sma3nz_amean\n",
      "spectralFluxUV_sma3nz_amean\n",
      "loudnessPeaksPerSec\n",
      "VoicedSegmentsPerSec\n",
      "MeanVoicedSegmentLengthSec\n",
      "StddevVoicedSegmentLengthSec\n",
      "MeanUnvoicedSegmentLength\n",
      "StddevUnvoicedSegmentLength\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "features = X_train.columns.to_list()\n",
    "best_features_rfe = []\n",
    "for x, y in (sorted(zip(rfe.ranking_ , features), key=itemgetter(0))):\n",
    "    if x == 1:\n",
    "        print(y)\n",
    "        best_features_rfe.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mfcc1_sma3_stddevNorm',\n",
       " 'MeanVoicedSegmentLengthSec',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_percentile80.0',\n",
       " 'StddevVoicedSegmentLengthSec',\n",
       " 'mfcc1_sma3_amean',\n",
       " 'alphaRatioV_sma3nz_amean',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_percentile50.0',\n",
       " 'F3amplitudeLogRelF0_sma3nz_amean',\n",
       " 'mfcc1V_sma3nz_amean']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F0semitoneFrom27.5Hz_sma3nz_amean',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_stddevNorm',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_percentile20.0',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_percentile50.0',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_percentile80.0',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_pctlrange0-2',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_meanRisingSlope',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_stddevRisingSlope',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_meanFallingSlope',\n",
       " 'F0semitoneFrom27.5Hz_sma3nz_stddevFallingSlope']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features_rfe[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_n, Y, test_size=0.1, random_state=22)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4095</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">171,990</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,388,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4095\u001b[0m)           │       \u001b[38;5;34m171,990\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │     \u001b[38;5;34m8,388,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,358,398</span> (43.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,358,398\u001b[0m (43.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,358,398</span> (43.33 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,358,398\u001b[0m (43.33 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1557 - loss: 24.8528\n",
      "Epoch 1: val_loss improved from inf to 2.21370, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 31ms/step - accuracy: 0.1557 - loss: 24.7031 - val_accuracy: 0.1094 - val_loss: 2.2137\n",
      "Epoch 2/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1406 - loss: 2.2304\n",
      "Epoch 2: val_loss improved from 2.21370 to 2.02475, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.1407 - loss: 2.2389 - val_accuracy: 0.1489 - val_loss: 2.0247\n",
      "Epoch 3/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1541 - loss: 2.0778\n",
      "Epoch 3: val_loss improved from 2.02475 to 2.02292, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.1541 - loss: 2.0787 - val_accuracy: 0.1523 - val_loss: 2.0229\n",
      "Epoch 4/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1576 - loss: 2.0369\n",
      "Epoch 4: val_loss improved from 2.02292 to 2.00456, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.1577 - loss: 2.0368 - val_accuracy: 0.1667 - val_loss: 2.0046\n",
      "Epoch 5/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1729 - loss: 2.0195\n",
      "Epoch 5: val_loss did not improve from 2.00456\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.1729 - loss: 2.0195 - val_accuracy: 0.1604 - val_loss: 2.0284\n",
      "Epoch 6/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1683 - loss: 2.0422\n",
      "Epoch 6: val_loss did not improve from 2.00456\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.1683 - loss: 2.0421 - val_accuracy: 0.1724 - val_loss: 2.0093\n",
      "Epoch 7/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1744 - loss: 2.0219\n",
      "Epoch 7: val_loss did not improve from 2.00456\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.1744 - loss: 2.0219 - val_accuracy: 0.1758 - val_loss: 2.0073\n",
      "Epoch 8/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1804 - loss: 2.0151\n",
      "Epoch 8: val_loss improved from 2.00456 to 2.00381, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.1804 - loss: 2.0151 - val_accuracy: 0.1747 - val_loss: 2.0038\n",
      "Epoch 9/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1812 - loss: 2.0144\n",
      "Epoch 9: val_loss did not improve from 2.00381\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1812 - loss: 2.0144 - val_accuracy: 0.1753 - val_loss: 2.0076\n",
      "Epoch 10/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1895 - loss: 2.0098\n",
      "Epoch 10: val_loss improved from 2.00381 to 1.99849, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.1894 - loss: 2.0098 - val_accuracy: 0.1758 - val_loss: 1.9985\n",
      "Epoch 11/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1676 - loss: 2.0142\n",
      "Epoch 11: val_loss improved from 1.99849 to 1.99754, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.1676 - loss: 2.0142 - val_accuracy: 0.1741 - val_loss: 1.9975\n",
      "Epoch 12/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1887 - loss: 2.0033\n",
      "Epoch 12: val_loss improved from 1.99754 to 1.99332, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.1886 - loss: 2.0034 - val_accuracy: 0.1764 - val_loss: 1.9933\n",
      "Epoch 13/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1830 - loss: 2.0109\n",
      "Epoch 13: val_loss did not improve from 1.99332\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.1830 - loss: 2.0109 - val_accuracy: 0.1741 - val_loss: 1.9937\n",
      "Epoch 14/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1834 - loss: 2.0077\n",
      "Epoch 14: val_loss did not improve from 1.99332\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1835 - loss: 2.0077 - val_accuracy: 0.1787 - val_loss: 1.9935\n",
      "Epoch 15/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1781 - loss: 2.0120\n",
      "Epoch 15: val_loss improved from 1.99332 to 1.98977, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.1781 - loss: 2.0120 - val_accuracy: 0.1770 - val_loss: 1.9898\n",
      "Epoch 16/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1926 - loss: 2.0042\n",
      "Epoch 16: val_loss did not improve from 1.98977\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1925 - loss: 2.0042 - val_accuracy: 0.1816 - val_loss: 1.9935\n",
      "Epoch 17/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1880 - loss: 2.0106\n",
      "Epoch 17: val_loss did not improve from 1.98977\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1880 - loss: 2.0106 - val_accuracy: 0.1787 - val_loss: 1.9914\n",
      "Epoch 18/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1878 - loss: 2.0078\n",
      "Epoch 18: val_loss improved from 1.98977 to 1.98714, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.1878 - loss: 2.0078 - val_accuracy: 0.1879 - val_loss: 1.9871\n",
      "Epoch 19/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1859 - loss: 2.0164\n",
      "Epoch 19: val_loss did not improve from 1.98714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.1858 - loss: 2.0164 - val_accuracy: 0.1884 - val_loss: 1.9931\n",
      "Epoch 20/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1798 - loss: 2.0130\n",
      "Epoch 20: val_loss did not improve from 1.98714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.1798 - loss: 2.0130 - val_accuracy: 0.1718 - val_loss: 2.0006\n",
      "Epoch 21/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1778 - loss: 2.0217\n",
      "Epoch 21: val_loss did not improve from 1.98714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1778 - loss: 2.0217 - val_accuracy: 0.1890 - val_loss: 1.9966\n",
      "Epoch 22/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1851 - loss: 2.0174\n",
      "Epoch 22: val_loss did not improve from 1.98714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 30ms/step - accuracy: 0.1851 - loss: 2.0174 - val_accuracy: 0.1907 - val_loss: 1.9907\n",
      "Epoch 23/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1896 - loss: 2.0195\n",
      "Epoch 23: val_loss did not improve from 1.98714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.1896 - loss: 2.0201 - val_accuracy: 0.1718 - val_loss: 2.0077\n",
      "Epoch 24/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1913 - loss: 2.0033\n",
      "Epoch 24: val_loss did not improve from 1.98714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.1914 - loss: 2.0034 - val_accuracy: 0.1896 - val_loss: 1.9962\n",
      "Epoch 25/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1989 - loss: 2.0059\n",
      "Epoch 25: val_loss did not improve from 1.98714\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.1989 - loss: 2.0058 - val_accuracy: 0.1661 - val_loss: 2.0183\n",
      "Epoch 26/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2036 - loss: 2.0042\n",
      "Epoch 26: val_loss improved from 1.98714 to 1.98248, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.2036 - loss: 2.0042 - val_accuracy: 0.1976 - val_loss: 1.9825\n",
      "Epoch 27/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2222 - loss: 2.0089\n",
      "Epoch 27: val_loss did not improve from 1.98248\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2221 - loss: 2.0090 - val_accuracy: 0.2062 - val_loss: 1.9866\n",
      "Epoch 28/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2125 - loss: 1.9961\n",
      "Epoch 28: val_loss improved from 1.98248 to 1.97568, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.2125 - loss: 1.9961 - val_accuracy: 0.2176 - val_loss: 1.9757\n",
      "Epoch 29/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2101 - loss: 1.9975\n",
      "Epoch 29: val_loss improved from 1.97568 to 1.97107, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.2101 - loss: 1.9975 - val_accuracy: 0.2205 - val_loss: 1.9711\n",
      "Epoch 30/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2305 - loss: 2.0803\n",
      "Epoch 30: val_loss improved from 1.97107 to 1.96501, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.2305 - loss: 2.0801 - val_accuracy: 0.2090 - val_loss: 1.9650\n",
      "Epoch 31/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2160 - loss: 1.9836\n",
      "Epoch 31: val_loss improved from 1.96501 to 1.96305, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.2160 - loss: 1.9836 - val_accuracy: 0.2257 - val_loss: 1.9630\n",
      "Epoch 32/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2285 - loss: 1.9731\n",
      "Epoch 32: val_loss did not improve from 1.96305\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.2285 - loss: 1.9731 - val_accuracy: 0.2153 - val_loss: 1.9646\n",
      "Epoch 33/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2146 - loss: 1.9827\n",
      "Epoch 33: val_loss did not improve from 1.96305\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2147 - loss: 1.9827 - val_accuracy: 0.2320 - val_loss: 1.9653\n",
      "Epoch 34/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2237 - loss: 1.9762\n",
      "Epoch 34: val_loss improved from 1.96305 to 1.95724, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 36ms/step - accuracy: 0.2237 - loss: 1.9762 - val_accuracy: 0.2234 - val_loss: 1.9572\n",
      "Epoch 35/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2286 - loss: 1.9743\n",
      "Epoch 35: val_loss did not improve from 1.95724\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2286 - loss: 1.9743 - val_accuracy: 0.2216 - val_loss: 1.9684\n",
      "Epoch 36/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2361 - loss: 1.9662\n",
      "Epoch 36: val_loss did not improve from 1.95724\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2361 - loss: 1.9662 - val_accuracy: 0.2142 - val_loss: 1.9701\n",
      "Epoch 37/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2312 - loss: 1.9633\n",
      "Epoch 37: val_loss improved from 1.95724 to 1.95587, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.2312 - loss: 1.9634 - val_accuracy: 0.2176 - val_loss: 1.9559\n",
      "Epoch 38/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2362 - loss: 1.9567\n",
      "Epoch 38: val_loss improved from 1.95587 to 1.95476, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2362 - loss: 1.9568 - val_accuracy: 0.2119 - val_loss: 1.9548\n",
      "Epoch 39/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2300 - loss: 2.0055\n",
      "Epoch 39: val_loss did not improve from 1.95476\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2301 - loss: 2.0052 - val_accuracy: 0.2148 - val_loss: 1.9608\n",
      "Epoch 40/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2334 - loss: 1.9614\n",
      "Epoch 40: val_loss did not improve from 1.95476\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2334 - loss: 1.9614 - val_accuracy: 0.2102 - val_loss: 1.9827\n",
      "Epoch 41/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2315 - loss: 1.9698\n",
      "Epoch 41: val_loss improved from 1.95476 to 1.95242, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.2316 - loss: 1.9698 - val_accuracy: 0.2131 - val_loss: 1.9524\n",
      "Epoch 42/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2383 - loss: 1.9528\n",
      "Epoch 42: val_loss did not improve from 1.95242\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2383 - loss: 1.9528 - val_accuracy: 0.2205 - val_loss: 1.9663\n",
      "Epoch 43/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2394 - loss: 1.9666\n",
      "Epoch 43: val_loss did not improve from 1.95242\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2394 - loss: 1.9665 - val_accuracy: 0.2194 - val_loss: 1.9607\n",
      "Epoch 44/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2268 - loss: 1.9730\n",
      "Epoch 44: val_loss did not improve from 1.95242\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2269 - loss: 1.9729 - val_accuracy: 0.2142 - val_loss: 1.9648\n",
      "Epoch 45/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2282 - loss: 1.9730\n",
      "Epoch 45: val_loss improved from 1.95242 to 1.95232, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.2282 - loss: 1.9730 - val_accuracy: 0.2119 - val_loss: 1.9523\n",
      "Epoch 46/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2416 - loss: 1.9575\n",
      "Epoch 46: val_loss improved from 1.95232 to 1.94891, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.2417 - loss: 1.9574 - val_accuracy: 0.2194 - val_loss: 1.9489\n",
      "Epoch 47/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2472 - loss: 1.9484\n",
      "Epoch 47: val_loss did not improve from 1.94891\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2471 - loss: 1.9484 - val_accuracy: 0.2165 - val_loss: 1.9569\n",
      "Epoch 48/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2406 - loss: 1.9470\n",
      "Epoch 48: val_loss did not improve from 1.94891\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2406 - loss: 1.9471 - val_accuracy: 0.2102 - val_loss: 1.9711\n",
      "Epoch 49/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2393 - loss: 1.9576\n",
      "Epoch 49: val_loss did not improve from 1.94891\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2392 - loss: 1.9576 - val_accuracy: 0.2148 - val_loss: 1.9527\n",
      "Epoch 50/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2328 - loss: 1.9526\n",
      "Epoch 50: val_loss did not improve from 1.94891\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2328 - loss: 1.9526 - val_accuracy: 0.2159 - val_loss: 1.9555\n",
      "Epoch 51/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2416 - loss: 1.9521\n",
      "Epoch 51: val_loss did not improve from 1.94891\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2416 - loss: 1.9521 - val_accuracy: 0.2136 - val_loss: 1.9659\n",
      "Epoch 52/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2468 - loss: 1.9538\n",
      "Epoch 52: val_loss did not improve from 1.94891\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2467 - loss: 1.9538 - val_accuracy: 0.2153 - val_loss: 1.9504\n",
      "Epoch 53/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2470 - loss: 1.9514\n",
      "Epoch 53: val_loss did not improve from 1.94891\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2469 - loss: 1.9514 - val_accuracy: 0.2125 - val_loss: 1.9582\n",
      "Epoch 54/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2414 - loss: 1.9491\n",
      "Epoch 54: val_loss did not improve from 1.94891\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2414 - loss: 1.9491 - val_accuracy: 0.2125 - val_loss: 1.9518\n",
      "Epoch 55/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2304 - loss: 2.0334\n",
      "Epoch 55: val_loss did not improve from 1.94891\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2305 - loss: 2.0333 - val_accuracy: 0.2153 - val_loss: 1.9567\n",
      "Epoch 56/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2339 - loss: 1.9679\n",
      "Epoch 56: val_loss improved from 1.94891 to 1.94756, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 34ms/step - accuracy: 0.2339 - loss: 1.9679 - val_accuracy: 0.2085 - val_loss: 1.9476\n",
      "Epoch 57/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2497 - loss: 1.9454\n",
      "Epoch 57: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.2495 - loss: 1.9455 - val_accuracy: 0.2131 - val_loss: 1.9673\n",
      "Epoch 58/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2502 - loss: 1.9464\n",
      "Epoch 58: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2501 - loss: 1.9464 - val_accuracy: 0.2142 - val_loss: 1.9507\n",
      "Epoch 59/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2373 - loss: 1.9454\n",
      "Epoch 59: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2373 - loss: 1.9454 - val_accuracy: 0.2199 - val_loss: 1.9565\n",
      "Epoch 60/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2431 - loss: 1.9448\n",
      "Epoch 60: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2431 - loss: 1.9449 - val_accuracy: 0.2096 - val_loss: 1.9760\n",
      "Epoch 61/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2283 - loss: 1.9659\n",
      "Epoch 61: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2284 - loss: 1.9657 - val_accuracy: 0.2165 - val_loss: 1.9612\n",
      "Epoch 62/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2345 - loss: 1.9914\n",
      "Epoch 62: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2345 - loss: 1.9913 - val_accuracy: 0.2199 - val_loss: 1.9509\n",
      "Epoch 63/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2400 - loss: 1.9543\n",
      "Epoch 63: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2400 - loss: 1.9542 - val_accuracy: 0.2153 - val_loss: 1.9498\n",
      "Epoch 64/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2471 - loss: 1.9457\n",
      "Epoch 64: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2471 - loss: 1.9457 - val_accuracy: 0.2159 - val_loss: 1.9491\n",
      "Epoch 65/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2299 - loss: 1.9563\n",
      "Epoch 65: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2300 - loss: 1.9562 - val_accuracy: 0.2165 - val_loss: 1.9509\n",
      "Epoch 66/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2477 - loss: 1.9416\n",
      "Epoch 66: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2477 - loss: 1.9417 - val_accuracy: 0.2148 - val_loss: 1.9691\n",
      "Epoch 67/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2352 - loss: 1.9548\n",
      "Epoch 67: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2353 - loss: 1.9547 - val_accuracy: 0.2125 - val_loss: 1.9630\n",
      "Epoch 68/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2394 - loss: 1.9495\n",
      "Epoch 68: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2394 - loss: 1.9495 - val_accuracy: 0.2142 - val_loss: 1.9516\n",
      "Epoch 69/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2380 - loss: 1.9495\n",
      "Epoch 69: val_loss did not improve from 1.94756\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2380 - loss: 1.9494 - val_accuracy: 0.2205 - val_loss: 1.9487\n",
      "Epoch 70/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2408 - loss: 1.9516\n",
      "Epoch 70: val_loss improved from 1.94756 to 1.94516, saving model to model/SER_DEMoS_41feat_05_11_2024_14_39_34.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.2408 - loss: 1.9516 - val_accuracy: 0.2176 - val_loss: 1.9452\n",
      "Epoch 71/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2376 - loss: 1.9546\n",
      "Epoch 71: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2375 - loss: 1.9546 - val_accuracy: 0.2136 - val_loss: 1.9566\n",
      "Epoch 72/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2508 - loss: 1.9422\n",
      "Epoch 72: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2507 - loss: 1.9423 - val_accuracy: 0.2136 - val_loss: 1.9590\n",
      "Epoch 73/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2405 - loss: 1.9526\n",
      "Epoch 73: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2406 - loss: 1.9526 - val_accuracy: 0.2239 - val_loss: 1.9558\n",
      "Epoch 74/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2441 - loss: 1.9540\n",
      "Epoch 74: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2440 - loss: 1.9539 - val_accuracy: 0.1993 - val_loss: 1.9745\n",
      "Epoch 75/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2390 - loss: 1.9521\n",
      "Epoch 75: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2390 - loss: 1.9520 - val_accuracy: 0.2199 - val_loss: 1.9471\n",
      "Epoch 76/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2326 - loss: 1.9508\n",
      "Epoch 76: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2326 - loss: 1.9508 - val_accuracy: 0.2171 - val_loss: 1.9514\n",
      "Epoch 77/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2366 - loss: 1.9531\n",
      "Epoch 77: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2366 - loss: 1.9530 - val_accuracy: 0.2085 - val_loss: 1.9555\n",
      "Epoch 78/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2431 - loss: 1.9542\n",
      "Epoch 78: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2431 - loss: 1.9541 - val_accuracy: 0.2205 - val_loss: 1.9482\n",
      "Epoch 79/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2489 - loss: 1.9458\n",
      "Epoch 79: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2489 - loss: 1.9458 - val_accuracy: 0.2159 - val_loss: 1.9460\n",
      "Epoch 80/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2367 - loss: 1.9497\n",
      "Epoch 80: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2368 - loss: 1.9497 - val_accuracy: 0.2211 - val_loss: 1.9599\n",
      "Epoch 81/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2386 - loss: 1.9556\n",
      "Epoch 81: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2387 - loss: 1.9555 - val_accuracy: 0.2102 - val_loss: 1.9510\n",
      "Epoch 82/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2313 - loss: 1.9478\n",
      "Epoch 82: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2314 - loss: 1.9478 - val_accuracy: 0.2165 - val_loss: 1.9578\n",
      "Epoch 83/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2470 - loss: 1.9449\n",
      "Epoch 83: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2469 - loss: 1.9449 - val_accuracy: 0.2171 - val_loss: 1.9658\n",
      "Epoch 84/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2373 - loss: 1.9448\n",
      "Epoch 84: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.2374 - loss: 1.9448 - val_accuracy: 0.2142 - val_loss: 1.9501\n",
      "Epoch 85/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2406 - loss: 1.9501\n",
      "Epoch 85: val_loss did not improve from 1.94516\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.2406 - loss: 1.9500 - val_accuracy: 0.2102 - val_loss: 1.9525\n",
      "Epoch 85: early stopping\n",
      "Restoring model weights from the end of the best epoch: 70.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2266 - loss: 1.9553\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2266 - loss: 1.9553\n",
      "Loss : 1.9719300270080566, Accuracy : 0.23298968374729156\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"model/SER_DEMoS_41feat_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=15,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "model = get_cnn((X_train.shape[1:]))\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=32,\n",
    "                       epochs=1000,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {model.evaluate(X_test,y_test)[0]}, Accuracy : {model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "def get_model(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    encoder = layers.LSTM(256)(inputs)\n",
    "    drop = layers.Dropout(0.3)(encoder)\n",
    "    hidden1 = layers.Dense(128, activation='relu')(drop)\n",
    "\n",
    "    hidden2 = layers.Dense(64, activation='relu')(hidden1)\n",
    "    hidden = layers.Dense(32, activation='relu')(hidden2)\n",
    "    outputs = layers.Dense(8, activation='softmax')(hidden)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.expand_dims(X_n,axis=2), Y, test_size=0.1, random_state=22)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">264,192</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m264,192\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">307,688</span> (1.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m307,688\u001b[0m (1.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">307,688</span> (1.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m307,688\u001b[0m (1.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1461 - loss: 2.0392\n",
      "Epoch 1: val_loss improved from inf to 2.00979, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.1463 - loss: 2.0391 - val_accuracy: 0.1569 - val_loss: 2.0098\n",
      "Epoch 2/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1668 - loss: 2.0234\n",
      "Epoch 2: val_loss did not improve from 2.00979\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.1669 - loss: 2.0233 - val_accuracy: 0.1690 - val_loss: 2.0207\n",
      "Epoch 3/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1786 - loss: 2.0128\n",
      "Epoch 3: val_loss improved from 2.00979 to 1.99227, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.1785 - loss: 2.0128 - val_accuracy: 0.1924 - val_loss: 1.9923\n",
      "Epoch 4/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1739 - loss: 2.0148\n",
      "Epoch 4: val_loss improved from 1.99227 to 1.96622, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.1740 - loss: 2.0147 - val_accuracy: 0.1936 - val_loss: 1.9662\n",
      "Epoch 5/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1965 - loss: 1.9868\n",
      "Epoch 5: val_loss did not improve from 1.96622\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.1965 - loss: 1.9868 - val_accuracy: 0.1982 - val_loss: 1.9774\n",
      "Epoch 6/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2020 - loss: 1.9801\n",
      "Epoch 6: val_loss improved from 1.96622 to 1.96368, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2020 - loss: 1.9800 - val_accuracy: 0.1953 - val_loss: 1.9637\n",
      "Epoch 7/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2034 - loss: 1.9667\n",
      "Epoch 7: val_loss improved from 1.96368 to 1.96038, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2034 - loss: 1.9667 - val_accuracy: 0.2148 - val_loss: 1.9604\n",
      "Epoch 8/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2101 - loss: 1.9559\n",
      "Epoch 8: val_loss improved from 1.96038 to 1.91865, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2102 - loss: 1.9559 - val_accuracy: 0.2463 - val_loss: 1.9186\n",
      "Epoch 9/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2242 - loss: 1.9338\n",
      "Epoch 9: val_loss improved from 1.91865 to 1.91781, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.2242 - loss: 1.9340 - val_accuracy: 0.2549 - val_loss: 1.9178\n",
      "Epoch 10/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2142 - loss: 1.9362\n",
      "Epoch 10: val_loss did not improve from 1.91781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2143 - loss: 1.9362 - val_accuracy: 0.2451 - val_loss: 1.9248\n",
      "Epoch 11/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2509 - loss: 1.9153\n",
      "Epoch 11: val_loss did not improve from 1.91781\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2508 - loss: 1.9153 - val_accuracy: 0.2463 - val_loss: 1.9271\n",
      "Epoch 12/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2390 - loss: 1.9129\n",
      "Epoch 12: val_loss improved from 1.91781 to 1.90377, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2390 - loss: 1.9128 - val_accuracy: 0.2629 - val_loss: 1.9038\n",
      "Epoch 13/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2359 - loss: 1.9059\n",
      "Epoch 13: val_loss did not improve from 1.90377\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2359 - loss: 1.9059 - val_accuracy: 0.2428 - val_loss: 1.9201\n",
      "Epoch 14/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2497 - loss: 1.8979\n",
      "Epoch 14: val_loss did not improve from 1.90377\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2496 - loss: 1.8980 - val_accuracy: 0.2251 - val_loss: 1.9289\n",
      "Epoch 15/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2507 - loss: 1.8983\n",
      "Epoch 15: val_loss improved from 1.90377 to 1.90145, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2508 - loss: 1.8982 - val_accuracy: 0.2709 - val_loss: 1.9015\n",
      "Epoch 16/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2642 - loss: 1.8926\n",
      "Epoch 16: val_loss improved from 1.90145 to 1.88632, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.2641 - loss: 1.8926 - val_accuracy: 0.2663 - val_loss: 1.8863\n",
      "Epoch 17/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2539 - loss: 1.8781\n",
      "Epoch 17: val_loss did not improve from 1.88632\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2540 - loss: 1.8781 - val_accuracy: 0.2554 - val_loss: 1.8991\n",
      "Epoch 18/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2725 - loss: 1.8626\n",
      "Epoch 18: val_loss did not improve from 1.88632\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.2724 - loss: 1.8628 - val_accuracy: 0.2887 - val_loss: 1.8878\n",
      "Epoch 19/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2678 - loss: 1.8685\n",
      "Epoch 19: val_loss improved from 1.88632 to 1.87505, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.2678 - loss: 1.8685 - val_accuracy: 0.2761 - val_loss: 1.8750\n",
      "Epoch 20/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2629 - loss: 1.8698\n",
      "Epoch 20: val_loss did not improve from 1.87505\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.2630 - loss: 1.8697 - val_accuracy: 0.2480 - val_loss: 1.8837\n",
      "Epoch 21/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2789 - loss: 1.8405\n",
      "Epoch 21: val_loss improved from 1.87505 to 1.85001, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2789 - loss: 1.8407 - val_accuracy: 0.2864 - val_loss: 1.8500\n",
      "Epoch 22/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2926 - loss: 1.8194\n",
      "Epoch 22: val_loss improved from 1.85001 to 1.83917, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.2926 - loss: 1.8194 - val_accuracy: 0.2978 - val_loss: 1.8392\n",
      "Epoch 23/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2861 - loss: 1.8253\n",
      "Epoch 23: val_loss did not improve from 1.83917\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.2862 - loss: 1.8252 - val_accuracy: 0.2738 - val_loss: 1.8491\n",
      "Epoch 24/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.2973 - loss: 1.8097\n",
      "Epoch 24: val_loss did not improve from 1.83917\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.2974 - loss: 1.8095 - val_accuracy: 0.2801 - val_loss: 1.8423\n",
      "Epoch 25/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3134 - loss: 1.7753\n",
      "Epoch 25: val_loss improved from 1.83917 to 1.80365, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.3135 - loss: 1.7753 - val_accuracy: 0.3053 - val_loss: 1.8037\n",
      "Epoch 26/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3301 - loss: 1.7573\n",
      "Epoch 26: val_loss improved from 1.80365 to 1.78845, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.3301 - loss: 1.7573 - val_accuracy: 0.3133 - val_loss: 1.7885\n",
      "Epoch 27/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3216 - loss: 1.7643\n",
      "Epoch 27: val_loss improved from 1.78845 to 1.78318, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.3216 - loss: 1.7642 - val_accuracy: 0.3173 - val_loss: 1.7832\n",
      "Epoch 28/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3392 - loss: 1.7149\n",
      "Epoch 28: val_loss improved from 1.78318 to 1.77884, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.3391 - loss: 1.7149 - val_accuracy: 0.3213 - val_loss: 1.7788\n",
      "Epoch 29/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3327 - loss: 1.7238\n",
      "Epoch 29: val_loss improved from 1.77884 to 1.75671, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.3327 - loss: 1.7237 - val_accuracy: 0.3190 - val_loss: 1.7567\n",
      "Epoch 30/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3447 - loss: 1.6963\n",
      "Epoch 30: val_loss did not improve from 1.75671\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.3448 - loss: 1.6964 - val_accuracy: 0.3265 - val_loss: 1.7753\n",
      "Epoch 31/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3648 - loss: 1.6663\n",
      "Epoch 31: val_loss did not improve from 1.75671\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.3646 - loss: 1.6666 - val_accuracy: 0.3225 - val_loss: 1.7608\n",
      "Epoch 32/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3608 - loss: 1.6715\n",
      "Epoch 32: val_loss did not improve from 1.75671\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.3609 - loss: 1.6716 - val_accuracy: 0.3276 - val_loss: 1.7627\n",
      "Epoch 33/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3589 - loss: 1.6514\n",
      "Epoch 33: val_loss did not improve from 1.75671\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.3589 - loss: 1.6516 - val_accuracy: 0.3127 - val_loss: 1.8012\n",
      "Epoch 34/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3540 - loss: 1.6847\n",
      "Epoch 34: val_loss improved from 1.75671 to 1.75348, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.3541 - loss: 1.6844 - val_accuracy: 0.3345 - val_loss: 1.7535\n",
      "Epoch 35/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3727 - loss: 1.6453\n",
      "Epoch 35: val_loss did not improve from 1.75348\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.3727 - loss: 1.6454 - val_accuracy: 0.3379 - val_loss: 1.7805\n",
      "Epoch 36/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3652 - loss: 1.6500\n",
      "Epoch 36: val_loss improved from 1.75348 to 1.74749, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.3653 - loss: 1.6499 - val_accuracy: 0.3299 - val_loss: 1.7475\n",
      "Epoch 37/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3825 - loss: 1.6205\n",
      "Epoch 37: val_loss did not improve from 1.74749\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.3825 - loss: 1.6206 - val_accuracy: 0.3288 - val_loss: 1.7673\n",
      "Epoch 38/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3903 - loss: 1.6102\n",
      "Epoch 38: val_loss improved from 1.74749 to 1.74020, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.3902 - loss: 1.6103 - val_accuracy: 0.3545 - val_loss: 1.7402\n",
      "Epoch 39/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3986 - loss: 1.6008\n",
      "Epoch 39: val_loss did not improve from 1.74020\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.3986 - loss: 1.6008 - val_accuracy: 0.3345 - val_loss: 1.7723\n",
      "Epoch 40/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3893 - loss: 1.5984\n",
      "Epoch 40: val_loss improved from 1.74020 to 1.72054, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.3893 - loss: 1.5984 - val_accuracy: 0.3574 - val_loss: 1.7205\n",
      "Epoch 41/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4025 - loss: 1.5654\n",
      "Epoch 41: val_loss did not improve from 1.72054\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4024 - loss: 1.5657 - val_accuracy: 0.3408 - val_loss: 1.7373\n",
      "Epoch 42/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4015 - loss: 1.5580\n",
      "Epoch 42: val_loss did not improve from 1.72054\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4015 - loss: 1.5583 - val_accuracy: 0.3517 - val_loss: 1.7336\n",
      "Epoch 43/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4132 - loss: 1.5383\n",
      "Epoch 43: val_loss did not improve from 1.72054\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4131 - loss: 1.5385 - val_accuracy: 0.3505 - val_loss: 1.7425\n",
      "Epoch 44/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4218 - loss: 1.5387\n",
      "Epoch 44: val_loss improved from 1.72054 to 1.71913, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.4217 - loss: 1.5388 - val_accuracy: 0.3597 - val_loss: 1.7191\n",
      "Epoch 45/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4207 - loss: 1.5208\n",
      "Epoch 45: val_loss did not improve from 1.71913\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.4207 - loss: 1.5210 - val_accuracy: 0.3414 - val_loss: 1.7798\n",
      "Epoch 46/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4274 - loss: 1.5254\n",
      "Epoch 46: val_loss did not improve from 1.71913\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.4274 - loss: 1.5254 - val_accuracy: 0.3562 - val_loss: 1.7474\n",
      "Epoch 47/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4244 - loss: 1.5166\n",
      "Epoch 47: val_loss improved from 1.71913 to 1.70918, saving model to model/lstm_28_feat_05_11_2024_11_45_26.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4244 - loss: 1.5166 - val_accuracy: 0.3625 - val_loss: 1.7092\n",
      "Epoch 48/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4466 - loss: 1.4846\n",
      "Epoch 48: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4465 - loss: 1.4847 - val_accuracy: 0.3666 - val_loss: 1.7408\n",
      "Epoch 49/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4359 - loss: 1.4890\n",
      "Epoch 49: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4358 - loss: 1.4891 - val_accuracy: 0.3608 - val_loss: 1.7602\n",
      "Epoch 50/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4264 - loss: 1.5173\n",
      "Epoch 50: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4266 - loss: 1.5169 - val_accuracy: 0.3597 - val_loss: 1.7365\n",
      "Epoch 51/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4604 - loss: 1.4576\n",
      "Epoch 51: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4603 - loss: 1.4578 - val_accuracy: 0.3666 - val_loss: 1.7335\n",
      "Epoch 52/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4498 - loss: 1.4572\n",
      "Epoch 52: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.4498 - loss: 1.4572 - val_accuracy: 0.3425 - val_loss: 1.8030\n",
      "Epoch 53/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4538 - loss: 1.4560\n",
      "Epoch 53: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.4538 - loss: 1.4560 - val_accuracy: 0.3660 - val_loss: 1.7602\n",
      "Epoch 54/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4622 - loss: 1.4353\n",
      "Epoch 54: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.4622 - loss: 1.4352 - val_accuracy: 0.3729 - val_loss: 1.7505\n",
      "Epoch 55/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4667 - loss: 1.4034\n",
      "Epoch 55: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.4667 - loss: 1.4035 - val_accuracy: 0.3763 - val_loss: 1.7483\n",
      "Epoch 56/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4822 - loss: 1.3910\n",
      "Epoch 56: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.4819 - loss: 1.3914 - val_accuracy: 0.3729 - val_loss: 1.7191\n",
      "Epoch 57/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4736 - loss: 1.4039\n",
      "Epoch 57: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.4735 - loss: 1.4041 - val_accuracy: 0.3803 - val_loss: 1.7130\n",
      "Epoch 58/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4863 - loss: 1.3672\n",
      "Epoch 58: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.4862 - loss: 1.3675 - val_accuracy: 0.3774 - val_loss: 1.7324\n",
      "Epoch 59/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4922 - loss: 1.3697\n",
      "Epoch 59: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.4921 - loss: 1.3698 - val_accuracy: 0.3843 - val_loss: 1.7459\n",
      "Epoch 60/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4860 - loss: 1.3620\n",
      "Epoch 60: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.4859 - loss: 1.3622 - val_accuracy: 0.3763 - val_loss: 1.7746\n",
      "Epoch 61/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4849 - loss: 1.3644\n",
      "Epoch 61: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.4850 - loss: 1.3643 - val_accuracy: 0.3711 - val_loss: 1.8242\n",
      "Epoch 62/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4909 - loss: 1.3692\n",
      "Epoch 62: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.4909 - loss: 1.3690 - val_accuracy: 0.3711 - val_loss: 1.7489\n",
      "Epoch 63/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5137 - loss: 1.3087\n",
      "Epoch 63: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.5135 - loss: 1.3088 - val_accuracy: 0.3734 - val_loss: 1.7936\n",
      "Epoch 64/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5110 - loss: 1.3153\n",
      "Epoch 64: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.5109 - loss: 1.3155 - val_accuracy: 0.3837 - val_loss: 1.7707\n",
      "Epoch 65/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5145 - loss: 1.3143\n",
      "Epoch 65: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.5145 - loss: 1.3143 - val_accuracy: 0.3706 - val_loss: 1.7766\n",
      "Epoch 66/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5158 - loss: 1.2910\n",
      "Epoch 66: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.5158 - loss: 1.2912 - val_accuracy: 0.3814 - val_loss: 1.7435\n",
      "Epoch 67/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5154 - loss: 1.2693\n",
      "Epoch 67: val_loss did not improve from 1.70918\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.5153 - loss: 1.2697 - val_accuracy: 0.3900 - val_loss: 1.7722\n",
      "Epoch 67: early stopping\n",
      "Restoring model weights from the end of the best epoch: 47.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3806 - loss: 1.6889\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3806 - loss: 1.6889\n",
      "Loss : 1.700313925743103, Accuracy : 0.3773195743560791\n"
     ]
    }
   ],
   "source": [
    "LSTM_model = get_model((X_train.shape[1:]))\n",
    "LSTM_model.summary()\n",
    "\n",
    "\n",
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"model/lstm_41feat_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "LSTM_history = LSTM_model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=32,\n",
    "                       epochs=1000,\n",
    "                       verbose=1,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {LSTM_model.evaluate(X_test,y_test)[0]}, Accuracy : {LSTM_model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9696, 41)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_7 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m98,432\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_8 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │        \u001b[38;5;34m24,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,016</span> (558.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m143,016\u001b[0m (558.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">143,016</span> (558.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m143,016\u001b[0m (558.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1532 - loss: 4.1102\n",
      "Epoch 1: val_loss improved from inf to 2.05900, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.1532 - loss: 4.1033 - val_accuracy: 0.1569 - val_loss: 2.0590\n",
      "Epoch 2/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1567 - loss: 2.0613\n",
      "Epoch 2: val_loss improved from 2.05900 to 2.03955, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1570 - loss: 2.0610 - val_accuracy: 0.1672 - val_loss: 2.0395\n",
      "Epoch 3/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1713 - loss: 2.0411\n",
      "Epoch 3: val_loss improved from 2.03955 to 2.02684, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1715 - loss: 2.0409 - val_accuracy: 0.1672 - val_loss: 2.0268\n",
      "Epoch 4/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1754 - loss: 2.0346\n",
      "Epoch 4: val_loss improved from 2.02684 to 2.01899, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1755 - loss: 2.0344 - val_accuracy: 0.1672 - val_loss: 2.0190\n",
      "Epoch 5/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1802 - loss: 2.0315\n",
      "Epoch 5: val_loss improved from 2.01899 to 2.01415, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1800 - loss: 2.0314 - val_accuracy: 0.1672 - val_loss: 2.0142\n",
      "Epoch 6/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1813 - loss: 2.0186\n",
      "Epoch 6: val_loss improved from 2.01415 to 2.01106, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1810 - loss: 2.0188 - val_accuracy: 0.1672 - val_loss: 2.0111\n",
      "Epoch 7/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1781 - loss: 2.0229\n",
      "Epoch 7: val_loss improved from 2.01106 to 2.00878, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1780 - loss: 2.0228 - val_accuracy: 0.1672 - val_loss: 2.0088\n",
      "Epoch 8/1000\n",
      "\u001b[1m205/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1880 - loss: 2.0136\n",
      "Epoch 8: val_loss improved from 2.00878 to 2.00749, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1871 - loss: 2.0140 - val_accuracy: 0.1672 - val_loss: 2.0075\n",
      "Epoch 9/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1719 - loss: 2.0197\n",
      "Epoch 9: val_loss improved from 2.00749 to 2.00641, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1720 - loss: 2.0196 - val_accuracy: 0.1672 - val_loss: 2.0064\n",
      "Epoch 10/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1801 - loss: 2.0127\n",
      "Epoch 10: val_loss improved from 2.00641 to 2.00558, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1799 - loss: 2.0130 - val_accuracy: 0.1672 - val_loss: 2.0056\n",
      "Epoch 11/1000\n",
      "\u001b[1m218/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1757 - loss: 2.0139\n",
      "Epoch 11: val_loss improved from 2.00558 to 2.00507, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1757 - loss: 2.0139 - val_accuracy: 0.1672 - val_loss: 2.0051\n",
      "Epoch 12/1000\n",
      "\u001b[1m209/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1748 - loss: 2.0183\n",
      "Epoch 12: val_loss improved from 2.00507 to 2.00463, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1748 - loss: 2.0182 - val_accuracy: 0.1672 - val_loss: 2.0046\n",
      "Epoch 13/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1801 - loss: 2.0125\n",
      "Epoch 13: val_loss improved from 2.00463 to 2.00447, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1799 - loss: 2.0126 - val_accuracy: 0.1672 - val_loss: 2.0045\n",
      "Epoch 14/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1730 - loss: 2.0182\n",
      "Epoch 14: val_loss improved from 2.00447 to 2.00420, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1731 - loss: 2.0182 - val_accuracy: 0.1672 - val_loss: 2.0042\n",
      "Epoch 15/1000\n",
      "\u001b[1m217/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1808 - loss: 2.0107\n",
      "Epoch 15: val_loss improved from 2.00420 to 2.00396, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1808 - loss: 2.0107 - val_accuracy: 0.1672 - val_loss: 2.0040\n",
      "Epoch 16/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1757 - loss: 2.0213\n",
      "Epoch 16: val_loss improved from 2.00396 to 2.00383, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1757 - loss: 2.0211 - val_accuracy: 0.1672 - val_loss: 2.0038\n",
      "Epoch 17/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1828 - loss: 2.0135\n",
      "Epoch 17: val_loss improved from 2.00383 to 2.00374, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1828 - loss: 2.0135 - val_accuracy: 0.1672 - val_loss: 2.0037\n",
      "Epoch 18/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1735 - loss: 2.0152\n",
      "Epoch 18: val_loss improved from 2.00374 to 2.00373, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1736 - loss: 2.0153 - val_accuracy: 0.1672 - val_loss: 2.0037\n",
      "Epoch 19/1000\n",
      "\u001b[1m216/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1756 - loss: 2.0153\n",
      "Epoch 19: val_loss improved from 2.00373 to 2.00359, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1756 - loss: 2.0154 - val_accuracy: 0.1672 - val_loss: 2.0036\n",
      "Epoch 20/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1706 - loss: 2.0106\n",
      "Epoch 20: val_loss improved from 2.00359 to 2.00348, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1707 - loss: 2.0108 - val_accuracy: 0.1672 - val_loss: 2.0035\n",
      "Epoch 21/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1839 - loss: 2.0097\n",
      "Epoch 21: val_loss improved from 2.00348 to 2.00339, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1837 - loss: 2.0099 - val_accuracy: 0.1672 - val_loss: 2.0034\n",
      "Epoch 22/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1673 - loss: 2.0208\n",
      "Epoch 22: val_loss did not improve from 2.00339\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1673 - loss: 2.0208 - val_accuracy: 0.1672 - val_loss: 2.0035\n",
      "Epoch 23/1000\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1815 - loss: 2.0129\n",
      "Epoch 23: val_loss did not improve from 2.00339\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1814 - loss: 2.0129 - val_accuracy: 0.1672 - val_loss: 2.0035\n",
      "Epoch 24/1000\n",
      "\u001b[1m208/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1771 - loss: 2.0102\n",
      "Epoch 24: val_loss did not improve from 2.00339\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1770 - loss: 2.0106 - val_accuracy: 0.1672 - val_loss: 2.0034\n",
      "Epoch 25/1000\n",
      "\u001b[1m213/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1695 - loss: 2.0222\n",
      "Epoch 25: val_loss did not improve from 2.00339\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1697 - loss: 2.0220 - val_accuracy: 0.1672 - val_loss: 2.0035\n",
      "Epoch 26/1000\n",
      "\u001b[1m211/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1746 - loss: 2.0154\n",
      "Epoch 26: val_loss improved from 2.00339 to 2.00334, saving model to model/SER_DEMoS_function_05_11_2024_15_12_58.keras\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1746 - loss: 2.0155 - val_accuracy: 0.1672 - val_loss: 2.0033\n",
      "Epoch 27/1000\n",
      "\u001b[1m212/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1781 - loss: 2.0156\n",
      "Epoch 27: val_loss did not improve from 2.00334\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1780 - loss: 2.0156 - val_accuracy: 0.1672 - val_loss: 2.0035\n",
      "Epoch 28/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1780 - loss: 2.0130\n",
      "Epoch 28: val_loss did not improve from 2.00334\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1779 - loss: 2.0131 - val_accuracy: 0.1672 - val_loss: 2.0034\n",
      "Epoch 29/1000\n",
      "\u001b[1m210/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1808 - loss: 2.0128\n",
      "Epoch 29: val_loss did not improve from 2.00334\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1805 - loss: 2.0129 - val_accuracy: 0.1672 - val_loss: 2.0034\n",
      "Epoch 30/1000\n",
      "\u001b[1m214/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1698 - loss: 2.0165\n",
      "Epoch 30: val_loss did not improve from 2.00334\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1699 - loss: 2.0165 - val_accuracy: 0.1672 - val_loss: 2.0034\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1591 - loss: 2.0178\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1591 - loss: 2.0178 \n",
      "Loss : 2.022216796875, Accuracy : 0.16597938537597656\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"model/SER_DEMoS_function_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=15,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.expand_dims(X_n,axis=2), Y, test_size=0.1, random_state=22)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=22)\n",
    "\n",
    "\n",
    "model = get_model((X_train.shape[1:]))\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=32,\n",
    "                       epochs=1000,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {model.evaluate(X_test,y_test)[0]}, Accuracy : {model.evaluate(X_test,y_test)[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
