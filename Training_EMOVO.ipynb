{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy, scipy as sklearn, librosa, urllib\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "import json \n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "import csv\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import keras\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import roc_curve, auc, silhouette_score,roc_auc_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the pickle files\n",
    "not_aug_df=pd.read_pickle('EMOVO_dataset/not_aug_df.pkl')\n",
    "semi_aug_df=pd.read_pickle('EMOVO_dataset/semi_aug_df.pkl')\n",
    "aug_df=pd.read_pickle('EMOVO_dataset/aug_df.pkl')\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = not_aug_df.loc[not_aug_df[\"actor\"] == \"f1\"]\n",
    "not_aug_df = not_aug_df.drop(test_df.index)\n",
    "\n",
    "Y_test = test_df[\"label_id\"]\n",
    "X_mfccs_k_test = np.array(test_df.iloc[:, 3:29])\n",
    "X_mfccs_k_test=np.array(X_mfccs_k_test.tolist())\n",
    "X_mfccs_k_test=scaler.fit_transform(X_mfccs_k_test.reshape(-1, X_mfccs_k_test.shape[-1])).reshape(X_mfccs_k_test.shape)\n",
    "Y_mfccs_k_test=test_df['label']\n",
    "X_logmel_test = np.array(test_df.loc[:, ['logmel' in i for i in test_df.columns]])\n",
    "X_logmel_test=np.array(X_logmel_test.tolist())\n",
    "X_test = np.reshape(X_logmel_test, (X_logmel_test.shape[0],X_logmel_test.shape[1],X_logmel_test.shape[2],1))\n",
    "X_logmel_test = scaler.fit_transform(X_logmel_test.reshape(-1, X_logmel_test.shape[-1])).reshape(X_logmel_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 60, 130, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 60, 130)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_logmel_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "490"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_aug_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anger', 'disgust', 'fear', 'joy', 'neutrality', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creation of the array containg the emotions ordered by their encoding\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "sorted_labels=[]\n",
    "label_encoder.fit(not_aug_df['label'])\n",
    "name_mapping = dict(zip( label_encoder.transform(label_encoder.classes_),label_encoder.classes_))\n",
    "for i in range(7):\n",
    "  sorted_labels.append(name_mapping[i])\n",
    "sorted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#extraction of the mfccs from the datasets - not aug\n",
    "X_mfccs_k = np.array(not_aug_df.iloc[:, 3:29])\n",
    "X_mfccs_k=np.array(X_mfccs_k.tolist())\n",
    "X_mfccs_k=scaler.fit_transform(X_mfccs_k.reshape(-1, X_mfccs_k.shape[-1])).reshape(X_mfccs_k.shape)\n",
    "Y_mfccs_k=not_aug_df['label']\n",
    "\n",
    "\n",
    "#extraction of the log mel specrogram from the datasets - not aug\n",
    "X_logmel_k = np.array(not_aug_df.loc[:, ['logmel' in i for i in not_aug_df.columns]])\n",
    "X_logmel_k=np.array(X_logmel_k.tolist())\n",
    "X_logmel_k=scaler.fit_transform(X_logmel_k.reshape(-1, X_logmel_k.shape[-1])).reshape(X_logmel_k.shape)\n",
    "Y_logmel_k=not_aug_df['label']\n",
    "\n",
    "#reshape the data from 3D to 2D - not aug\n",
    "X_mfccs_k=X_mfccs_k.reshape(X_mfccs_k.shape[0],X_mfccs_k.shape[1]*X_mfccs_k.shape[2])\n",
    "X_logmel_k=X_logmel_k.reshape(X_logmel_k.shape[0],X_logmel_k.shape[1]*X_logmel_k.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_logmel_k = np.array(not_aug_df.loc[:, ['logmel' in i for i in not_aug_df.columns]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction of labels_id from datasets\n",
    "Y_not_aug=not_aug_df['label_id']\n",
    "Y_semi_aug=semi_aug_df['label_id']\n",
    "Y_aug=aug_df['label_id']\n",
    "\n",
    "\n",
    "#take the log mel spectrogram from the datasets\n",
    "X_logmel = np.array(not_aug_df.loc[:, ['logmel' in i for i in not_aug_df.columns]])\n",
    "X_logmel=np.array(X_logmel.tolist())\n",
    "X_logmel_semi_aug = np.array(semi_aug_df.loc[:, ['logmel' in i for i in semi_aug_df.columns]])\n",
    "X_logmel_semi_aug=np.array(X_logmel_semi_aug.tolist())\n",
    "X_logmel_aug = np.array(aug_df.loc[:, ['logmel' in i for i in aug_df.columns]])\n",
    "X_logmel_aug=np.array(X_logmel_aug.tolist())\n",
    "\n",
    "\n",
    "#take the mfccs & deltas from the datasets\n",
    "X_mfccs = np.array(not_aug_df.iloc[:, 3:29]) \n",
    "X_mfccs=np.array(X_mfccs.tolist())\n",
    "X_mfccs_semi_aug = np.array(semi_aug_df.iloc[:, 3:29])\n",
    "X_mfccs_semi_aug=np.array(X_mfccs_semi_aug.tolist())\n",
    "X_mfccs_aug = np.array(aug_df.iloc[:, 3:29])\n",
    "X_mfccs_aug=np.array(X_mfccs_aug.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 60, 130)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_logmel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add one dimension to data to make them suitable foR CNN\n",
    "X_logmel = np.reshape(X_logmel, (X_logmel.shape[0],X_logmel.shape[1],X_logmel.shape[2],1))\n",
    "X_logmel_semi_aug= np.reshape(X_logmel_semi_aug, (X_logmel_semi_aug.shape[0],X_logmel_semi_aug.shape[1],X_logmel_semi_aug.shape[2],1))\n",
    "X_logmel_aug= np.reshape(X_logmel_aug, (X_logmel_aug.shape[0],X_logmel_aug.shape[1],X_logmel_aug.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 60, 130, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_logmel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(input_shape):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Input(shape=input_shape))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(256, 3, activation='relu' ))\n",
    "    model.add(keras.layers.MaxPooling2D(padding='same'))\n",
    "    model.add(keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(128, 3, activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(padding='same'))\n",
    "    model.add(keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64, 3, activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(padding='same'))\n",
    "    model.add(keras.layers.Dropout(rate=0.3))\n",
    "\n",
    "    model.add(keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(keras.layers.Dense(1024, activation='relu'))\n",
    "    \n",
    "    model.add(keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "\n",
    "    model.add(keras.layers.Dense(7, activation='softmax'))\n",
    "\n",
    "    optimzer = keras.optimizers.Adam()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimzer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 60, 130, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_logmel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(input):\n",
    "    input_data=(input.shape[1:])\n",
    "    modelcnn=create_cnn(input_data)\n",
    "    modelcnn.compile(\n",
    "    optimizer = \"Adam\", \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    return modelcnn\n",
    "def train_val_test(X,Y):\n",
    "    X = scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "    Y = keras.utils.to_categorical(Y.to_numpy())\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=22)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=22)\n",
    "    return X_train,X_val,X_test,y_train,y_val,y_test\n",
    "\n",
    "def get_accuracy(X_test,y_test, modelcnn):\n",
    "    predicted = modelcnn.predict(X_test)\n",
    "\n",
    "    preds = []\n",
    "    for prediction in predicted:\n",
    "        preds.append(np.argmax(prediction))\n",
    "\n",
    "    print(accuracy_score(y_test,preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1360 - loss: 1.9465  \n",
      "Epoch 1: val_loss improved from inf to 1.93669, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.1371 - loss: 1.9465 - val_accuracy: 0.1910 - val_loss: 1.9367\n",
      "Epoch 2/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2420 - loss: 1.9182\n",
      "Epoch 2: val_loss improved from 1.93669 to 1.91037, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.2380 - loss: 1.9201 - val_accuracy: 0.2022 - val_loss: 1.9104\n",
      "Epoch 3/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2173 - loss: 1.8775\n",
      "Epoch 3: val_loss improved from 1.91037 to 1.90137, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.2169 - loss: 1.8766 - val_accuracy: 0.1910 - val_loss: 1.9014\n",
      "Epoch 4/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2362 - loss: 1.8480\n",
      "Epoch 4: val_loss improved from 1.90137 to 1.90006, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.2341 - loss: 1.8496 - val_accuracy: 0.1910 - val_loss: 1.9001\n",
      "Epoch 5/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2326 - loss: 1.8617\n",
      "Epoch 5: val_loss improved from 1.90006 to 1.86731, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.2346 - loss: 1.8604 - val_accuracy: 0.2247 - val_loss: 1.8673\n",
      "Epoch 6/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2168 - loss: 1.8502\n",
      "Epoch 6: val_loss improved from 1.86731 to 1.84949, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.2174 - loss: 1.8495 - val_accuracy: 0.2022 - val_loss: 1.8495\n",
      "Epoch 7/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2536 - loss: 1.8289\n",
      "Epoch 7: val_loss did not improve from 1.84949\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.2495 - loss: 1.8322 - val_accuracy: 0.2135 - val_loss: 1.8664\n",
      "Epoch 8/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2292 - loss: 1.8482\n",
      "Epoch 8: val_loss improved from 1.84949 to 1.84871, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.2314 - loss: 1.8469 - val_accuracy: 0.2472 - val_loss: 1.8487\n",
      "Epoch 9/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2617 - loss: 1.8137\n",
      "Epoch 9: val_loss did not improve from 1.84871\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.2578 - loss: 1.8153 - val_accuracy: 0.2022 - val_loss: 1.8537\n",
      "Epoch 10/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2385 - loss: 1.8146\n",
      "Epoch 10: val_loss did not improve from 1.84871\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.2385 - loss: 1.8144 - val_accuracy: 0.1461 - val_loss: 1.8505\n",
      "Epoch 11/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2509 - loss: 1.8015\n",
      "Epoch 11: val_loss improved from 1.84871 to 1.84544, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.2525 - loss: 1.8014 - val_accuracy: 0.2247 - val_loss: 1.8454\n",
      "Epoch 12/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2488 - loss: 1.8124\n",
      "Epoch 12: val_loss improved from 1.84544 to 1.82919, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.2549 - loss: 1.8081 - val_accuracy: 0.2247 - val_loss: 1.8292\n",
      "Epoch 13/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2638 - loss: 1.7987\n",
      "Epoch 13: val_loss improved from 1.82919 to 1.80876, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.2659 - loss: 1.7956 - val_accuracy: 0.2247 - val_loss: 1.8088\n",
      "Epoch 14/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2576 - loss: 1.7816\n",
      "Epoch 14: val_loss improved from 1.80876 to 1.80126, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.2589 - loss: 1.7816 - val_accuracy: 0.2135 - val_loss: 1.8013\n",
      "Epoch 15/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2672 - loss: 1.7934\n",
      "Epoch 15: val_loss improved from 1.80126 to 1.78766, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.2691 - loss: 1.7893 - val_accuracy: 0.2247 - val_loss: 1.7877\n",
      "Epoch 16/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2860 - loss: 1.7571\n",
      "Epoch 16: val_loss did not improve from 1.78766\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3s/step - accuracy: 0.2863 - loss: 1.7586 - val_accuracy: 0.2135 - val_loss: 1.7991\n",
      "Epoch 17/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2782 - loss: 1.7703\n",
      "Epoch 17: val_loss did not improve from 1.78766\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.2811 - loss: 1.7671 - val_accuracy: 0.2135 - val_loss: 1.7973\n",
      "Epoch 18/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2866 - loss: 1.7794\n",
      "Epoch 18: val_loss improved from 1.78766 to 1.77119, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.2857 - loss: 1.7765 - val_accuracy: 0.2135 - val_loss: 1.7712\n",
      "Epoch 19/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2837 - loss: 1.7550\n",
      "Epoch 19: val_loss improved from 1.77119 to 1.76064, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.2820 - loss: 1.7533 - val_accuracy: 0.2697 - val_loss: 1.7606\n",
      "Epoch 20/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3074 - loss: 1.7149\n",
      "Epoch 20: val_loss did not improve from 1.76064\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.3043 - loss: 1.7195 - val_accuracy: 0.2360 - val_loss: 1.7726\n",
      "Epoch 21/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2697 - loss: 1.7421\n",
      "Epoch 21: val_loss improved from 1.76064 to 1.75960, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.2698 - loss: 1.7419 - val_accuracy: 0.2360 - val_loss: 1.7596\n",
      "Epoch 22/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3219 - loss: 1.7083\n",
      "Epoch 22: val_loss improved from 1.75960 to 1.75671, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.3159 - loss: 1.7157 - val_accuracy: 0.2360 - val_loss: 1.7567\n",
      "Epoch 23/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2889 - loss: 1.7183\n",
      "Epoch 23: val_loss improved from 1.75671 to 1.74837, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.2901 - loss: 1.7192 - val_accuracy: 0.2360 - val_loss: 1.7484\n",
      "Epoch 24/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3088 - loss: 1.7029\n",
      "Epoch 24: val_loss improved from 1.74837 to 1.74826, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3062 - loss: 1.7053 - val_accuracy: 0.2247 - val_loss: 1.7483\n",
      "Epoch 25/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.2818 - loss: 1.7254\n",
      "Epoch 25: val_loss improved from 1.74826 to 1.74763, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.2807 - loss: 1.7240 - val_accuracy: 0.2135 - val_loss: 1.7476\n",
      "Epoch 26/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2981 - loss: 1.7078\n",
      "Epoch 26: val_loss improved from 1.74763 to 1.74198, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.2972 - loss: 1.7102 - val_accuracy: 0.2472 - val_loss: 1.7420\n",
      "Epoch 27/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3105 - loss: 1.7209\n",
      "Epoch 27: val_loss improved from 1.74198 to 1.72799, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3112 - loss: 1.7198 - val_accuracy: 0.2360 - val_loss: 1.7280\n",
      "Epoch 28/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2821 - loss: 1.6907\n",
      "Epoch 28: val_loss improved from 1.72799 to 1.72378, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.2837 - loss: 1.6935 - val_accuracy: 0.2360 - val_loss: 1.7238\n",
      "Epoch 29/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2940 - loss: 1.6865\n",
      "Epoch 29: val_loss did not improve from 1.72378\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.2983 - loss: 1.6847 - val_accuracy: 0.2584 - val_loss: 1.7539\n",
      "Epoch 30/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2763 - loss: 1.7442\n",
      "Epoch 30: val_loss did not improve from 1.72378\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.2798 - loss: 1.7400 - val_accuracy: 0.2135 - val_loss: 1.7578\n",
      "Epoch 31/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2676 - loss: 1.7238\n",
      "Epoch 31: val_loss did not improve from 1.72378\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.2721 - loss: 1.7172 - val_accuracy: 0.2247 - val_loss: 1.7275\n",
      "Epoch 32/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3072 - loss: 1.6879\n",
      "Epoch 32: val_loss did not improve from 1.72378\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3080 - loss: 1.6865 - val_accuracy: 0.2472 - val_loss: 1.7250\n",
      "Epoch 33/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3221 - loss: 1.6854\n",
      "Epoch 33: val_loss did not improve from 1.72378\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3227 - loss: 1.6849 - val_accuracy: 0.2809 - val_loss: 1.7258\n",
      "Epoch 34/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2889 - loss: 1.7049\n",
      "Epoch 34: val_loss improved from 1.72378 to 1.68952, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.2901 - loss: 1.7064 - val_accuracy: 0.2809 - val_loss: 1.6895\n",
      "Epoch 35/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3237 - loss: 1.6604\n",
      "Epoch 35: val_loss did not improve from 1.68952\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3209 - loss: 1.6636 - val_accuracy: 0.2697 - val_loss: 1.7037\n",
      "Epoch 36/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2931 - loss: 1.6786\n",
      "Epoch 36: val_loss did not improve from 1.68952\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.2958 - loss: 1.6775 - val_accuracy: 0.2247 - val_loss: 1.7747\n",
      "Epoch 37/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3040 - loss: 1.7027\n",
      "Epoch 37: val_loss did not improve from 1.68952\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3011 - loss: 1.7076 - val_accuracy: 0.2472 - val_loss: 1.7425\n",
      "Epoch 38/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3187 - loss: 1.6679\n",
      "Epoch 38: val_loss did not improve from 1.68952\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.3195 - loss: 1.6727 - val_accuracy: 0.2360 - val_loss: 1.7394\n",
      "Epoch 39/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3033 - loss: 1.6808\n",
      "Epoch 39: val_loss did not improve from 1.68952\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3054 - loss: 1.6791 - val_accuracy: 0.2135 - val_loss: 1.7355\n",
      "Epoch 40/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2992 - loss: 1.6889\n",
      "Epoch 40: val_loss did not improve from 1.68952\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3065 - loss: 1.6851 - val_accuracy: 0.2360 - val_loss: 1.7000\n",
      "Epoch 41/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3102 - loss: 1.6521\n",
      "Epoch 41: val_loss improved from 1.68952 to 1.67487, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3081 - loss: 1.6544 - val_accuracy: 0.3258 - val_loss: 1.6749\n",
      "Epoch 42/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3192 - loss: 1.6679\n",
      "Epoch 42: val_loss did not improve from 1.67487\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3189 - loss: 1.6657 - val_accuracy: 0.2921 - val_loss: 1.6887\n",
      "Epoch 43/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3130 - loss: 1.6568\n",
      "Epoch 43: val_loss did not improve from 1.67487\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.3119 - loss: 1.6552 - val_accuracy: 0.3034 - val_loss: 1.7057\n",
      "Epoch 44/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3120 - loss: 1.6451\n",
      "Epoch 44: val_loss did not improve from 1.67487\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3131 - loss: 1.6478 - val_accuracy: 0.2472 - val_loss: 1.6879\n",
      "Epoch 45/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3288 - loss: 1.6440\n",
      "Epoch 45: val_loss did not improve from 1.67487\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.3291 - loss: 1.6427 - val_accuracy: 0.2472 - val_loss: 1.7181\n",
      "Epoch 46/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3068 - loss: 1.6759\n",
      "Epoch 46: val_loss did not improve from 1.67487\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3049 - loss: 1.6761 - val_accuracy: 0.2472 - val_loss: 1.6957\n",
      "Epoch 47/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3226 - loss: 1.6258\n",
      "Epoch 47: val_loss did not improve from 1.67487\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.3221 - loss: 1.6287 - val_accuracy: 0.3034 - val_loss: 1.7062\n",
      "Epoch 48/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3525 - loss: 1.6237\n",
      "Epoch 48: val_loss did not improve from 1.67487\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.3514 - loss: 1.6253 - val_accuracy: 0.2022 - val_loss: 1.7288\n",
      "Epoch 49/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3210 - loss: 1.6461\n",
      "Epoch 49: val_loss improved from 1.67487 to 1.66859, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.3239 - loss: 1.6437 - val_accuracy: 0.2809 - val_loss: 1.6686\n",
      "Epoch 50/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3974 - loss: 1.5878\n",
      "Epoch 50: val_loss improved from 1.66859 to 1.66166, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3918 - loss: 1.5949 - val_accuracy: 0.2809 - val_loss: 1.6617\n",
      "Epoch 51/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3581 - loss: 1.6071\n",
      "Epoch 51: val_loss did not improve from 1.66166\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3590 - loss: 1.6023 - val_accuracy: 0.2584 - val_loss: 1.6812\n",
      "Epoch 52/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3759 - loss: 1.5800\n",
      "Epoch 52: val_loss did not improve from 1.66166\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.3775 - loss: 1.5809 - val_accuracy: 0.2809 - val_loss: 1.7060\n",
      "Epoch 53/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3038 - loss: 1.6298\n",
      "Epoch 53: val_loss did not improve from 1.66166\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3048 - loss: 1.6295 - val_accuracy: 0.2697 - val_loss: 1.6779\n",
      "Epoch 54/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3718 - loss: 1.5703\n",
      "Epoch 54: val_loss did not improve from 1.66166\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.3681 - loss: 1.5714 - val_accuracy: 0.2584 - val_loss: 1.6657\n",
      "Epoch 55/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3826 - loss: 1.6024\n",
      "Epoch 55: val_loss improved from 1.66166 to 1.64534, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.3839 - loss: 1.5997 - val_accuracy: 0.3034 - val_loss: 1.6453\n",
      "Epoch 56/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3739 - loss: 1.5753\n",
      "Epoch 56: val_loss did not improve from 1.64534\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.3762 - loss: 1.5721 - val_accuracy: 0.2135 - val_loss: 1.6874\n",
      "Epoch 57/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3565 - loss: 1.5921\n",
      "Epoch 57: val_loss did not improve from 1.64534\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.3608 - loss: 1.5878 - val_accuracy: 0.2921 - val_loss: 1.6643\n",
      "Epoch 58/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3780 - loss: 1.5643\n",
      "Epoch 58: val_loss improved from 1.64534 to 1.63502, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.3751 - loss: 1.5626 - val_accuracy: 0.2921 - val_loss: 1.6350\n",
      "Epoch 59/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.3899 - loss: 1.5362\n",
      "Epoch 59: val_loss did not improve from 1.63502\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.3897 - loss: 1.5362 - val_accuracy: 0.2360 - val_loss: 1.6698\n",
      "Epoch 60/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3764 - loss: 1.5454\n",
      "Epoch 60: val_loss did not improve from 1.63502\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3s/step - accuracy: 0.3769 - loss: 1.5474 - val_accuracy: 0.2809 - val_loss: 1.6821\n",
      "Epoch 61/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3828 - loss: 1.5782\n",
      "Epoch 61: val_loss did not improve from 1.63502\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3802 - loss: 1.5799 - val_accuracy: 0.3146 - val_loss: 1.6376\n",
      "Epoch 62/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3793 - loss: 1.5657\n",
      "Epoch 62: val_loss did not improve from 1.63502\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.3807 - loss: 1.5649 - val_accuracy: 0.3146 - val_loss: 1.6653\n",
      "Epoch 63/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3778 - loss: 1.5839\n",
      "Epoch 63: val_loss did not improve from 1.63502\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.3788 - loss: 1.5803 - val_accuracy: 0.2584 - val_loss: 1.6854\n",
      "Epoch 64/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3949 - loss: 1.5286\n",
      "Epoch 64: val_loss did not improve from 1.63502\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.3911 - loss: 1.5353 - val_accuracy: 0.3371 - val_loss: 1.6511\n",
      "Epoch 65/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4020 - loss: 1.5415\n",
      "Epoch 65: val_loss improved from 1.63502 to 1.60032, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.4006 - loss: 1.5419 - val_accuracy: 0.3371 - val_loss: 1.6003\n",
      "Epoch 66/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3841 - loss: 1.5354\n",
      "Epoch 66: val_loss did not improve from 1.60032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.3858 - loss: 1.5367 - val_accuracy: 0.3146 - val_loss: 1.6194\n",
      "Epoch 67/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3807 - loss: 1.5350\n",
      "Epoch 67: val_loss did not improve from 1.60032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3826 - loss: 1.5348 - val_accuracy: 0.3483 - val_loss: 1.6251\n",
      "Epoch 68/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3629 - loss: 1.5517\n",
      "Epoch 68: val_loss did not improve from 1.60032\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3641 - loss: 1.5478 - val_accuracy: 0.3146 - val_loss: 1.6313\n",
      "Epoch 69/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4006 - loss: 1.5188\n",
      "Epoch 69: val_loss improved from 1.60032 to 1.58165, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.3987 - loss: 1.5221 - val_accuracy: 0.3596 - val_loss: 1.5817\n",
      "Epoch 70/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4194 - loss: 1.5036\n",
      "Epoch 70: val_loss did not improve from 1.58165\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.4160 - loss: 1.5063 - val_accuracy: 0.2921 - val_loss: 1.6257\n",
      "Epoch 71/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3958 - loss: 1.5272\n",
      "Epoch 71: val_loss did not improve from 1.58165\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3s/step - accuracy: 0.3936 - loss: 1.5301 - val_accuracy: 0.2584 - val_loss: 1.6257\n",
      "Epoch 72/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4135 - loss: 1.5023\n",
      "Epoch 72: val_loss did not improve from 1.58165\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3s/step - accuracy: 0.4121 - loss: 1.5064 - val_accuracy: 0.3146 - val_loss: 1.6408\n",
      "Epoch 73/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3754 - loss: 1.5212\n",
      "Epoch 73: val_loss did not improve from 1.58165\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3781 - loss: 1.5136 - val_accuracy: 0.2809 - val_loss: 1.6785\n",
      "Epoch 74/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3908 - loss: 1.5626\n",
      "Epoch 74: val_loss improved from 1.58165 to 1.56656, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.3922 - loss: 1.5569 - val_accuracy: 0.3708 - val_loss: 1.5666\n",
      "Epoch 75/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4192 - loss: 1.4749\n",
      "Epoch 75: val_loss improved from 1.56656 to 1.53747, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.4196 - loss: 1.4748 - val_accuracy: 0.3483 - val_loss: 1.5375\n",
      "Epoch 76/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4361 - loss: 1.4570\n",
      "Epoch 76: val_loss did not improve from 1.53747\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.4356 - loss: 1.4565 - val_accuracy: 0.2809 - val_loss: 1.6037\n",
      "Epoch 77/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4102 - loss: 1.4602\n",
      "Epoch 77: val_loss did not improve from 1.53747\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.4089 - loss: 1.4592 - val_accuracy: 0.3596 - val_loss: 1.6179\n",
      "Epoch 78/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3991 - loss: 1.4914\n",
      "Epoch 78: val_loss did not improve from 1.53747\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.3968 - loss: 1.4924 - val_accuracy: 0.3708 - val_loss: 1.5517\n",
      "Epoch 79/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4343 - loss: 1.4449\n",
      "Epoch 79: val_loss did not improve from 1.53747\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.4306 - loss: 1.4504 - val_accuracy: 0.3483 - val_loss: 1.5845\n",
      "Epoch 80/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4322 - loss: 1.4611\n",
      "Epoch 80: val_loss did not improve from 1.53747\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.4330 - loss: 1.4614 - val_accuracy: 0.3933 - val_loss: 1.5519\n",
      "Epoch 81/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4274 - loss: 1.4529\n",
      "Epoch 81: val_loss improved from 1.53747 to 1.53022, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.4279 - loss: 1.4522 - val_accuracy: 0.3820 - val_loss: 1.5302\n",
      "Epoch 82/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4034 - loss: 1.4281\n",
      "Epoch 82: val_loss improved from 1.53022 to 1.52834, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.4025 - loss: 1.4331 - val_accuracy: 0.3933 - val_loss: 1.5283\n",
      "Epoch 83/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4572 - loss: 1.4203\n",
      "Epoch 83: val_loss did not improve from 1.52834\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.4573 - loss: 1.4195 - val_accuracy: 0.3820 - val_loss: 1.5638\n",
      "Epoch 84/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4668 - loss: 1.4060\n",
      "Epoch 84: val_loss did not improve from 1.52834\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.4674 - loss: 1.4049 - val_accuracy: 0.3371 - val_loss: 1.5538\n",
      "Epoch 85/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4206 - loss: 1.4212\n",
      "Epoch 85: val_loss improved from 1.52834 to 1.52149, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.4215 - loss: 1.4211 - val_accuracy: 0.3483 - val_loss: 1.5215\n",
      "Epoch 86/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4448 - loss: 1.3738\n",
      "Epoch 86: val_loss did not improve from 1.52149\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.4433 - loss: 1.3775 - val_accuracy: 0.4382 - val_loss: 1.5638\n",
      "Epoch 87/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4611 - loss: 1.3872\n",
      "Epoch 87: val_loss did not improve from 1.52149\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.4599 - loss: 1.3873 - val_accuracy: 0.3371 - val_loss: 1.5677\n",
      "Epoch 88/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4629 - loss: 1.3649\n",
      "Epoch 88: val_loss improved from 1.52149 to 1.49813, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.4648 - loss: 1.3679 - val_accuracy: 0.3820 - val_loss: 1.4981\n",
      "Epoch 89/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4457 - loss: 1.3569\n",
      "Epoch 89: val_loss improved from 1.49813 to 1.48860, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.4458 - loss: 1.3581 - val_accuracy: 0.4157 - val_loss: 1.4886\n",
      "Epoch 90/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4677 - loss: 1.3498\n",
      "Epoch 90: val_loss did not improve from 1.48860\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.4699 - loss: 1.3491 - val_accuracy: 0.3820 - val_loss: 1.5091\n",
      "Epoch 91/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4924 - loss: 1.3303\n",
      "Epoch 91: val_loss improved from 1.48860 to 1.44926, saving model to ser_07_10_2024_16_31_12.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.4911 - loss: 1.3313 - val_accuracy: 0.4157 - val_loss: 1.4493\n",
      "Epoch 92/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4670 - loss: 1.3071\n",
      "Epoch 92: val_loss did not improve from 1.44926\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.4638 - loss: 1.3098 - val_accuracy: 0.4382 - val_loss: 1.4782\n",
      "Epoch 93/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4679 - loss: 1.3215\n",
      "Epoch 93: val_loss did not improve from 1.44926\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.4663 - loss: 1.3252 - val_accuracy: 0.2472 - val_loss: 1.6636\n",
      "Epoch 94/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4615 - loss: 1.4523\n",
      "Epoch 94: val_loss did not improve from 1.44926\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.4629 - loss: 1.4499 - val_accuracy: 0.3708 - val_loss: 1.5341\n",
      "Epoch 95/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4505 - loss: 1.3732\n",
      "Epoch 95: val_loss did not improve from 1.44926\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.4509 - loss: 1.3676 - val_accuracy: 0.3034 - val_loss: 1.6083\n",
      "Epoch 96/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4412 - loss: 1.4199\n",
      "Epoch 96: val_loss did not improve from 1.44926\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.4438 - loss: 1.4154 - val_accuracy: 0.4157 - val_loss: 1.5446\n",
      "Epoch 97/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4254 - loss: 1.4156\n",
      "Epoch 97: val_loss did not improve from 1.44926\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3s/step - accuracy: 0.4266 - loss: 1.4082 - val_accuracy: 0.3146 - val_loss: 1.5890\n",
      "Epoch 98/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4347 - loss: 1.4032\n",
      "Epoch 98: val_loss did not improve from 1.44926\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.4337 - loss: 1.3997 - val_accuracy: 0.3820 - val_loss: 1.5361\n",
      "Epoch 99/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4572 - loss: 1.4008\n",
      "Epoch 99: val_loss did not improve from 1.44926\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.4573 - loss: 1.3968 - val_accuracy: 0.4045 - val_loss: 1.5186\n",
      "Epoch 100/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4810 - loss: 1.3177\n",
      "Epoch 100: val_loss did not improve from 1.44926\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3s/step - accuracy: 0.4760 - loss: 1.3188 - val_accuracy: 0.3596 - val_loss: 1.5125\n",
      "Epoch 101/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5117 - loss: 1.2574\n",
      "Epoch 101: val_loss did not improve from 1.44926\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3s/step - accuracy: 0.5078 - loss: 1.2595 - val_accuracy: 0.3596 - val_loss: 1.4900\n",
      "Epoch 101: early stopping\n",
      "Restoring model weights from the end of the best epoch: 91.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"ser_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "X_train,X_val,X_test,y_train,y_val,y_test = train_val_test(X_logmel,Y_not_aug)\n",
    "modelcnn = compile_model(X_train)\n",
    "\n",
    "# modelcnn.summary()\n",
    "\n",
    "history = modelcnn.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=256,\n",
    "                       epochs=1000,\n",
    "                       callbacks=callbacks\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step \n",
      "0.46938775510204084\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4900 - loss: 1.3877\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4900 - loss: 1.3877\n",
      "Loss : 1.4225701093673706, Accuracy : 0.4693877696990967\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(X_test,y_test,modelcnn)\n",
    "print(f\"Loss : {modelcnn.evaluate(X_test,y_test)[0]}, Accuracy : {modelcnn.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train,X_val,X_test,y_train,y_val,y_test = train_val_test(X_logmel_semi_aug,Y_semi_aug)\n",
    "modelcnn = compile_model(X_train    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1491 - loss: 1.9391\n",
      "Epoch 1: val_loss improved from inf to 1.89750, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.1525 - loss: 1.9376 - val_accuracy: 0.2516 - val_loss: 1.8975\n",
      "Epoch 2/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2207 - loss: 1.8686\n",
      "Epoch 2: val_loss improved from 1.89750 to 1.87293, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.2206 - loss: 1.8683 - val_accuracy: 0.2516 - val_loss: 1.8729\n",
      "Epoch 3/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2290 - loss: 1.8347\n",
      "Epoch 3: val_loss improved from 1.87293 to 1.85809, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.2301 - loss: 1.8354 - val_accuracy: 0.2296 - val_loss: 1.8581\n",
      "Epoch 4/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2521 - loss: 1.8083\n",
      "Epoch 4: val_loss improved from 1.85809 to 1.82961, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.2525 - loss: 1.8084 - val_accuracy: 0.2327 - val_loss: 1.8296\n",
      "Epoch 5/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2519 - loss: 1.7981\n",
      "Epoch 5: val_loss improved from 1.82961 to 1.81245, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.2514 - loss: 1.7997 - val_accuracy: 0.2610 - val_loss: 1.8125\n",
      "Epoch 6/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2526 - loss: 1.8052\n",
      "Epoch 6: val_loss improved from 1.81245 to 1.81098, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.2546 - loss: 1.8038 - val_accuracy: 0.2547 - val_loss: 1.8110\n",
      "Epoch 7/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2799 - loss: 1.7722\n",
      "Epoch 7: val_loss did not improve from 1.81098\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.2773 - loss: 1.7727 - val_accuracy: 0.2704 - val_loss: 1.8125\n",
      "Epoch 8/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2733 - loss: 1.7541\n",
      "Epoch 8: val_loss improved from 1.81098 to 1.78702, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.2716 - loss: 1.7569 - val_accuracy: 0.2358 - val_loss: 1.7870\n",
      "Epoch 9/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2844 - loss: 1.7557\n",
      "Epoch 9: val_loss did not improve from 1.78702\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.2833 - loss: 1.7570 - val_accuracy: 0.2233 - val_loss: 1.8038\n",
      "Epoch 10/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2610 - loss: 1.7839\n",
      "Epoch 10: val_loss improved from 1.78702 to 1.77935, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.2632 - loss: 1.7787 - val_accuracy: 0.2484 - val_loss: 1.7793\n",
      "Epoch 11/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2569 - loss: 1.7451\n",
      "Epoch 11: val_loss improved from 1.77935 to 1.76638, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.2600 - loss: 1.7438 - val_accuracy: 0.2673 - val_loss: 1.7664\n",
      "Epoch 12/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2657 - loss: 1.7212\n",
      "Epoch 12: val_loss improved from 1.76638 to 1.75688, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.2678 - loss: 1.7212 - val_accuracy: 0.2862 - val_loss: 1.7569\n",
      "Epoch 13/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2837 - loss: 1.7168\n",
      "Epoch 13: val_loss improved from 1.75688 to 1.75218, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.2845 - loss: 1.7153 - val_accuracy: 0.2767 - val_loss: 1.7522\n",
      "Epoch 14/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2999 - loss: 1.6880\n",
      "Epoch 14: val_loss improved from 1.75218 to 1.74044, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.2987 - loss: 1.6898 - val_accuracy: 0.2862 - val_loss: 1.7404\n",
      "Epoch 15/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2862 - loss: 1.7011\n",
      "Epoch 15: val_loss did not improve from 1.74044\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.2867 - loss: 1.7001 - val_accuracy: 0.2642 - val_loss: 1.7445\n",
      "Epoch 16/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.2802 - loss: 1.7168\n",
      "Epoch 16: val_loss improved from 1.74044 to 1.73566, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.2815 - loss: 1.7141 - val_accuracy: 0.3050 - val_loss: 1.7357\n",
      "Epoch 17/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3021 - loss: 1.6865\n",
      "Epoch 17: val_loss improved from 1.73566 to 1.72424, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.3043 - loss: 1.6860 - val_accuracy: 0.2704 - val_loss: 1.7242\n",
      "Epoch 18/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3119 - loss: 1.6699\n",
      "Epoch 18: val_loss improved from 1.72424 to 1.70894, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.3119 - loss: 1.6699 - val_accuracy: 0.2767 - val_loss: 1.7089\n",
      "Epoch 19/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3412 - loss: 1.6433\n",
      "Epoch 19: val_loss improved from 1.70894 to 1.69958, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.3416 - loss: 1.6446 - val_accuracy: 0.2704 - val_loss: 1.6996\n",
      "Epoch 20/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3361 - loss: 1.6624\n",
      "Epoch 20: val_loss improved from 1.69958 to 1.66937, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.3368 - loss: 1.6590 - val_accuracy: 0.3082 - val_loss: 1.6694\n",
      "Epoch 21/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3477 - loss: 1.6318\n",
      "Epoch 21: val_loss did not improve from 1.66937\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.3479 - loss: 1.6284 - val_accuracy: 0.3050 - val_loss: 1.6746\n",
      "Epoch 22/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3454 - loss: 1.6046\n",
      "Epoch 22: val_loss improved from 1.66937 to 1.66582, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.3451 - loss: 1.6059 - val_accuracy: 0.3270 - val_loss: 1.6658\n",
      "Epoch 23/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3563 - loss: 1.5993\n",
      "Epoch 23: val_loss improved from 1.66582 to 1.64394, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.3567 - loss: 1.6011 - val_accuracy: 0.2987 - val_loss: 1.6439\n",
      "Epoch 24/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3537 - loss: 1.5949\n",
      "Epoch 24: val_loss did not improve from 1.64394\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.3525 - loss: 1.5970 - val_accuracy: 0.2987 - val_loss: 1.7201\n",
      "Epoch 25/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3640 - loss: 1.6209\n",
      "Epoch 25: val_loss did not improve from 1.64394\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.3641 - loss: 1.6186 - val_accuracy: 0.3270 - val_loss: 1.6699\n",
      "Epoch 26/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3743 - loss: 1.5743\n",
      "Epoch 26: val_loss did not improve from 1.64394\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - accuracy: 0.3748 - loss: 1.5731 - val_accuracy: 0.3396 - val_loss: 1.6554\n",
      "Epoch 27/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.3803 - loss: 1.5965\n",
      "Epoch 27: val_loss improved from 1.64394 to 1.61907, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6s/step - accuracy: 0.3810 - loss: 1.5920 - val_accuracy: 0.3459 - val_loss: 1.6191\n",
      "Epoch 28/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3906 - loss: 1.5547\n",
      "Epoch 28: val_loss improved from 1.61907 to 1.59542, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.3892 - loss: 1.5548 - val_accuracy: 0.3365 - val_loss: 1.5954\n",
      "Epoch 29/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3609 - loss: 1.5712\n",
      "Epoch 29: val_loss did not improve from 1.59542\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.3638 - loss: 1.5656 - val_accuracy: 0.3459 - val_loss: 1.6022\n",
      "Epoch 30/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.3954 - loss: 1.5345\n",
      "Epoch 30: val_loss improved from 1.59542 to 1.58280, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.3957 - loss: 1.5343 - val_accuracy: 0.3239 - val_loss: 1.5828\n",
      "Epoch 31/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.3990 - loss: 1.5417\n",
      "Epoch 31: val_loss did not improve from 1.58280\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.3992 - loss: 1.5379 - val_accuracy: 0.3899 - val_loss: 1.5907\n",
      "Epoch 32/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4117 - loss: 1.5028\n",
      "Epoch 32: val_loss improved from 1.58280 to 1.56774, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.4122 - loss: 1.5002 - val_accuracy: 0.3805 - val_loss: 1.5677\n",
      "Epoch 33/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4157 - loss: 1.4400\n",
      "Epoch 33: val_loss improved from 1.56774 to 1.51392, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - accuracy: 0.4166 - loss: 1.4427 - val_accuracy: 0.3962 - val_loss: 1.5139\n",
      "Epoch 34/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4163 - loss: 1.4604\n",
      "Epoch 34: val_loss did not improve from 1.51392\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.4156 - loss: 1.4595 - val_accuracy: 0.3836 - val_loss: 1.5238\n",
      "Epoch 35/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4335 - loss: 1.4281\n",
      "Epoch 35: val_loss improved from 1.51392 to 1.48682, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.4308 - loss: 1.4315 - val_accuracy: 0.4245 - val_loss: 1.4868\n",
      "Epoch 36/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4530 - loss: 1.4046\n",
      "Epoch 36: val_loss did not improve from 1.48682\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.4516 - loss: 1.4059 - val_accuracy: 0.3899 - val_loss: 1.5312\n",
      "Epoch 37/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4446 - loss: 1.3865\n",
      "Epoch 37: val_loss improved from 1.48682 to 1.44549, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - accuracy: 0.4422 - loss: 1.3907 - val_accuracy: 0.4277 - val_loss: 1.4455\n",
      "Epoch 38/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4753 - loss: 1.3315\n",
      "Epoch 38: val_loss improved from 1.44549 to 1.43656, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - accuracy: 0.4719 - loss: 1.3353 - val_accuracy: 0.4371 - val_loss: 1.4366\n",
      "Epoch 39/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4537 - loss: 1.3719\n",
      "Epoch 39: val_loss improved from 1.43656 to 1.41950, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - accuracy: 0.4552 - loss: 1.3679 - val_accuracy: 0.4497 - val_loss: 1.4195\n",
      "Epoch 40/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4606 - loss: 1.3514\n",
      "Epoch 40: val_loss improved from 1.41950 to 1.40305, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.4613 - loss: 1.3492 - val_accuracy: 0.4340 - val_loss: 1.4031\n",
      "Epoch 41/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4937 - loss: 1.2871\n",
      "Epoch 41: val_loss did not improve from 1.40305\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.4914 - loss: 1.2926 - val_accuracy: 0.4748 - val_loss: 1.4131\n",
      "Epoch 42/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630s/step - accuracy: 0.4556 - loss: 1.3219   \n",
      "Epoch 42: val_loss did not improve from 1.40305\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2525s\u001b[0m 630s/step - accuracy: 0.4553 - loss: 1.3244 - val_accuracy: 0.4340 - val_loss: 1.4296\n",
      "Epoch 43/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.4691 - loss: 1.3428\n",
      "Epoch 43: val_loss improved from 1.40305 to 1.34872, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.4679 - loss: 1.3402 - val_accuracy: 0.4748 - val_loss: 1.3487\n",
      "Epoch 44/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4849 - loss: 1.2883\n",
      "Epoch 44: val_loss did not improve from 1.34872\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - accuracy: 0.4817 - loss: 1.2909 - val_accuracy: 0.4465 - val_loss: 1.3544\n",
      "Epoch 45/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4766 - loss: 1.2817\n",
      "Epoch 45: val_loss did not improve from 1.34872\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - accuracy: 0.4763 - loss: 1.2857 - val_accuracy: 0.4874 - val_loss: 1.3639\n",
      "Epoch 46/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4910 - loss: 1.2731\n",
      "Epoch 46: val_loss improved from 1.34872 to 1.34163, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - accuracy: 0.4942 - loss: 1.2681 - val_accuracy: 0.4843 - val_loss: 1.3416\n",
      "Epoch 47/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5065 - loss: 1.2224\n",
      "Epoch 47: val_loss improved from 1.34163 to 1.29014, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5050 - loss: 1.2226 - val_accuracy: 0.5094 - val_loss: 1.2901\n",
      "Epoch 48/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5401 - loss: 1.1889\n",
      "Epoch 48: val_loss improved from 1.29014 to 1.26608, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5407 - loss: 1.1871 - val_accuracy: 0.4623 - val_loss: 1.2661\n",
      "Epoch 49/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5420 - loss: 1.1608\n",
      "Epoch 49: val_loss did not improve from 1.26608\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3s/step - accuracy: 0.5421 - loss: 1.1624 - val_accuracy: 0.4717 - val_loss: 1.3299\n",
      "Epoch 50/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4989 - loss: 1.2517\n",
      "Epoch 50: val_loss did not improve from 1.26608\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3s/step - accuracy: 0.4973 - loss: 1.2528 - val_accuracy: 0.4874 - val_loss: 1.3491\n",
      "Epoch 51/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5356 - loss: 1.1936\n",
      "Epoch 51: val_loss did not improve from 1.26608\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5336 - loss: 1.1985 - val_accuracy: 0.4654 - val_loss: 1.3742\n",
      "Epoch 52/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5300 - loss: 1.1708\n",
      "Epoch 52: val_loss did not improve from 1.26608\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5294 - loss: 1.1730 - val_accuracy: 0.4654 - val_loss: 1.2816\n",
      "Epoch 53/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5287 - loss: 1.1866\n",
      "Epoch 53: val_loss improved from 1.26608 to 1.25677, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5290 - loss: 1.1836 - val_accuracy: 0.4906 - val_loss: 1.2568\n",
      "Epoch 54/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5515 - loss: 1.1445\n",
      "Epoch 54: val_loss improved from 1.25677 to 1.22845, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5511 - loss: 1.1446 - val_accuracy: 0.5157 - val_loss: 1.2285\n",
      "Epoch 55/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5617 - loss: 1.0926\n",
      "Epoch 55: val_loss improved from 1.22845 to 1.21755, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5591 - loss: 1.0959 - val_accuracy: 0.5094 - val_loss: 1.2176\n",
      "Epoch 56/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5817 - loss: 1.0983\n",
      "Epoch 56: val_loss improved from 1.21755 to 1.19611, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.5825 - loss: 1.0956 - val_accuracy: 0.5472 - val_loss: 1.1961\n",
      "Epoch 57/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5806 - loss: 1.0746\n",
      "Epoch 57: val_loss did not improve from 1.19611\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4s/step - accuracy: 0.5811 - loss: 1.0736 - val_accuracy: 0.5220 - val_loss: 1.2319\n",
      "Epoch 58/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5954 - loss: 1.0526\n",
      "Epoch 58: val_loss did not improve from 1.19611\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.5942 - loss: 1.0554 - val_accuracy: 0.5063 - val_loss: 1.2044\n",
      "Epoch 59/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5901 - loss: 1.0707\n",
      "Epoch 59: val_loss improved from 1.19611 to 1.16092, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.5920 - loss: 1.0660 - val_accuracy: 0.5535 - val_loss: 1.1609\n",
      "Epoch 60/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.5820 - loss: 1.0505\n",
      "Epoch 60: val_loss did not improve from 1.16092\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.5812 - loss: 1.0522 - val_accuracy: 0.5094 - val_loss: 1.1926\n",
      "Epoch 61/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5703 - loss: 1.0697\n",
      "Epoch 61: val_loss did not improve from 1.16092\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4s/step - accuracy: 0.5702 - loss: 1.0706 - val_accuracy: 0.5346 - val_loss: 1.1713\n",
      "Epoch 62/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5792 - loss: 1.0771\n",
      "Epoch 62: val_loss did not improve from 1.16092\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.5771 - loss: 1.0827 - val_accuracy: 0.4874 - val_loss: 1.3308\n",
      "Epoch 63/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.5699 - loss: 1.0932\n",
      "Epoch 63: val_loss did not improve from 1.16092\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.5729 - loss: 1.0897 - val_accuracy: 0.5566 - val_loss: 1.1959\n",
      "Epoch 64/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75s/step - accuracy: 0.5794 - loss: 1.0371  \n",
      "Epoch 64: val_loss improved from 1.16092 to 1.09976, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 75s/step - accuracy: 0.5813 - loss: 1.0360 - val_accuracy: 0.5472 - val_loss: 1.0998\n",
      "Epoch 65/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6092 - loss: 0.9887\n",
      "Epoch 65: val_loss did not improve from 1.09976\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4s/step - accuracy: 0.6086 - loss: 0.9911 - val_accuracy: 0.5849 - val_loss: 1.1155\n",
      "Epoch 66/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6227 - loss: 0.9790\n",
      "Epoch 66: val_loss improved from 1.09976 to 1.05858, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.6246 - loss: 0.9733 - val_accuracy: 0.5535 - val_loss: 1.0586\n",
      "Epoch 67/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6552 - loss: 0.9069\n",
      "Epoch 67: val_loss improved from 1.05858 to 1.03197, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.6526 - loss: 0.9098 - val_accuracy: 0.6038 - val_loss: 1.0320\n",
      "Epoch 68/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6450 - loss: 0.9086\n",
      "Epoch 68: val_loss did not improve from 1.03197\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.6439 - loss: 0.9101 - val_accuracy: 0.5975 - val_loss: 1.0704\n",
      "Epoch 69/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6481 - loss: 0.9319\n",
      "Epoch 69: val_loss improved from 1.03197 to 1.03076, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.6480 - loss: 0.9303 - val_accuracy: 0.5912 - val_loss: 1.0308\n",
      "Epoch 70/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6356 - loss: 0.8826\n",
      "Epoch 70: val_loss did not improve from 1.03076\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4s/step - accuracy: 0.6342 - loss: 0.8877 - val_accuracy: 0.5786 - val_loss: 1.0479\n",
      "Epoch 71/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6542 - loss: 0.8866\n",
      "Epoch 71: val_loss did not improve from 1.03076\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.6520 - loss: 0.8907 - val_accuracy: 0.5786 - val_loss: 1.0769\n",
      "Epoch 72/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6483 - loss: 0.8782\n",
      "Epoch 72: val_loss improved from 1.03076 to 1.02967, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.6490 - loss: 0.8779 - val_accuracy: 0.5818 - val_loss: 1.0297\n",
      "Epoch 73/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6672 - loss: 0.8483\n",
      "Epoch 73: val_loss did not improve from 1.02967\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.6683 - loss: 0.8466 - val_accuracy: 0.5818 - val_loss: 1.0355\n",
      "Epoch 74/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6661 - loss: 0.8415\n",
      "Epoch 74: val_loss did not improve from 1.02967\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.6654 - loss: 0.8446 - val_accuracy: 0.5723 - val_loss: 1.0615\n",
      "Epoch 75/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6248 - loss: 0.9303\n",
      "Epoch 75: val_loss improved from 1.02967 to 1.00695, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.6260 - loss: 0.9302 - val_accuracy: 0.5818 - val_loss: 1.0070\n",
      "Epoch 76/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6831 - loss: 0.8429\n",
      "Epoch 76: val_loss did not improve from 1.00695\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4s/step - accuracy: 0.6806 - loss: 0.8447 - val_accuracy: 0.6038 - val_loss: 1.0126\n",
      "Epoch 77/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6694 - loss: 0.8250\n",
      "Epoch 77: val_loss did not improve from 1.00695\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6700 - loss: 0.8226 - val_accuracy: 0.6069 - val_loss: 1.0317\n",
      "Epoch 78/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6679 - loss: 0.8327\n",
      "Epoch 78: val_loss did not improve from 1.00695\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6692 - loss: 0.8314 - val_accuracy: 0.5943 - val_loss: 1.0307\n",
      "Epoch 79/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6834 - loss: 0.8223\n",
      "Epoch 79: val_loss did not improve from 1.00695\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6839 - loss: 0.8222 - val_accuracy: 0.5597 - val_loss: 1.0417\n",
      "Epoch 80/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6676 - loss: 0.8541\n",
      "Epoch 80: val_loss did not improve from 1.00695\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6665 - loss: 0.8530 - val_accuracy: 0.6006 - val_loss: 1.0122\n",
      "Epoch 81/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6762 - loss: 0.8434\n",
      "Epoch 81: val_loss did not improve from 1.00695\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6769 - loss: 0.8450 - val_accuracy: 0.5283 - val_loss: 1.3124\n",
      "Epoch 82/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6263 - loss: 1.0013\n",
      "Epoch 82: val_loss did not improve from 1.00695\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step - accuracy: 0.6270 - loss: 0.9918 - val_accuracy: 0.5818 - val_loss: 1.0963\n",
      "Epoch 83/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6677 - loss: 0.8864\n",
      "Epoch 83: val_loss did not improve from 1.00695\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6704 - loss: 0.8795 - val_accuracy: 0.5818 - val_loss: 1.0699\n",
      "Epoch 84/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6879 - loss: 0.8132\n",
      "Epoch 84: val_loss improved from 1.00695 to 0.97410, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3s/step - accuracy: 0.6881 - loss: 0.8117 - val_accuracy: 0.6132 - val_loss: 0.9741\n",
      "Epoch 85/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.6905 - loss: 0.7794\n",
      "Epoch 85: val_loss did not improve from 0.97410\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3s/step - accuracy: 0.6880 - loss: 0.7827 - val_accuracy: 0.5723 - val_loss: 1.0045\n",
      "Epoch 86/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.6843 - loss: 0.7966\n",
      "Epoch 86: val_loss improved from 0.97410 to 0.93894, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5s/step - accuracy: 0.6877 - loss: 0.7908 - val_accuracy: 0.6038 - val_loss: 0.9389\n",
      "Epoch 87/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7294 - loss: 0.7087\n",
      "Epoch 87: val_loss improved from 0.93894 to 0.90884, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6s/step - accuracy: 0.7271 - loss: 0.7116 - val_accuracy: 0.6321 - val_loss: 0.9088\n",
      "Epoch 88/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7400 - loss: 0.6785\n",
      "Epoch 88: val_loss improved from 0.90884 to 0.87323, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5s/step - accuracy: 0.7390 - loss: 0.6803 - val_accuracy: 0.6447 - val_loss: 0.8732\n",
      "Epoch 89/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7663 - loss: 0.6601\n",
      "Epoch 89: val_loss did not improve from 0.87323\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6s/step - accuracy: 0.7629 - loss: 0.6649 - val_accuracy: 0.6761 - val_loss: 0.9065\n",
      "Epoch 90/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7308 - loss: 0.7006\n",
      "Epoch 90: val_loss did not improve from 0.87323\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 5s/step - accuracy: 0.7299 - loss: 0.7011 - val_accuracy: 0.6415 - val_loss: 0.9079\n",
      "Epoch 91/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7230 - loss: 0.7041\n",
      "Epoch 91: val_loss did not improve from 0.87323\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 7s/step - accuracy: 0.7212 - loss: 0.7062 - val_accuracy: 0.6289 - val_loss: 0.9725\n",
      "Epoch 92/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7108 - loss: 0.7187\n",
      "Epoch 92: val_loss did not improve from 0.87323\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step - accuracy: 0.7100 - loss: 0.7167 - val_accuracy: 0.5975 - val_loss: 0.9437\n",
      "Epoch 93/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7352 - loss: 0.7157\n",
      "Epoch 93: val_loss did not improve from 0.87323\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step - accuracy: 0.7369 - loss: 0.7116 - val_accuracy: 0.6321 - val_loss: 0.8971\n",
      "Epoch 94/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7474 - loss: 0.6682\n",
      "Epoch 94: val_loss did not improve from 0.87323\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6s/step - accuracy: 0.7469 - loss: 0.6698 - val_accuracy: 0.6258 - val_loss: 0.9346\n",
      "Epoch 95/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7380 - loss: 0.6794\n",
      "Epoch 95: val_loss improved from 0.87323 to 0.85798, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6s/step - accuracy: 0.7381 - loss: 0.6763 - val_accuracy: 0.6887 - val_loss: 0.8580\n",
      "Epoch 96/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7593 - loss: 0.6428\n",
      "Epoch 96: val_loss improved from 0.85798 to 0.84552, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5s/step - accuracy: 0.7583 - loss: 0.6450 - val_accuracy: 0.6635 - val_loss: 0.8455\n",
      "Epoch 97/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7548 - loss: 0.6197\n",
      "Epoch 97: val_loss improved from 0.84552 to 0.81821, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4s/step - accuracy: 0.7540 - loss: 0.6232 - val_accuracy: 0.6698 - val_loss: 0.8182\n",
      "Epoch 98/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7745 - loss: 0.5962\n",
      "Epoch 98: val_loss improved from 0.81821 to 0.80961, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.7736 - loss: 0.5973 - val_accuracy: 0.6792 - val_loss: 0.8096\n",
      "Epoch 99/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7950 - loss: 0.5668\n",
      "Epoch 99: val_loss improved from 0.80961 to 0.79429, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.7935 - loss: 0.5684 - val_accuracy: 0.6824 - val_loss: 0.7943\n",
      "Epoch 100/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7923 - loss: 0.5974\n",
      "Epoch 100: val_loss improved from 0.79429 to 0.77379, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.7934 - loss: 0.5932 - val_accuracy: 0.7075 - val_loss: 0.7738\n",
      "Epoch 101/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7972 - loss: 0.5272\n",
      "Epoch 101: val_loss did not improve from 0.77379\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.7966 - loss: 0.5311 - val_accuracy: 0.6855 - val_loss: 0.7951\n",
      "Epoch 102/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8182 - loss: 0.4878\n",
      "Epoch 102: val_loss did not improve from 0.77379\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - accuracy: 0.8156 - loss: 0.4920 - val_accuracy: 0.6824 - val_loss: 0.7938\n",
      "Epoch 103/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7753 - loss: 0.5616\n",
      "Epoch 103: val_loss improved from 0.77379 to 0.77101, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5s/step - accuracy: 0.7749 - loss: 0.5611 - val_accuracy: 0.6918 - val_loss: 0.7710\n",
      "Epoch 104/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8093 - loss: 0.5240\n",
      "Epoch 104: val_loss improved from 0.77101 to 0.74585, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6s/step - accuracy: 0.8055 - loss: 0.5340 - val_accuracy: 0.7138 - val_loss: 0.7459\n",
      "Epoch 105/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7583 - loss: 0.5897\n",
      "Epoch 105: val_loss did not improve from 0.74585\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6s/step - accuracy: 0.7562 - loss: 0.5937 - val_accuracy: 0.6855 - val_loss: 0.7868\n",
      "Epoch 106/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7710 - loss: 0.5420\n",
      "Epoch 106: val_loss did not improve from 0.74585\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step - accuracy: 0.7684 - loss: 0.5496 - val_accuracy: 0.5943 - val_loss: 0.9325\n",
      "Epoch 107/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7397 - loss: 0.6295\n",
      "Epoch 107: val_loss did not improve from 0.74585\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 7s/step - accuracy: 0.7438 - loss: 0.6229 - val_accuracy: 0.6509 - val_loss: 0.8523\n",
      "Epoch 108/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7970 - loss: 0.5461\n",
      "Epoch 108: val_loss did not improve from 0.74585\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4s/step - accuracy: 0.7967 - loss: 0.5456 - val_accuracy: 0.6730 - val_loss: 0.7817\n",
      "Epoch 109/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7859 - loss: 0.5555\n",
      "Epoch 109: val_loss improved from 0.74585 to 0.74162, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.7879 - loss: 0.5533 - val_accuracy: 0.6918 - val_loss: 0.7416\n",
      "Epoch 110/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7957 - loss: 0.5197\n",
      "Epoch 110: val_loss did not improve from 0.74162\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4s/step - accuracy: 0.7949 - loss: 0.5212 - val_accuracy: 0.6698 - val_loss: 0.7587\n",
      "Epoch 111/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7733 - loss: 0.5510\n",
      "Epoch 111: val_loss improved from 0.74162 to 0.73427, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7s/step - accuracy: 0.7758 - loss: 0.5481 - val_accuracy: 0.7044 - val_loss: 0.7343\n",
      "Epoch 112/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8018 - loss: 0.5097\n",
      "Epoch 112: val_loss did not improve from 0.73427\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7s/step - accuracy: 0.8002 - loss: 0.5119 - val_accuracy: 0.7013 - val_loss: 0.7689\n",
      "Epoch 113/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8125 - loss: 0.4967\n",
      "Epoch 113: val_loss did not improve from 0.73427\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 6s/step - accuracy: 0.8131 - loss: 0.4976 - val_accuracy: 0.7075 - val_loss: 0.7522\n",
      "Epoch 114/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8108 - loss: 0.4910\n",
      "Epoch 114: val_loss improved from 0.73427 to 0.68861, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 7s/step - accuracy: 0.8108 - loss: 0.4907 - val_accuracy: 0.7358 - val_loss: 0.6886\n",
      "Epoch 115/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8233 - loss: 0.4722\n",
      "Epoch 115: val_loss did not improve from 0.68861\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6s/step - accuracy: 0.8213 - loss: 0.4740 - val_accuracy: 0.7170 - val_loss: 0.7114\n",
      "Epoch 116/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8150 - loss: 0.4611\n",
      "Epoch 116: val_loss did not improve from 0.68861\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 7s/step - accuracy: 0.8158 - loss: 0.4585 - val_accuracy: 0.7044 - val_loss: 0.7002\n",
      "Epoch 117/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8355 - loss: 0.4219\n",
      "Epoch 117: val_loss did not improve from 0.68861\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step - accuracy: 0.8364 - loss: 0.4214 - val_accuracy: 0.7107 - val_loss: 0.7085\n",
      "Epoch 118/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8447 - loss: 0.4258\n",
      "Epoch 118: val_loss improved from 0.68861 to 0.65585, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step - accuracy: 0.8429 - loss: 0.4255 - val_accuracy: 0.7421 - val_loss: 0.6559\n",
      "Epoch 119/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8674 - loss: 0.3769\n",
      "Epoch 119: val_loss improved from 0.65585 to 0.65574, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 7s/step - accuracy: 0.8664 - loss: 0.3787 - val_accuracy: 0.7579 - val_loss: 0.6557\n",
      "Epoch 120/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8602 - loss: 0.3799\n",
      "Epoch 120: val_loss improved from 0.65574 to 0.65468, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7s/step - accuracy: 0.8579 - loss: 0.3836 - val_accuracy: 0.7767 - val_loss: 0.6547\n",
      "Epoch 121/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8512 - loss: 0.4031\n",
      "Epoch 121: val_loss did not improve from 0.65468\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 7s/step - accuracy: 0.8512 - loss: 0.4035 - val_accuracy: 0.7138 - val_loss: 0.7440\n",
      "Epoch 122/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8111 - loss: 0.4904\n",
      "Epoch 122: val_loss did not improve from 0.65468\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8097 - loss: 0.4901 - val_accuracy: 0.7044 - val_loss: 0.8326\n",
      "Epoch 123/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.7958 - loss: 0.4989\n",
      "Epoch 123: val_loss did not improve from 0.65468\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7s/step - accuracy: 0.7979 - loss: 0.4976 - val_accuracy: 0.7107 - val_loss: 0.6809\n",
      "Epoch 124/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8058 - loss: 0.4830\n",
      "Epoch 124: val_loss did not improve from 0.65468\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5s/step - accuracy: 0.8061 - loss: 0.4808 - val_accuracy: 0.7013 - val_loss: 0.7351\n",
      "Epoch 125/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.7903 - loss: 0.5203\n",
      "Epoch 125: val_loss did not improve from 0.65468\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5s/step - accuracy: 0.7930 - loss: 0.5129 - val_accuracy: 0.7264 - val_loss: 0.7192\n",
      "Epoch 126/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8214 - loss: 0.4610\n",
      "Epoch 126: val_loss did not improve from 0.65468\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5s/step - accuracy: 0.8207 - loss: 0.4604 - val_accuracy: 0.7516 - val_loss: 0.6579\n",
      "Epoch 127/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8391 - loss: 0.4349\n",
      "Epoch 127: val_loss did not improve from 0.65468\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5s/step - accuracy: 0.8398 - loss: 0.4337 - val_accuracy: 0.7358 - val_loss: 0.6922\n",
      "Epoch 128/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8444 - loss: 0.4136\n",
      "Epoch 128: val_loss improved from 0.65468 to 0.61681, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5s/step - accuracy: 0.8443 - loss: 0.4130 - val_accuracy: 0.7547 - val_loss: 0.6168\n",
      "Epoch 129/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8626 - loss: 0.3645\n",
      "Epoch 129: val_loss did not improve from 0.61681\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 5s/step - accuracy: 0.8606 - loss: 0.3696 - val_accuracy: 0.7516 - val_loss: 0.6479\n",
      "Epoch 130/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8548 - loss: 0.3847\n",
      "Epoch 130: val_loss did not improve from 0.61681\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6s/step - accuracy: 0.8548 - loss: 0.3858 - val_accuracy: 0.7642 - val_loss: 0.6286\n",
      "Epoch 131/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8624 - loss: 0.3811\n",
      "Epoch 131: val_loss did not improve from 0.61681\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5s/step - accuracy: 0.8619 - loss: 0.3816 - val_accuracy: 0.7579 - val_loss: 0.6289\n",
      "Epoch 132/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8945 - loss: 0.3160\n",
      "Epoch 132: val_loss improved from 0.61681 to 0.60254, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.8927 - loss: 0.3187 - val_accuracy: 0.7736 - val_loss: 0.6025\n",
      "Epoch 133/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8739 - loss: 0.3363\n",
      "Epoch 133: val_loss did not improve from 0.60254\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.8735 - loss: 0.3376 - val_accuracy: 0.7547 - val_loss: 0.6444\n",
      "Epoch 134/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8880 - loss: 0.3033\n",
      "Epoch 134: val_loss did not improve from 0.60254\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 5s/step - accuracy: 0.8856 - loss: 0.3081 - val_accuracy: 0.7579 - val_loss: 0.6607\n",
      "Epoch 135/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8502 - loss: 0.3731\n",
      "Epoch 135: val_loss did not improve from 0.60254\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.8476 - loss: 0.3810 - val_accuracy: 0.7642 - val_loss: 0.6285\n",
      "Epoch 136/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8453 - loss: 0.3932\n",
      "Epoch 136: val_loss improved from 0.60254 to 0.60098, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.8444 - loss: 0.3974 - val_accuracy: 0.7830 - val_loss: 0.6010\n",
      "Epoch 137/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8568 - loss: 0.3823\n",
      "Epoch 137: val_loss did not improve from 0.60098\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.8559 - loss: 0.3848 - val_accuracy: 0.7516 - val_loss: 0.6536\n",
      "Epoch 138/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8412 - loss: 0.4221\n",
      "Epoch 138: val_loss improved from 0.60098 to 0.58487, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.8397 - loss: 0.4244 - val_accuracy: 0.7830 - val_loss: 0.5849\n",
      "Epoch 139/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8577 - loss: 0.3677\n",
      "Epoch 139: val_loss did not improve from 0.58487\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.8572 - loss: 0.3719 - val_accuracy: 0.7484 - val_loss: 0.7251\n",
      "Epoch 140/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8595 - loss: 0.3689\n",
      "Epoch 140: val_loss did not improve from 0.58487\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.8599 - loss: 0.3689 - val_accuracy: 0.7704 - val_loss: 0.6056\n",
      "Epoch 141/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8848 - loss: 0.3543\n",
      "Epoch 141: val_loss improved from 0.58487 to 0.55217, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.8847 - loss: 0.3527 - val_accuracy: 0.7956 - val_loss: 0.5522\n",
      "Epoch 142/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8710 - loss: 0.3393\n",
      "Epoch 142: val_loss did not improve from 0.55217\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.8716 - loss: 0.3374 - val_accuracy: 0.7925 - val_loss: 0.5581\n",
      "Epoch 143/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8815 - loss: 0.3244\n",
      "Epoch 143: val_loss did not improve from 0.55217\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6s/step - accuracy: 0.8820 - loss: 0.3232 - val_accuracy: 0.7956 - val_loss: 0.5608\n",
      "Epoch 144/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8911 - loss: 0.2997\n",
      "Epoch 144: val_loss did not improve from 0.55217\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6s/step - accuracy: 0.8906 - loss: 0.2998 - val_accuracy: 0.8019 - val_loss: 0.5636\n",
      "Epoch 145/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8985 - loss: 0.2982\n",
      "Epoch 145: val_loss did not improve from 0.55217\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.8959 - loss: 0.3029 - val_accuracy: 0.7862 - val_loss: 0.5729\n",
      "Epoch 146/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8821 - loss: 0.3080\n",
      "Epoch 146: val_loss did not improve from 0.55217\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6s/step - accuracy: 0.8826 - loss: 0.3073 - val_accuracy: 0.8050 - val_loss: 0.5601\n",
      "Epoch 147/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8753 - loss: 0.3281\n",
      "Epoch 147: val_loss did not improve from 0.55217\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6s/step - accuracy: 0.8774 - loss: 0.3234 - val_accuracy: 0.7704 - val_loss: 0.5932\n",
      "Epoch 148/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9047 - loss: 0.2515\n",
      "Epoch 148: val_loss did not improve from 0.55217\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.9059 - loss: 0.2516 - val_accuracy: 0.8019 - val_loss: 0.5692\n",
      "Epoch 149/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9057 - loss: 0.2702\n",
      "Epoch 149: val_loss did not improve from 0.55217\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.9062 - loss: 0.2691 - val_accuracy: 0.7925 - val_loss: 0.5631\n",
      "Epoch 150/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8733 - loss: 0.3062\n",
      "Epoch 150: val_loss improved from 0.55217 to 0.51174, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.8732 - loss: 0.3086 - val_accuracy: 0.8239 - val_loss: 0.5117\n",
      "Epoch 151/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9029 - loss: 0.2738\n",
      "Epoch 151: val_loss did not improve from 0.51174\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 6s/step - accuracy: 0.9031 - loss: 0.2740 - val_accuracy: 0.8050 - val_loss: 0.5414\n",
      "Epoch 152/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9153 - loss: 0.2558\n",
      "Epoch 152: val_loss improved from 0.51174 to 0.48834, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.9156 - loss: 0.2555 - val_accuracy: 0.8428 - val_loss: 0.4883\n",
      "Epoch 153/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9003 - loss: 0.2780\n",
      "Epoch 153: val_loss did not improve from 0.48834\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.9015 - loss: 0.2770 - val_accuracy: 0.8208 - val_loss: 0.5021\n",
      "Epoch 154/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8805 - loss: 0.3021\n",
      "Epoch 154: val_loss did not improve from 0.48834\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.8808 - loss: 0.3018 - val_accuracy: 0.7736 - val_loss: 0.6066\n",
      "Epoch 155/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8874 - loss: 0.3120\n",
      "Epoch 155: val_loss did not improve from 0.48834\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.8867 - loss: 0.3138 - val_accuracy: 0.7956 - val_loss: 0.5577\n",
      "Epoch 156/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9039 - loss: 0.2806\n",
      "Epoch 156: val_loss did not improve from 0.48834\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.9025 - loss: 0.2817 - val_accuracy: 0.8113 - val_loss: 0.5486\n",
      "Epoch 157/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8966 - loss: 0.2986\n",
      "Epoch 157: val_loss did not improve from 0.48834\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.8946 - loss: 0.3036 - val_accuracy: 0.8176 - val_loss: 0.5548\n",
      "Epoch 158/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9043 - loss: 0.2846\n",
      "Epoch 158: val_loss improved from 0.48834 to 0.48562, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.9052 - loss: 0.2814 - val_accuracy: 0.8145 - val_loss: 0.4856\n",
      "Epoch 159/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9226 - loss: 0.2255\n",
      "Epoch 159: val_loss improved from 0.48562 to 0.46699, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.9230 - loss: 0.2262 - val_accuracy: 0.8333 - val_loss: 0.4670\n",
      "Epoch 160/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9261 - loss: 0.2305\n",
      "Epoch 160: val_loss did not improve from 0.46699\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.9249 - loss: 0.2317 - val_accuracy: 0.8145 - val_loss: 0.4875\n",
      "Epoch 161/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9322 - loss: 0.2300\n",
      "Epoch 161: val_loss did not improve from 0.46699\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.9308 - loss: 0.2317 - val_accuracy: 0.7956 - val_loss: 0.5401\n",
      "Epoch 162/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9125 - loss: 0.2375\n",
      "Epoch 162: val_loss did not improve from 0.46699\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.9121 - loss: 0.2396 - val_accuracy: 0.8113 - val_loss: 0.5658\n",
      "Epoch 163/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9018 - loss: 0.2450\n",
      "Epoch 163: val_loss did not improve from 0.46699\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6s/step - accuracy: 0.9007 - loss: 0.2465 - val_accuracy: 0.8239 - val_loss: 0.4939\n",
      "Epoch 164/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9158 - loss: 0.2187\n",
      "Epoch 164: val_loss improved from 0.46699 to 0.45380, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6s/step - accuracy: 0.9159 - loss: 0.2201 - val_accuracy: 0.8396 - val_loss: 0.4538\n",
      "Epoch 165/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9318 - loss: 0.1925\n",
      "Epoch 165: val_loss did not improve from 0.45380\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6s/step - accuracy: 0.9293 - loss: 0.1969 - val_accuracy: 0.8208 - val_loss: 0.5063\n",
      "Epoch 166/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.9336 - loss: 0.2097\n",
      "Epoch 166: val_loss improved from 0.45380 to 0.44414, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6s/step - accuracy: 0.9328 - loss: 0.2115 - val_accuracy: 0.8239 - val_loss: 0.4441\n",
      "Epoch 167/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9257 - loss: 0.2286\n",
      "Epoch 167: val_loss did not improve from 0.44414\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.9251 - loss: 0.2282 - val_accuracy: 0.8553 - val_loss: 0.4584\n",
      "Epoch 168/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9424 - loss: 0.1746\n",
      "Epoch 168: val_loss did not improve from 0.44414\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6s/step - accuracy: 0.9431 - loss: 0.1755 - val_accuracy: 0.8333 - val_loss: 0.4710\n",
      "Epoch 169/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9442 - loss: 0.1707\n",
      "Epoch 169: val_loss improved from 0.44414 to 0.40366, saving model to ser_semiaug_07_10_2024_11_43_13.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.9433 - loss: 0.1723 - val_accuracy: 0.8616 - val_loss: 0.4037\n",
      "Epoch 170/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9482 - loss: 0.1557\n",
      "Epoch 170: val_loss did not improve from 0.40366\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 6s/step - accuracy: 0.9485 - loss: 0.1563 - val_accuracy: 0.8365 - val_loss: 0.4887\n",
      "Epoch 171/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9186 - loss: 0.2316\n",
      "Epoch 171: val_loss did not improve from 0.40366\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.9194 - loss: 0.2295 - val_accuracy: 0.8522 - val_loss: 0.4098\n",
      "Epoch 172/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9477 - loss: 0.1695\n",
      "Epoch 172: val_loss did not improve from 0.40366\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.9471 - loss: 0.1706 - val_accuracy: 0.8176 - val_loss: 0.4975\n",
      "Epoch 173/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9250 - loss: 0.1982\n",
      "Epoch 173: val_loss did not improve from 0.40366\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6s/step - accuracy: 0.9258 - loss: 0.1968 - val_accuracy: 0.8365 - val_loss: 0.5187\n",
      "Epoch 174/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9140 - loss: 0.2488\n",
      "Epoch 174: val_loss did not improve from 0.40366\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4s/step - accuracy: 0.9106 - loss: 0.2554 - val_accuracy: 0.7799 - val_loss: 0.7111\n",
      "Epoch 175/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8787 - loss: 0.3214\n",
      "Epoch 175: val_loss did not improve from 0.40366\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4s/step - accuracy: 0.8796 - loss: 0.3183 - val_accuracy: 0.8176 - val_loss: 0.5838\n",
      "Epoch 176/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9010 - loss: 0.2628\n",
      "Epoch 176: val_loss did not improve from 0.40366\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.9007 - loss: 0.2622 - val_accuracy: 0.7799 - val_loss: 0.5780\n",
      "Epoch 177/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.8972 - loss: 0.2622\n",
      "Epoch 177: val_loss did not improve from 0.40366\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6s/step - accuracy: 0.8973 - loss: 0.2623 - val_accuracy: 0.7516 - val_loss: 0.6231\n",
      "Epoch 178/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9083 - loss: 0.2617\n",
      "Epoch 178: val_loss did not improve from 0.40366\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6s/step - accuracy: 0.9101 - loss: 0.2577 - val_accuracy: 0.8491 - val_loss: 0.4488\n",
      "Epoch 179/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.9231 - loss: 0.2106\n",
      "Epoch 179: val_loss did not improve from 0.40366\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5s/step - accuracy: 0.9229 - loss: 0.2107 - val_accuracy: 0.8239 - val_loss: 0.5233\n",
      "Epoch 179: early stopping\n",
      "Restoring model weights from the end of the best epoch: 169.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"ser_semiaug_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history_semi = modelcnn.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=256,\n",
    "                       epochs=1000,\n",
    "                       callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step\n",
      "0.8757062146892656\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(X_test,y_test,modelcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcnn = compile_model()\n",
    "\n",
    "X_train,X_val,X_test,y_train,y_val,y_test = train_val_test(X_logmel_aug,Y_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1504 - loss: 1.9342\n",
      "Epoch 1: val_loss improved from inf to 1.89338, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.1531 - loss: 1.9324 - val_accuracy: 0.2311 - val_loss: 1.8934\n",
      "Epoch 2/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2167 - loss: 1.8876\n",
      "Epoch 2: val_loss improved from 1.89338 to 1.85522, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.2171 - loss: 1.8860 - val_accuracy: 0.2476 - val_loss: 1.8552\n",
      "Epoch 3/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2435 - loss: 1.8447\n",
      "Epoch 3: val_loss improved from 1.85522 to 1.84853, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.2422 - loss: 1.8452 - val_accuracy: 0.2406 - val_loss: 1.8485\n",
      "Epoch 4/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2518 - loss: 1.8319\n",
      "Epoch 4: val_loss improved from 1.84853 to 1.82915, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.2507 - loss: 1.8320 - val_accuracy: 0.2453 - val_loss: 1.8292\n",
      "Epoch 5/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2320 - loss: 1.8412\n",
      "Epoch 5: val_loss improved from 1.82915 to 1.82851, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.2338 - loss: 1.8390 - val_accuracy: 0.2217 - val_loss: 1.8285\n",
      "Epoch 6/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2626 - loss: 1.8050\n",
      "Epoch 6: val_loss improved from 1.82851 to 1.81127, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.2633 - loss: 1.8054 - val_accuracy: 0.2335 - val_loss: 1.8113\n",
      "Epoch 7/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2595 - loss: 1.7878\n",
      "Epoch 7: val_loss improved from 1.81127 to 1.78467, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.2602 - loss: 1.7874 - val_accuracy: 0.2500 - val_loss: 1.7847\n",
      "Epoch 8/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2756 - loss: 1.7817\n",
      "Epoch 8: val_loss improved from 1.78467 to 1.76097, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.2773 - loss: 1.7795 - val_accuracy: 0.2476 - val_loss: 1.7610\n",
      "Epoch 9/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2904 - loss: 1.7581\n",
      "Epoch 9: val_loss did not improve from 1.76097\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.2898 - loss: 1.7588 - val_accuracy: 0.2547 - val_loss: 1.7716\n",
      "Epoch 10/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2846 - loss: 1.7799\n",
      "Epoch 10: val_loss improved from 1.76097 to 1.74650, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.2858 - loss: 1.7772 - val_accuracy: 0.2618 - val_loss: 1.7465\n",
      "Epoch 11/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.2835 - loss: 1.7389\n",
      "Epoch 11: val_loss improved from 1.74650 to 1.72931, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.2841 - loss: 1.7396 - val_accuracy: 0.2877 - val_loss: 1.7293\n",
      "Epoch 12/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3140 - loss: 1.7443\n",
      "Epoch 12: val_loss improved from 1.72931 to 1.71620, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.3131 - loss: 1.7430 - val_accuracy: 0.2972 - val_loss: 1.7162\n",
      "Epoch 13/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3088 - loss: 1.7054\n",
      "Epoch 13: val_loss improved from 1.71620 to 1.71186, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.3084 - loss: 1.7062 - val_accuracy: 0.3042 - val_loss: 1.7119\n",
      "Epoch 14/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3271 - loss: 1.6903\n",
      "Epoch 14: val_loss did not improve from 1.71186\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.3259 - loss: 1.6910 - val_accuracy: 0.2830 - val_loss: 1.7332\n",
      "Epoch 15/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3001 - loss: 1.7106\n",
      "Epoch 15: val_loss did not improve from 1.71186\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.2999 - loss: 1.7096 - val_accuracy: 0.3113 - val_loss: 1.7499\n",
      "Epoch 16/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3054 - loss: 1.7031\n",
      "Epoch 16: val_loss did not improve from 1.71186\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.3060 - loss: 1.7022 - val_accuracy: 0.2830 - val_loss: 1.7339\n",
      "Epoch 17/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3174 - loss: 1.6719\n",
      "Epoch 17: val_loss improved from 1.71186 to 1.66928, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.3184 - loss: 1.6715 - val_accuracy: 0.3231 - val_loss: 1.6693\n",
      "Epoch 18/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3211 - loss: 1.6541\n",
      "Epoch 18: val_loss improved from 1.66928 to 1.66302, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.3216 - loss: 1.6548 - val_accuracy: 0.3184 - val_loss: 1.6630\n",
      "Epoch 19/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3292 - loss: 1.6357\n",
      "Epoch 19: val_loss improved from 1.66302 to 1.64085, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.3295 - loss: 1.6349 - val_accuracy: 0.3255 - val_loss: 1.6409\n",
      "Epoch 20/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3452 - loss: 1.5861\n",
      "Epoch 20: val_loss did not improve from 1.64085\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.3450 - loss: 1.5882 - val_accuracy: 0.3019 - val_loss: 1.6827\n",
      "Epoch 21/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3688 - loss: 1.5820\n",
      "Epoch 21: val_loss improved from 1.64085 to 1.62567, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.3685 - loss: 1.5824 - val_accuracy: 0.3420 - val_loss: 1.6257\n",
      "Epoch 22/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3787 - loss: 1.5635\n",
      "Epoch 22: val_loss improved from 1.62567 to 1.61239, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.3776 - loss: 1.5653 - val_accuracy: 0.3420 - val_loss: 1.6124\n",
      "Epoch 23/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3504 - loss: 1.5740\n",
      "Epoch 23: val_loss improved from 1.61239 to 1.60308, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.3512 - loss: 1.5732 - val_accuracy: 0.3538 - val_loss: 1.6031\n",
      "Epoch 24/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3892 - loss: 1.5239\n",
      "Epoch 24: val_loss improved from 1.60308 to 1.57328, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.3888 - loss: 1.5245 - val_accuracy: 0.3325 - val_loss: 1.5733\n",
      "Epoch 25/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3897 - loss: 1.5095\n",
      "Epoch 25: val_loss improved from 1.57328 to 1.52722, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.3906 - loss: 1.5092 - val_accuracy: 0.4151 - val_loss: 1.5272\n",
      "Epoch 26/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4180 - loss: 1.4620\n",
      "Epoch 26: val_loss improved from 1.52722 to 1.51166, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.4181 - loss: 1.4636 - val_accuracy: 0.3915 - val_loss: 1.5117\n",
      "Epoch 27/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4216 - loss: 1.4474\n",
      "Epoch 27: val_loss improved from 1.51166 to 1.48969, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.4203 - loss: 1.4487 - val_accuracy: 0.3892 - val_loss: 1.4897\n",
      "Epoch 28/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4430 - loss: 1.4175\n",
      "Epoch 28: val_loss did not improve from 1.48969\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.4409 - loss: 1.4210 - val_accuracy: 0.3939 - val_loss: 1.5149\n",
      "Epoch 29/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4259 - loss: 1.4391\n",
      "Epoch 29: val_loss improved from 1.48969 to 1.44801, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.4265 - loss: 1.4373 - val_accuracy: 0.4292 - val_loss: 1.4480\n",
      "Epoch 30/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4442 - loss: 1.3765\n",
      "Epoch 30: val_loss improved from 1.44801 to 1.41205, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.4430 - loss: 1.3766 - val_accuracy: 0.4316 - val_loss: 1.4121\n",
      "Epoch 31/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4396 - loss: 1.3866\n",
      "Epoch 31: val_loss improved from 1.41205 to 1.40829, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.4391 - loss: 1.3865 - val_accuracy: 0.4292 - val_loss: 1.4083\n",
      "Epoch 32/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4504 - loss: 1.3521\n",
      "Epoch 32: val_loss improved from 1.40829 to 1.35789, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.4513 - loss: 1.3516 - val_accuracy: 0.4599 - val_loss: 1.3579\n",
      "Epoch 33/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4672 - loss: 1.3162\n",
      "Epoch 33: val_loss did not improve from 1.35789\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.4679 - loss: 1.3160 - val_accuracy: 0.4481 - val_loss: 1.3667\n",
      "Epoch 34/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4613 - loss: 1.2817\n",
      "Epoch 34: val_loss improved from 1.35789 to 1.32003, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.4616 - loss: 1.2808 - val_accuracy: 0.4811 - val_loss: 1.3200\n",
      "Epoch 35/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4855 - loss: 1.2527\n",
      "Epoch 35: val_loss improved from 1.32003 to 1.31822, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.4856 - loss: 1.2516 - val_accuracy: 0.5094 - val_loss: 1.3182\n",
      "Epoch 36/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4973 - loss: 1.2198\n",
      "Epoch 36: val_loss improved from 1.31822 to 1.27712, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.4963 - loss: 1.2226 - val_accuracy: 0.4528 - val_loss: 1.2771\n",
      "Epoch 37/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4929 - loss: 1.2390\n",
      "Epoch 37: val_loss did not improve from 1.27712\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.4939 - loss: 1.2375 - val_accuracy: 0.4929 - val_loss: 1.2901\n",
      "Epoch 38/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5232 - loss: 1.1780\n",
      "Epoch 38: val_loss did not improve from 1.27712\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.5228 - loss: 1.1804 - val_accuracy: 0.4693 - val_loss: 1.3258\n",
      "Epoch 39/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5118 - loss: 1.1901\n",
      "Epoch 39: val_loss improved from 1.27712 to 1.20798, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.5126 - loss: 1.1915 - val_accuracy: 0.5307 - val_loss: 1.2080\n",
      "Epoch 40/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5407 - loss: 1.1616\n",
      "Epoch 40: val_loss did not improve from 1.20798\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5402 - loss: 1.1625 - val_accuracy: 0.5165 - val_loss: 1.2143\n",
      "Epoch 41/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5351 - loss: 1.1383\n",
      "Epoch 41: val_loss did not improve from 1.20798\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.5346 - loss: 1.1399 - val_accuracy: 0.4858 - val_loss: 1.2561\n",
      "Epoch 42/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5357 - loss: 1.1511\n",
      "Epoch 42: val_loss improved from 1.20798 to 1.18851, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.5341 - loss: 1.1517 - val_accuracy: 0.5472 - val_loss: 1.1885\n",
      "Epoch 43/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5505 - loss: 1.1066\n",
      "Epoch 43: val_loss did not improve from 1.18851\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5494 - loss: 1.1089 - val_accuracy: 0.5118 - val_loss: 1.2004\n",
      "Epoch 44/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5734 - loss: 1.0495\n",
      "Epoch 44: val_loss improved from 1.18851 to 1.18524, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.5717 - loss: 1.0517 - val_accuracy: 0.5377 - val_loss: 1.1852\n",
      "Epoch 45/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5590 - loss: 1.0427\n",
      "Epoch 45: val_loss improved from 1.18524 to 1.12716, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5590 - loss: 1.0442 - val_accuracy: 0.5684 - val_loss: 1.1272\n",
      "Epoch 46/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5737 - loss: 1.0297\n",
      "Epoch 46: val_loss improved from 1.12716 to 1.12040, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5736 - loss: 1.0322 - val_accuracy: 0.5542 - val_loss: 1.1204\n",
      "Epoch 47/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5565 - loss: 1.0565\n",
      "Epoch 47: val_loss improved from 1.12040 to 1.09717, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.5574 - loss: 1.0547 - val_accuracy: 0.5330 - val_loss: 1.0972\n",
      "Epoch 48/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5865 - loss: 1.0315\n",
      "Epoch 48: val_loss improved from 1.09717 to 1.06429, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.5864 - loss: 1.0294 - val_accuracy: 0.5778 - val_loss: 1.0643\n",
      "Epoch 49/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5903 - loss: 0.9751\n",
      "Epoch 49: val_loss did not improve from 1.06429\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5913 - loss: 0.9759 - val_accuracy: 0.5401 - val_loss: 1.1417\n",
      "Epoch 50/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5855 - loss: 1.0003\n",
      "Epoch 50: val_loss did not improve from 1.06429\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.5861 - loss: 1.0007 - val_accuracy: 0.5519 - val_loss: 1.0774\n",
      "Epoch 51/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5972 - loss: 0.9777\n",
      "Epoch 51: val_loss did not improve from 1.06429\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.5968 - loss: 0.9784 - val_accuracy: 0.5519 - val_loss: 1.2012\n",
      "Epoch 52/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5881 - loss: 1.0333\n",
      "Epoch 52: val_loss did not improve from 1.06429\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.5889 - loss: 1.0302 - val_accuracy: 0.5212 - val_loss: 1.1609\n",
      "Epoch 53/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5646 - loss: 1.0631\n",
      "Epoch 53: val_loss improved from 1.06429 to 1.01788, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.5648 - loss: 1.0641 - val_accuracy: 0.5920 - val_loss: 1.0179\n",
      "Epoch 54/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6172 - loss: 0.9779\n",
      "Epoch 54: val_loss did not improve from 1.01788\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.6156 - loss: 0.9799 - val_accuracy: 0.5660 - val_loss: 1.0887\n",
      "Epoch 55/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5984 - loss: 0.9704\n",
      "Epoch 55: val_loss improved from 1.01788 to 1.01713, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.5995 - loss: 0.9680 - val_accuracy: 0.5755 - val_loss: 1.0171\n",
      "Epoch 56/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6080 - loss: 0.9328\n",
      "Epoch 56: val_loss improved from 1.01713 to 1.01543, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6093 - loss: 0.9319 - val_accuracy: 0.6132 - val_loss: 1.0154\n",
      "Epoch 57/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6434 - loss: 0.8839\n",
      "Epoch 57: val_loss improved from 1.01543 to 1.00077, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6425 - loss: 0.8849 - val_accuracy: 0.6014 - val_loss: 1.0008\n",
      "Epoch 58/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6478 - loss: 0.8972\n",
      "Epoch 58: val_loss did not improve from 1.00077\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6480 - loss: 0.8944 - val_accuracy: 0.5637 - val_loss: 1.0102\n",
      "Epoch 59/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6423 - loss: 0.8573\n",
      "Epoch 59: val_loss improved from 1.00077 to 0.91981, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6426 - loss: 0.8584 - val_accuracy: 0.6321 - val_loss: 0.9198\n",
      "Epoch 60/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6479 - loss: 0.8690\n",
      "Epoch 60: val_loss did not improve from 0.91981\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6476 - loss: 0.8679 - val_accuracy: 0.6108 - val_loss: 0.9447\n",
      "Epoch 61/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6617 - loss: 0.8344\n",
      "Epoch 61: val_loss improved from 0.91981 to 0.89908, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6629 - loss: 0.8335 - val_accuracy: 0.6415 - val_loss: 0.8991\n",
      "Epoch 62/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6960 - loss: 0.8084\n",
      "Epoch 62: val_loss improved from 0.89908 to 0.89426, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6934 - loss: 0.8112 - val_accuracy: 0.6368 - val_loss: 0.8943\n",
      "Epoch 63/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6870 - loss: 0.7798\n",
      "Epoch 63: val_loss did not improve from 0.89426\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6861 - loss: 0.7818 - val_accuracy: 0.6179 - val_loss: 0.9101\n",
      "Epoch 64/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6861 - loss: 0.7996\n",
      "Epoch 64: val_loss did not improve from 0.89426\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6846 - loss: 0.8014 - val_accuracy: 0.6085 - val_loss: 0.9877\n",
      "Epoch 65/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6611 - loss: 0.8410\n",
      "Epoch 65: val_loss improved from 0.89426 to 0.88468, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6625 - loss: 0.8391 - val_accuracy: 0.6509 - val_loss: 0.8847\n",
      "Epoch 66/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6679 - loss: 0.7844\n",
      "Epoch 66: val_loss improved from 0.88468 to 0.82265, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6702 - loss: 0.7830 - val_accuracy: 0.6863 - val_loss: 0.8227\n",
      "Epoch 67/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6988 - loss: 0.7411\n",
      "Epoch 67: val_loss did not improve from 0.82265\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6984 - loss: 0.7418 - val_accuracy: 0.6769 - val_loss: 0.8571\n",
      "Epoch 68/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7133 - loss: 0.7366\n",
      "Epoch 68: val_loss improved from 0.82265 to 0.79557, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7132 - loss: 0.7368 - val_accuracy: 0.6958 - val_loss: 0.7956\n",
      "Epoch 69/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6975 - loss: 0.7428\n",
      "Epoch 69: val_loss did not improve from 0.79557\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.6977 - loss: 0.7441 - val_accuracy: 0.6509 - val_loss: 0.8690\n",
      "Epoch 70/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7203 - loss: 0.7500\n",
      "Epoch 70: val_loss did not improve from 0.79557\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7185 - loss: 0.7505 - val_accuracy: 0.7123 - val_loss: 0.8048\n",
      "Epoch 71/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7009 - loss: 0.7353\n",
      "Epoch 71: val_loss did not improve from 0.79557\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7004 - loss: 0.7364 - val_accuracy: 0.6344 - val_loss: 0.8958\n",
      "Epoch 72/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7110 - loss: 0.7108\n",
      "Epoch 72: val_loss did not improve from 0.79557\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7106 - loss: 0.7115 - val_accuracy: 0.6698 - val_loss: 0.8132\n",
      "Epoch 73/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7461 - loss: 0.6675\n",
      "Epoch 73: val_loss improved from 0.79557 to 0.76862, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7457 - loss: 0.6689 - val_accuracy: 0.6934 - val_loss: 0.7686\n",
      "Epoch 74/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7461 - loss: 0.6605\n",
      "Epoch 74: val_loss did not improve from 0.76862\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7459 - loss: 0.6619 - val_accuracy: 0.7123 - val_loss: 0.7710\n",
      "Epoch 75/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7396 - loss: 0.6765\n",
      "Epoch 75: val_loss did not improve from 0.76862\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7408 - loss: 0.6742 - val_accuracy: 0.6533 - val_loss: 0.8284\n",
      "Epoch 76/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7322 - loss: 0.6646\n",
      "Epoch 76: val_loss improved from 0.76862 to 0.72686, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7318 - loss: 0.6662 - val_accuracy: 0.6816 - val_loss: 0.7269\n",
      "Epoch 77/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7539 - loss: 0.6169\n",
      "Epoch 77: val_loss did not improve from 0.72686\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7528 - loss: 0.6195 - val_accuracy: 0.6840 - val_loss: 0.7604\n",
      "Epoch 78/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7496 - loss: 0.6284\n",
      "Epoch 78: val_loss did not improve from 0.72686\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7496 - loss: 0.6285 - val_accuracy: 0.6934 - val_loss: 0.7872\n",
      "Epoch 79/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7246 - loss: 0.6965\n",
      "Epoch 79: val_loss did not improve from 0.72686\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7258 - loss: 0.6938 - val_accuracy: 0.6604 - val_loss: 0.8238\n",
      "Epoch 80/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7323 - loss: 0.7114\n",
      "Epoch 80: val_loss did not improve from 0.72686\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7333 - loss: 0.7087 - val_accuracy: 0.6981 - val_loss: 0.7620\n",
      "Epoch 81/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7392 - loss: 0.6563\n",
      "Epoch 81: val_loss did not improve from 0.72686\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7401 - loss: 0.6538 - val_accuracy: 0.7075 - val_loss: 0.7315\n",
      "Epoch 82/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7736 - loss: 0.5920\n",
      "Epoch 82: val_loss improved from 0.72686 to 0.70021, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7732 - loss: 0.5924 - val_accuracy: 0.7217 - val_loss: 0.7002\n",
      "Epoch 83/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7491 - loss: 0.5961\n",
      "Epoch 83: val_loss improved from 0.70021 to 0.68420, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7511 - loss: 0.5949 - val_accuracy: 0.7288 - val_loss: 0.6842\n",
      "Epoch 84/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7963 - loss: 0.5257\n",
      "Epoch 84: val_loss improved from 0.68420 to 0.61924, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7944 - loss: 0.5289 - val_accuracy: 0.7500 - val_loss: 0.6192\n",
      "Epoch 85/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7928 - loss: 0.5316\n",
      "Epoch 85: val_loss did not improve from 0.61924\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7931 - loss: 0.5300 - val_accuracy: 0.7429 - val_loss: 0.6338\n",
      "Epoch 86/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7977 - loss: 0.5140\n",
      "Epoch 86: val_loss improved from 0.61924 to 0.61789, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7976 - loss: 0.5131 - val_accuracy: 0.7618 - val_loss: 0.6179\n",
      "Epoch 87/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8199 - loss: 0.4823\n",
      "Epoch 87: val_loss did not improve from 0.61789\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8187 - loss: 0.4843 - val_accuracy: 0.7571 - val_loss: 0.6322\n",
      "Epoch 88/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7920 - loss: 0.5612\n",
      "Epoch 88: val_loss did not improve from 0.61789\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7912 - loss: 0.5615 - val_accuracy: 0.7335 - val_loss: 0.6546\n",
      "Epoch 89/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7597 - loss: 0.5995\n",
      "Epoch 89: val_loss did not improve from 0.61789\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7590 - loss: 0.6041 - val_accuracy: 0.7594 - val_loss: 0.6320\n",
      "Epoch 90/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7444 - loss: 0.6391\n",
      "Epoch 90: val_loss did not improve from 0.61789\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7421 - loss: 0.6446 - val_accuracy: 0.7217 - val_loss: 0.7000\n",
      "Epoch 91/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7800 - loss: 0.5754\n",
      "Epoch 91: val_loss did not improve from 0.61789\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7798 - loss: 0.5753 - val_accuracy: 0.7476 - val_loss: 0.6273\n",
      "Epoch 92/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7980 - loss: 0.5295\n",
      "Epoch 92: val_loss improved from 0.61789 to 0.58947, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.7978 - loss: 0.5299 - val_accuracy: 0.7571 - val_loss: 0.5895\n",
      "Epoch 93/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8075 - loss: 0.5068\n",
      "Epoch 93: val_loss did not improve from 0.58947\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3s/step - accuracy: 0.8069 - loss: 0.5071 - val_accuracy: 0.7830 - val_loss: 0.6142\n",
      "Epoch 94/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8210 - loss: 0.4705\n",
      "Epoch 94: val_loss improved from 0.58947 to 0.57339, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8208 - loss: 0.4699 - val_accuracy: 0.7877 - val_loss: 0.5734\n",
      "Epoch 95/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8197 - loss: 0.4650\n",
      "Epoch 95: val_loss improved from 0.57339 to 0.54000, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8197 - loss: 0.4647 - val_accuracy: 0.7995 - val_loss: 0.5400\n",
      "Epoch 96/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8343 - loss: 0.4555\n",
      "Epoch 96: val_loss did not improve from 0.54000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8348 - loss: 0.4537 - val_accuracy: 0.7854 - val_loss: 0.5559\n",
      "Epoch 97/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8341 - loss: 0.4512\n",
      "Epoch 97: val_loss improved from 0.54000 to 0.53844, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8318 - loss: 0.4564 - val_accuracy: 0.7759 - val_loss: 0.5384\n",
      "Epoch 98/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8066 - loss: 0.4923\n",
      "Epoch 98: val_loss did not improve from 0.53844\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8081 - loss: 0.4888 - val_accuracy: 0.7901 - val_loss: 0.5822\n",
      "Epoch 99/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8164 - loss: 0.4583\n",
      "Epoch 99: val_loss did not improve from 0.53844\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8168 - loss: 0.4577 - val_accuracy: 0.7665 - val_loss: 0.5741\n",
      "Epoch 100/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8347 - loss: 0.4444\n",
      "Epoch 100: val_loss did not improve from 0.53844\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8338 - loss: 0.4463 - val_accuracy: 0.7689 - val_loss: 0.5908\n",
      "Epoch 101/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8319 - loss: 0.4453\n",
      "Epoch 101: val_loss did not improve from 0.53844\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8303 - loss: 0.4475 - val_accuracy: 0.7854 - val_loss: 0.5986\n",
      "Epoch 102/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8516 - loss: 0.4483\n",
      "Epoch 102: val_loss improved from 0.53844 to 0.47429, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8511 - loss: 0.4469 - val_accuracy: 0.8325 - val_loss: 0.4743\n",
      "Epoch 103/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8580 - loss: 0.3690\n",
      "Epoch 103: val_loss improved from 0.47429 to 0.44750, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8583 - loss: 0.3692 - val_accuracy: 0.8231 - val_loss: 0.4475\n",
      "Epoch 104/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8751 - loss: 0.3515\n",
      "Epoch 104: val_loss did not improve from 0.44750\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8735 - loss: 0.3542 - val_accuracy: 0.7830 - val_loss: 0.4908\n",
      "Epoch 105/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8377 - loss: 0.4238\n",
      "Epoch 105: val_loss did not improve from 0.44750\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8377 - loss: 0.4238 - val_accuracy: 0.7783 - val_loss: 0.5753\n",
      "Epoch 106/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8085 - loss: 0.4605\n",
      "Epoch 106: val_loss did not improve from 0.44750\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3s/step - accuracy: 0.8091 - loss: 0.4592 - val_accuracy: 0.7854 - val_loss: 0.5616\n",
      "Epoch 107/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8169 - loss: 0.4456\n",
      "Epoch 107: val_loss did not improve from 0.44750\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8168 - loss: 0.4464 - val_accuracy: 0.8042 - val_loss: 0.5432\n",
      "Epoch 108/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8255 - loss: 0.4443\n",
      "Epoch 108: val_loss did not improve from 0.44750\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8263 - loss: 0.4424 - val_accuracy: 0.7995 - val_loss: 0.5368\n",
      "Epoch 109/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8472 - loss: 0.3760\n",
      "Epoch 109: val_loss did not improve from 0.44750\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8466 - loss: 0.3761 - val_accuracy: 0.8255 - val_loss: 0.4701\n",
      "Epoch 110/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8682 - loss: 0.3518\n",
      "Epoch 110: val_loss did not improve from 0.44750\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8688 - loss: 0.3512 - val_accuracy: 0.7877 - val_loss: 0.4718\n",
      "Epoch 111/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8815 - loss: 0.3388\n",
      "Epoch 111: val_loss improved from 0.44750 to 0.42664, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8800 - loss: 0.3415 - val_accuracy: 0.8302 - val_loss: 0.4266\n",
      "Epoch 112/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8818 - loss: 0.3340\n",
      "Epoch 112: val_loss did not improve from 0.42664\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8809 - loss: 0.3356 - val_accuracy: 0.8302 - val_loss: 0.4556\n",
      "Epoch 113/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8896 - loss: 0.3072\n",
      "Epoch 113: val_loss improved from 0.42664 to 0.40641, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8889 - loss: 0.3075 - val_accuracy: 0.8538 - val_loss: 0.4064\n",
      "Epoch 114/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8980 - loss: 0.2947\n",
      "Epoch 114: val_loss improved from 0.40641 to 0.37575, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8977 - loss: 0.2944 - val_accuracy: 0.8585 - val_loss: 0.3758\n",
      "Epoch 115/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9021 - loss: 0.2876\n",
      "Epoch 115: val_loss did not improve from 0.37575\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9017 - loss: 0.2886 - val_accuracy: 0.8396 - val_loss: 0.4062\n",
      "Epoch 116/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8964 - loss: 0.2776\n",
      "Epoch 116: val_loss did not improve from 0.37575\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8960 - loss: 0.2781 - val_accuracy: 0.8420 - val_loss: 0.3952\n",
      "Epoch 117/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9085 - loss: 0.2643\n",
      "Epoch 117: val_loss improved from 0.37575 to 0.35655, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9089 - loss: 0.2636 - val_accuracy: 0.8491 - val_loss: 0.3566\n",
      "Epoch 118/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9140 - loss: 0.2511\n",
      "Epoch 118: val_loss did not improve from 0.35655\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9135 - loss: 0.2530 - val_accuracy: 0.8373 - val_loss: 0.3973\n",
      "Epoch 119/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9124 - loss: 0.2620\n",
      "Epoch 119: val_loss improved from 0.35655 to 0.34127, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9125 - loss: 0.2620 - val_accuracy: 0.8608 - val_loss: 0.3413\n",
      "Epoch 120/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9038 - loss: 0.2553\n",
      "Epoch 120: val_loss did not improve from 0.34127\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9039 - loss: 0.2551 - val_accuracy: 0.8561 - val_loss: 0.3590\n",
      "Epoch 121/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9132 - loss: 0.2338\n",
      "Epoch 121: val_loss did not improve from 0.34127\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9133 - loss: 0.2340 - val_accuracy: 0.8325 - val_loss: 0.3830\n",
      "Epoch 122/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9075 - loss: 0.2597\n",
      "Epoch 122: val_loss did not improve from 0.34127\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9065 - loss: 0.2620 - val_accuracy: 0.8278 - val_loss: 0.4657\n",
      "Epoch 123/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8738 - loss: 0.3129\n",
      "Epoch 123: val_loss did not improve from 0.34127\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8754 - loss: 0.3099 - val_accuracy: 0.8420 - val_loss: 0.3640\n",
      "Epoch 124/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8950 - loss: 0.2829\n",
      "Epoch 124: val_loss did not improve from 0.34127\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8947 - loss: 0.2842 - val_accuracy: 0.8420 - val_loss: 0.3957\n",
      "Epoch 125/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8938 - loss: 0.2903\n",
      "Epoch 125: val_loss improved from 0.34127 to 0.32795, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8937 - loss: 0.2897 - val_accuracy: 0.8726 - val_loss: 0.3280\n",
      "Epoch 126/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9102 - loss: 0.2378\n",
      "Epoch 126: val_loss did not improve from 0.32795\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9096 - loss: 0.2396 - val_accuracy: 0.8608 - val_loss: 0.3961\n",
      "Epoch 127/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9225 - loss: 0.2368\n",
      "Epoch 127: val_loss did not improve from 0.32795\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9217 - loss: 0.2372 - val_accuracy: 0.8561 - val_loss: 0.3591\n",
      "Epoch 128/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9199 - loss: 0.2374\n",
      "Epoch 128: val_loss did not improve from 0.32795\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9192 - loss: 0.2393 - val_accuracy: 0.8797 - val_loss: 0.3301\n",
      "Epoch 129/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9126 - loss: 0.2465\n",
      "Epoch 129: val_loss did not improve from 0.32795\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9114 - loss: 0.2493 - val_accuracy: 0.8208 - val_loss: 0.5094\n",
      "Epoch 130/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8589 - loss: 0.3289\n",
      "Epoch 130: val_loss did not improve from 0.32795\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8606 - loss: 0.3262 - val_accuracy: 0.8656 - val_loss: 0.4129\n",
      "Epoch 131/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8898 - loss: 0.3054\n",
      "Epoch 131: val_loss did not improve from 0.32795\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8904 - loss: 0.3044 - val_accuracy: 0.8514 - val_loss: 0.4390\n",
      "Epoch 132/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8928 - loss: 0.2842\n",
      "Epoch 132: val_loss did not improve from 0.32795\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8925 - loss: 0.2852 - val_accuracy: 0.8774 - val_loss: 0.3508\n",
      "Epoch 133/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8935 - loss: 0.2838\n",
      "Epoch 133: val_loss did not improve from 0.32795\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8938 - loss: 0.2841 - val_accuracy: 0.8514 - val_loss: 0.3743\n",
      "Epoch 134/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8890 - loss: 0.2867\n",
      "Epoch 134: val_loss improved from 0.32795 to 0.31168, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.8897 - loss: 0.2861 - val_accuracy: 0.8844 - val_loss: 0.3117\n",
      "Epoch 135/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9056 - loss: 0.2503\n",
      "Epoch 135: val_loss did not improve from 0.31168\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9051 - loss: 0.2512 - val_accuracy: 0.8443 - val_loss: 0.3915\n",
      "Epoch 136/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9065 - loss: 0.2546\n",
      "Epoch 136: val_loss did not improve from 0.31168\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9062 - loss: 0.2553 - val_accuracy: 0.8184 - val_loss: 0.4875\n",
      "Epoch 137/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8999 - loss: 0.2920\n",
      "Epoch 137: val_loss improved from 0.31168 to 0.31009, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9003 - loss: 0.2894 - val_accuracy: 0.8868 - val_loss: 0.3101\n",
      "Epoch 138/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9194 - loss: 0.2325\n",
      "Epoch 138: val_loss did not improve from 0.31009\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9178 - loss: 0.2354 - val_accuracy: 0.8750 - val_loss: 0.3356\n",
      "Epoch 139/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9066 - loss: 0.2360\n",
      "Epoch 139: val_loss did not improve from 0.31009\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.9062 - loss: 0.2359 - val_accuracy: 0.8939 - val_loss: 0.3106\n",
      "Epoch 140/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9191 - loss: 0.2182\n",
      "Epoch 140: val_loss did not improve from 0.31009\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9197 - loss: 0.2169 - val_accuracy: 0.8585 - val_loss: 0.3642\n",
      "Epoch 141/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9137 - loss: 0.2298\n",
      "Epoch 141: val_loss did not improve from 0.31009\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9147 - loss: 0.2274 - val_accuracy: 0.8750 - val_loss: 0.3134\n",
      "Epoch 142/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9309 - loss: 0.2125\n",
      "Epoch 142: val_loss improved from 0.31009 to 0.30027, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.9311 - loss: 0.2104 - val_accuracy: 0.8892 - val_loss: 0.3003\n",
      "Epoch 143/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9391 - loss: 0.1779\n",
      "Epoch 143: val_loss improved from 0.30027 to 0.29191, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9393 - loss: 0.1771 - val_accuracy: 0.8797 - val_loss: 0.2919\n",
      "Epoch 144/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9397 - loss: 0.1722\n",
      "Epoch 144: val_loss improved from 0.29191 to 0.25736, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9392 - loss: 0.1731 - val_accuracy: 0.9033 - val_loss: 0.2574\n",
      "Epoch 145/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9361 - loss: 0.1802\n",
      "Epoch 145: val_loss did not improve from 0.25736\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9357 - loss: 0.1806 - val_accuracy: 0.8750 - val_loss: 0.3356\n",
      "Epoch 146/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9344 - loss: 0.2070\n",
      "Epoch 146: val_loss did not improve from 0.25736\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9347 - loss: 0.2061 - val_accuracy: 0.8986 - val_loss: 0.2707\n",
      "Epoch 147/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9339 - loss: 0.1698\n",
      "Epoch 147: val_loss improved from 0.25736 to 0.24604, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9340 - loss: 0.1705 - val_accuracy: 0.9009 - val_loss: 0.2460\n",
      "Epoch 148/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9426 - loss: 0.1610\n",
      "Epoch 148: val_loss improved from 0.24604 to 0.24254, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9430 - loss: 0.1615 - val_accuracy: 0.9198 - val_loss: 0.2425\n",
      "Epoch 149/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9377 - loss: 0.1553\n",
      "Epoch 149: val_loss improved from 0.24254 to 0.22311, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9381 - loss: 0.1557 - val_accuracy: 0.9245 - val_loss: 0.2231\n",
      "Epoch 150/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9520 - loss: 0.1461\n",
      "Epoch 150: val_loss did not improve from 0.22311\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9511 - loss: 0.1475 - val_accuracy: 0.8962 - val_loss: 0.2637\n",
      "Epoch 151/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9519 - loss: 0.1607\n",
      "Epoch 151: val_loss did not improve from 0.22311\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3s/step - accuracy: 0.9517 - loss: 0.1610 - val_accuracy: 0.8821 - val_loss: 0.3384\n",
      "Epoch 152/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9563 - loss: 0.1363\n",
      "Epoch 152: val_loss did not improve from 0.22311\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9560 - loss: 0.1367 - val_accuracy: 0.9104 - val_loss: 0.2420\n",
      "Epoch 153/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9476 - loss: 0.1470\n",
      "Epoch 153: val_loss did not improve from 0.22311\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9478 - loss: 0.1477 - val_accuracy: 0.8844 - val_loss: 0.2868\n",
      "Epoch 154/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9539 - loss: 0.1331\n",
      "Epoch 154: val_loss did not improve from 0.22311\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9536 - loss: 0.1345 - val_accuracy: 0.9151 - val_loss: 0.2491\n",
      "Epoch 155/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9545 - loss: 0.1419\n",
      "Epoch 155: val_loss improved from 0.22311 to 0.20922, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9543 - loss: 0.1419 - val_accuracy: 0.9198 - val_loss: 0.2092\n",
      "Epoch 156/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9494 - loss: 0.1507\n",
      "Epoch 156: val_loss did not improve from 0.20922\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9485 - loss: 0.1525 - val_accuracy: 0.8844 - val_loss: 0.2858\n",
      "Epoch 157/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9439 - loss: 0.1600\n",
      "Epoch 157: val_loss did not improve from 0.20922\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9436 - loss: 0.1609 - val_accuracy: 0.9057 - val_loss: 0.2589\n",
      "Epoch 158/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9411 - loss: 0.1638\n",
      "Epoch 158: val_loss did not improve from 0.20922\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9411 - loss: 0.1634 - val_accuracy: 0.9222 - val_loss: 0.2367\n",
      "Epoch 159/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9446 - loss: 0.1501\n",
      "Epoch 159: val_loss improved from 0.20922 to 0.19976, saving model to ser_aug_07_10_2024_15_13_24.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9445 - loss: 0.1508 - val_accuracy: 0.9222 - val_loss: 0.1998\n",
      "Epoch 160/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9375 - loss: 0.1757\n",
      "Epoch 160: val_loss did not improve from 0.19976\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9367 - loss: 0.1789 - val_accuracy: 0.9057 - val_loss: 0.2630\n",
      "Epoch 161/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9341 - loss: 0.1722\n",
      "Epoch 161: val_loss did not improve from 0.19976\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9337 - loss: 0.1742 - val_accuracy: 0.9127 - val_loss: 0.2952\n",
      "Epoch 162/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9436 - loss: 0.1646\n",
      "Epoch 162: val_loss did not improve from 0.19976\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9440 - loss: 0.1634 - val_accuracy: 0.9057 - val_loss: 0.2785\n",
      "Epoch 163/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9571 - loss: 0.1377\n",
      "Epoch 163: val_loss did not improve from 0.19976\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9566 - loss: 0.1380 - val_accuracy: 0.9127 - val_loss: 0.2506\n",
      "Epoch 164/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9497 - loss: 0.1512\n",
      "Epoch 164: val_loss did not improve from 0.19976\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9498 - loss: 0.1511 - val_accuracy: 0.8821 - val_loss: 0.2919\n",
      "Epoch 165/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9524 - loss: 0.1304\n",
      "Epoch 165: val_loss did not improve from 0.19976\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9526 - loss: 0.1303 - val_accuracy: 0.9222 - val_loss: 0.2388\n",
      "Epoch 166/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9553 - loss: 0.1365\n",
      "Epoch 166: val_loss did not improve from 0.19976\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9544 - loss: 0.1379 - val_accuracy: 0.8915 - val_loss: 0.2872\n",
      "Epoch 167/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9460 - loss: 0.1437\n",
      "Epoch 167: val_loss did not improve from 0.19976\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9456 - loss: 0.1450 - val_accuracy: 0.9175 - val_loss: 0.3049\n",
      "Epoch 168/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9455 - loss: 0.1510\n",
      "Epoch 168: val_loss did not improve from 0.19976\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9454 - loss: 0.1514 - val_accuracy: 0.8915 - val_loss: 0.2883\n",
      "Epoch 169/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9408 - loss: 0.1532\n",
      "Epoch 169: val_loss did not improve from 0.19976\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3s/step - accuracy: 0.9416 - loss: 0.1514 - val_accuracy: 0.9175 - val_loss: 0.2440\n",
      "Epoch 169: early stopping\n",
      "Restoring model weights from the end of the best epoch: 159.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"ser_aug_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "history_semi = modelcnn.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=256,\n",
    "                       epochs=1000,\n",
    "                       callbacks=callbacks\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step\n",
      "0.885593220338983\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(X_test,y_test,modelcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423, 60, 130, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_val,X_test,y_train,y_val,y_test = train_val_test(X_logmel,Y_not_aug)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    encoder = layers.LSTM(128)(inputs)\n",
    "    drop = layers.Dropout(0.3)(encoder)\n",
    "    hidden = layers.Dense(32, activation='relu')(drop)\n",
    "    outputs = layers.Dense(7, activation='softmax')(hidden)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 130)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_71\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_71\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">132,608</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m130\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m132,608\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m231\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">136,967</span> (535.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m136,967\u001b[0m (535.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">136,967</span> (535.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m136,967\u001b[0m (535.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train,X_val,X_test,y_train,y_val,y_test = train_val_test(X_logmel.squeeze(3),Y_not_aug)\n",
    "LSTM_model = get_model(X_train.shape[1:])\n",
    "LSTM_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1205 - loss: 1.9909\n",
      "Epoch 1: val_loss improved from inf to 1.97996, saving model to ser_lstm_07_10_2024_16_50_16.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - accuracy: 0.1230 - loss: 1.9899 - val_accuracy: 0.1461 - val_loss: 1.9800\n",
      "Epoch 2/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2468 - loss: 1.8175\n",
      "Epoch 2: val_loss improved from 1.97996 to 1.93957, saving model to ser_lstm_07_10_2024_16_50_16.keras\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.2471 - loss: 1.8185 - val_accuracy: 0.1798 - val_loss: 1.9396\n",
      "Epoch 3/1000\n",
      "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.3694 - loss: 1.7400\n",
      "Epoch 3: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.3665 - loss: 1.7408 - val_accuracy: 0.1910 - val_loss: 1.9505\n",
      "Epoch 4/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4225 - loss: 1.6029\n",
      "Epoch 4: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.4217 - loss: 1.6042 - val_accuracy: 0.1573 - val_loss: 1.9887\n",
      "Epoch 5/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5047 - loss: 1.5055\n",
      "Epoch 5: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.5010 - loss: 1.5060 - val_accuracy: 0.1910 - val_loss: 2.0195\n",
      "Epoch 6/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5099 - loss: 1.4516\n",
      "Epoch 6: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.5109 - loss: 1.4495 - val_accuracy: 0.1910 - val_loss: 2.0293\n",
      "Epoch 7/1000\n",
      "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5337 - loss: 1.3248\n",
      "Epoch 7: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.5314 - loss: 1.3258 - val_accuracy: 0.1910 - val_loss: 2.0722\n",
      "Epoch 8/1000\n",
      "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6622 - loss: 1.1752\n",
      "Epoch 8: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.6564 - loss: 1.1836 - val_accuracy: 0.2022 - val_loss: 2.0943\n",
      "Epoch 9/1000\n",
      "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6797 - loss: 1.1219\n",
      "Epoch 9: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.6724 - loss: 1.1216 - val_accuracy: 0.2360 - val_loss: 2.2024\n",
      "Epoch 10/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6971 - loss: 1.0429\n",
      "Epoch 10: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.6947 - loss: 1.0430 - val_accuracy: 0.2584 - val_loss: 2.2027\n",
      "Epoch 11/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7036 - loss: 0.9220\n",
      "Epoch 11: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.7036 - loss: 0.9218 - val_accuracy: 0.2135 - val_loss: 2.2645\n",
      "Epoch 12/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7231 - loss: 0.8917\n",
      "Epoch 12: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7239 - loss: 0.8884 - val_accuracy: 0.1685 - val_loss: 2.5091\n",
      "Epoch 13/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7558 - loss: 0.8061\n",
      "Epoch 13: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7535 - loss: 0.8096 - val_accuracy: 0.1910 - val_loss: 2.4604\n",
      "Epoch 14/1000\n",
      "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8047 - loss: 0.6831\n",
      "Epoch 14: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8022 - loss: 0.6864 - val_accuracy: 0.1910 - val_loss: 2.5528\n",
      "Epoch 15/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8286 - loss: 0.6312\n",
      "Epoch 15: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8285 - loss: 0.6345 - val_accuracy: 0.2472 - val_loss: 2.4624\n",
      "Epoch 16/1000\n",
      "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8477 - loss: 0.5272\n",
      "Epoch 16: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.8452 - loss: 0.5364 - val_accuracy: 0.2360 - val_loss: 2.6832\n",
      "Epoch 17/1000\n",
      "\u001b[1m10/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9154 - loss: 0.4320\n",
      "Epoch 17: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9105 - loss: 0.4404 - val_accuracy: 0.2360 - val_loss: 2.7789\n",
      "Epoch 18/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9198 - loss: 0.4182\n",
      "Epoch 18: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9179 - loss: 0.4204 - val_accuracy: 0.2472 - val_loss: 2.8713\n",
      "Epoch 19/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9495 - loss: 0.3639\n",
      "Epoch 19: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9469 - loss: 0.3653 - val_accuracy: 0.2247 - val_loss: 3.0191\n",
      "Epoch 20/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9032 - loss: 0.3792\n",
      "Epoch 20: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9040 - loss: 0.3776 - val_accuracy: 0.1798 - val_loss: 3.0330\n",
      "Epoch 21/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9153 - loss: 0.3231\n",
      "Epoch 21: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9157 - loss: 0.3235 - val_accuracy: 0.2360 - val_loss: 2.9889\n",
      "Epoch 22/1000\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9358 - loss: 0.2550\n",
      "Epoch 22: val_loss did not improve from 1.93957\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9350 - loss: 0.2557 - val_accuracy: 0.2360 - val_loss: 3.0588\n",
      "Epoch 22: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2946 - loss: 1.8361 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2946 - loss: 1.8361 \n",
      "Loss : 1.8457982540130615, Accuracy : 0.2857142984867096\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"ser_lstm_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "LSTM_history = LSTM_model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=32,\n",
    "                       epochs=1000,\n",
    "                       verbose=1,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {LSTM_model.evaluate(X_test,y_test)[0]}, Accuracy : {LSTM_model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - accuracy: 0.1573 - loss: 2.0561\n",
      "Epoch 1: val_loss improved from inf to 1.90702, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 701ms/step - accuracy: 0.1588 - loss: 2.0464 - val_accuracy: 0.2201 - val_loss: 1.9070\n",
      "Epoch 2/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - accuracy: 0.2239 - loss: 1.8929\n",
      "Epoch 2: val_loss improved from 1.90702 to 1.88487, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - accuracy: 0.2254 - loss: 1.8906 - val_accuracy: 0.2579 - val_loss: 1.8849\n",
      "Epoch 3/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.2731 - loss: 1.8417\n",
      "Epoch 3: val_loss improved from 1.88487 to 1.85692, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 485ms/step - accuracy: 0.2724 - loss: 1.8414 - val_accuracy: 0.2610 - val_loss: 1.8569\n",
      "Epoch 4/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.2985 - loss: 1.8021\n",
      "Epoch 4: val_loss improved from 1.85692 to 1.81274, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 562ms/step - accuracy: 0.2991 - loss: 1.7996 - val_accuracy: 0.3019 - val_loss: 1.8127\n",
      "Epoch 5/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step - accuracy: 0.3145 - loss: 1.7407\n",
      "Epoch 5: val_loss improved from 1.81274 to 1.77542, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 462ms/step - accuracy: 0.3177 - loss: 1.7384 - val_accuracy: 0.2956 - val_loss: 1.7754\n",
      "Epoch 6/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.3605 - loss: 1.6759\n",
      "Epoch 6: val_loss improved from 1.77542 to 1.72895, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 533ms/step - accuracy: 0.3603 - loss: 1.6760 - val_accuracy: 0.3050 - val_loss: 1.7290\n",
      "Epoch 7/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.4038 - loss: 1.5958\n",
      "Epoch 7: val_loss improved from 1.72895 to 1.67890, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 481ms/step - accuracy: 0.4041 - loss: 1.5956 - val_accuracy: 0.3428 - val_loss: 1.6789\n",
      "Epoch 8/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.4287 - loss: 1.5285\n",
      "Epoch 8: val_loss improved from 1.67890 to 1.61849, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 577ms/step - accuracy: 0.4311 - loss: 1.5252 - val_accuracy: 0.3648 - val_loss: 1.6185\n",
      "Epoch 9/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.4856 - loss: 1.4411\n",
      "Epoch 9: val_loss improved from 1.61849 to 1.55921, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 498ms/step - accuracy: 0.4855 - loss: 1.4398 - val_accuracy: 0.3899 - val_loss: 1.5592\n",
      "Epoch 10/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.5684 - loss: 1.3190\n",
      "Epoch 10: val_loss improved from 1.55921 to 1.50041, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 494ms/step - accuracy: 0.5648 - loss: 1.3214 - val_accuracy: 0.4434 - val_loss: 1.5004\n",
      "Epoch 11/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.5626 - loss: 1.2346\n",
      "Epoch 11: val_loss improved from 1.50041 to 1.40895, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 447ms/step - accuracy: 0.5652 - loss: 1.2346 - val_accuracy: 0.4748 - val_loss: 1.4090\n",
      "Epoch 12/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445ms/step - accuracy: 0.6172 - loss: 1.1559\n",
      "Epoch 12: val_loss improved from 1.40895 to 1.36108, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 516ms/step - accuracy: 0.6147 - loss: 1.1569 - val_accuracy: 0.4937 - val_loss: 1.3611\n",
      "Epoch 13/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.6277 - loss: 1.0749\n",
      "Epoch 13: val_loss improved from 1.36108 to 1.29584, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 548ms/step - accuracy: 0.6289 - loss: 1.0740 - val_accuracy: 0.5440 - val_loss: 1.2958\n",
      "Epoch 14/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.6718 - loss: 1.0022\n",
      "Epoch 14: val_loss improved from 1.29584 to 1.22294, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 462ms/step - accuracy: 0.6724 - loss: 0.9992 - val_accuracy: 0.5566 - val_loss: 1.2229\n",
      "Epoch 15/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.7203 - loss: 0.8891\n",
      "Epoch 15: val_loss improved from 1.22294 to 1.14762, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 448ms/step - accuracy: 0.7191 - loss: 0.8883 - val_accuracy: 0.6006 - val_loss: 1.1476\n",
      "Epoch 16/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.7586 - loss: 0.8032\n",
      "Epoch 16: val_loss improved from 1.14762 to 1.04435, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 516ms/step - accuracy: 0.7579 - loss: 0.8042 - val_accuracy: 0.6509 - val_loss: 1.0443\n",
      "Epoch 17/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.7649 - loss: 0.7280\n",
      "Epoch 17: val_loss improved from 1.04435 to 1.00932, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 488ms/step - accuracy: 0.7679 - loss: 0.7259 - val_accuracy: 0.6824 - val_loss: 1.0093\n",
      "Epoch 18/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.8116 - loss: 0.6409\n",
      "Epoch 18: val_loss improved from 1.00932 to 0.94087, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 455ms/step - accuracy: 0.8117 - loss: 0.6398 - val_accuracy: 0.6887 - val_loss: 0.9409\n",
      "Epoch 19/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427ms/step - accuracy: 0.8446 - loss: 0.5238\n",
      "Epoch 19: val_loss improved from 0.94087 to 0.88269, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 547ms/step - accuracy: 0.8425 - loss: 0.5263 - val_accuracy: 0.7075 - val_loss: 0.8827\n",
      "Epoch 20/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8663 - loss: 0.4921\n",
      "Epoch 20: val_loss improved from 0.88269 to 0.75385, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 602ms/step - accuracy: 0.8655 - loss: 0.4937 - val_accuracy: 0.7799 - val_loss: 0.7538\n",
      "Epoch 21/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 0.8803 - loss: 0.4552\n",
      "Epoch 21: val_loss improved from 0.75385 to 0.71580, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 509ms/step - accuracy: 0.8805 - loss: 0.4524 - val_accuracy: 0.7736 - val_loss: 0.7158\n",
      "Epoch 22/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.8965 - loss: 0.3833\n",
      "Epoch 22: val_loss did not improve from 0.71580\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 470ms/step - accuracy: 0.8961 - loss: 0.3853 - val_accuracy: 0.7610 - val_loss: 0.7334\n",
      "Epoch 23/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.9153 - loss: 0.3321\n",
      "Epoch 23: val_loss improved from 0.71580 to 0.60006, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 546ms/step - accuracy: 0.9139 - loss: 0.3360 - val_accuracy: 0.8208 - val_loss: 0.6001\n",
      "Epoch 24/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422ms/step - accuracy: 0.9198 - loss: 0.3213\n",
      "Epoch 24: val_loss improved from 0.60006 to 0.59558, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 525ms/step - accuracy: 0.9199 - loss: 0.3187 - val_accuracy: 0.8365 - val_loss: 0.5956\n",
      "Epoch 25/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 0.9244 - loss: 0.2879\n",
      "Epoch 25: val_loss did not improve from 0.59558\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 492ms/step - accuracy: 0.9250 - loss: 0.2861 - val_accuracy: 0.8208 - val_loss: 0.6267\n",
      "Epoch 26/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.9411 - loss: 0.2632\n",
      "Epoch 26: val_loss improved from 0.59558 to 0.50260, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 434ms/step - accuracy: 0.9421 - loss: 0.2608 - val_accuracy: 0.8711 - val_loss: 0.5026\n",
      "Epoch 27/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.9493 - loss: 0.2167\n",
      "Epoch 27: val_loss improved from 0.50260 to 0.49443, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 509ms/step - accuracy: 0.9486 - loss: 0.2157 - val_accuracy: 0.8648 - val_loss: 0.4944\n",
      "Epoch 28/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.9726 - loss: 0.1750\n",
      "Epoch 28: val_loss did not improve from 0.49443\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 480ms/step - accuracy: 0.9724 - loss: 0.1759 - val_accuracy: 0.8679 - val_loss: 0.4957\n",
      "Epoch 29/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.9605 - loss: 0.1757\n",
      "Epoch 29: val_loss improved from 0.49443 to 0.44950, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 512ms/step - accuracy: 0.9602 - loss: 0.1760 - val_accuracy: 0.8742 - val_loss: 0.4495\n",
      "Epoch 30/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 348ms/step - accuracy: 0.9753 - loss: 0.1479\n",
      "Epoch 30: val_loss did not improve from 0.44950\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 432ms/step - accuracy: 0.9736 - loss: 0.1505 - val_accuracy: 0.8679 - val_loss: 0.4523\n",
      "Epoch 31/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.9664 - loss: 0.1445\n",
      "Epoch 31: val_loss did not improve from 0.44950\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 490ms/step - accuracy: 0.9667 - loss: 0.1439 - val_accuracy: 0.8616 - val_loss: 0.4728\n",
      "Epoch 32/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.9673 - loss: 0.1335\n",
      "Epoch 32: val_loss improved from 0.44950 to 0.41452, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 415ms/step - accuracy: 0.9671 - loss: 0.1336 - val_accuracy: 0.8679 - val_loss: 0.4145\n",
      "Epoch 33/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344ms/step - accuracy: 0.9743 - loss: 0.1169\n",
      "Epoch 33: val_loss did not improve from 0.41452\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 412ms/step - accuracy: 0.9735 - loss: 0.1178 - val_accuracy: 0.8836 - val_loss: 0.4224\n",
      "Epoch 34/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9875 - loss: 0.0889\n",
      "Epoch 34: val_loss did not improve from 0.41452\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 452ms/step - accuracy: 0.9868 - loss: 0.0897 - val_accuracy: 0.8774 - val_loss: 0.4579\n",
      "Epoch 35/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9870 - loss: 0.0834\n",
      "Epoch 35: val_loss improved from 0.41452 to 0.39609, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 386ms/step - accuracy: 0.9866 - loss: 0.0842 - val_accuracy: 0.8962 - val_loss: 0.3961\n",
      "Epoch 36/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9797 - loss: 0.0880\n",
      "Epoch 36: val_loss improved from 0.39609 to 0.36688, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 414ms/step - accuracy: 0.9795 - loss: 0.0891 - val_accuracy: 0.8962 - val_loss: 0.3669\n",
      "Epoch 37/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.9807 - loss: 0.1000\n",
      "Epoch 37: val_loss did not improve from 0.36688\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 430ms/step - accuracy: 0.9801 - loss: 0.1016 - val_accuracy: 0.8994 - val_loss: 0.4178\n",
      "Epoch 38/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292ms/step - accuracy: 0.9628 - loss: 0.1390\n",
      "Epoch 38: val_loss did not improve from 0.36688\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 440ms/step - accuracy: 0.9624 - loss: 0.1430 - val_accuracy: 0.8553 - val_loss: 0.6019\n",
      "Epoch 39/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.9574 - loss: 0.1649\n",
      "Epoch 39: val_loss did not improve from 0.36688\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.9574 - loss: 0.1670 - val_accuracy: 0.8836 - val_loss: 0.4416\n",
      "Epoch 40/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416ms/step - accuracy: 0.9631 - loss: 0.1363\n",
      "Epoch 40: val_loss did not improve from 0.36688\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 485ms/step - accuracy: 0.9641 - loss: 0.1338 - val_accuracy: 0.8994 - val_loss: 0.3907\n",
      "Epoch 41/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9723 - loss: 0.1092\n",
      "Epoch 41: val_loss did not improve from 0.36688\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 491ms/step - accuracy: 0.9715 - loss: 0.1102 - val_accuracy: 0.9119 - val_loss: 0.3915\n",
      "Epoch 42/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9822 - loss: 0.0907\n",
      "Epoch 42: val_loss did not improve from 0.36688\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 391ms/step - accuracy: 0.9812 - loss: 0.0936 - val_accuracy: 0.9088 - val_loss: 0.4555\n",
      "Epoch 43/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - accuracy: 0.9803 - loss: 0.1050\n",
      "Epoch 43: val_loss did not improve from 0.36688\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 479ms/step - accuracy: 0.9795 - loss: 0.1059 - val_accuracy: 0.8742 - val_loss: 0.4855\n",
      "Epoch 44/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423ms/step - accuracy: 0.9686 - loss: 0.1008\n",
      "Epoch 44: val_loss did not improve from 0.36688\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 505ms/step - accuracy: 0.9687 - loss: 0.1017 - val_accuracy: 0.9057 - val_loss: 0.4189\n",
      "Epoch 45/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.9796 - loss: 0.0990\n",
      "Epoch 45: val_loss did not improve from 0.36688\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 462ms/step - accuracy: 0.9796 - loss: 0.0986 - val_accuracy: 0.9088 - val_loss: 0.3795\n",
      "Epoch 46/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.9859 - loss: 0.0784\n",
      "Epoch 46: val_loss improved from 0.36688 to 0.35367, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 496ms/step - accuracy: 0.9855 - loss: 0.0795 - val_accuracy: 0.9151 - val_loss: 0.3537\n",
      "Epoch 47/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.9912 - loss: 0.0587\n",
      "Epoch 47: val_loss did not improve from 0.35367\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 473ms/step - accuracy: 0.9911 - loss: 0.0584 - val_accuracy: 0.9182 - val_loss: 0.3625\n",
      "Epoch 48/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9939 - loss: 0.0534\n",
      "Epoch 48: val_loss improved from 0.35367 to 0.34091, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - accuracy: 0.9936 - loss: 0.0533 - val_accuracy: 0.9245 - val_loss: 0.3409\n",
      "Epoch 49/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358ms/step - accuracy: 0.9962 - loss: 0.0390\n",
      "Epoch 49: val_loss improved from 0.34091 to 0.31567, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 444ms/step - accuracy: 0.9961 - loss: 0.0389 - val_accuracy: 0.9214 - val_loss: 0.3157\n",
      "Epoch 50/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.9964 - loss: 0.0363\n",
      "Epoch 50: val_loss did not improve from 0.31567\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 457ms/step - accuracy: 0.9964 - loss: 0.0362 - val_accuracy: 0.9245 - val_loss: 0.3191\n",
      "Epoch 51/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.9978 - loss: 0.0309\n",
      "Epoch 51: val_loss did not improve from 0.31567\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 556ms/step - accuracy: 0.9978 - loss: 0.0309 - val_accuracy: 0.9277 - val_loss: 0.3325\n",
      "Epoch 52/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.9974 - loss: 0.0230\n",
      "Epoch 52: val_loss did not improve from 0.31567\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 441ms/step - accuracy: 0.9973 - loss: 0.0231 - val_accuracy: 0.9308 - val_loss: 0.3324\n",
      "Epoch 53/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.9982 - loss: 0.0220\n",
      "Epoch 53: val_loss did not improve from 0.31567\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 445ms/step - accuracy: 0.9981 - loss: 0.0225 - val_accuracy: 0.9340 - val_loss: 0.3270\n",
      "Epoch 54/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.9981 - loss: 0.0211\n",
      "Epoch 54: val_loss improved from 0.31567 to 0.30927, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 467ms/step - accuracy: 0.9979 - loss: 0.0217 - val_accuracy: 0.9403 - val_loss: 0.3093\n",
      "Epoch 55/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364ms/step - accuracy: 0.9984 - loss: 0.0205\n",
      "Epoch 55: val_loss did not improve from 0.30927\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 484ms/step - accuracy: 0.9980 - loss: 0.0220 - val_accuracy: 0.9182 - val_loss: 0.3660\n",
      "Epoch 56/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 0.9898 - loss: 0.0380\n",
      "Epoch 56: val_loss did not improve from 0.30927\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 421ms/step - accuracy: 0.9906 - loss: 0.0364 - val_accuracy: 0.9182 - val_loss: 0.3684\n",
      "Epoch 57/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.9942 - loss: 0.0299\n",
      "Epoch 57: val_loss did not improve from 0.30927\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 447ms/step - accuracy: 0.9942 - loss: 0.0298 - val_accuracy: 0.9245 - val_loss: 0.3514\n",
      "Epoch 58/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.9967 - loss: 0.0262\n",
      "Epoch 58: val_loss did not improve from 0.30927\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 451ms/step - accuracy: 0.9966 - loss: 0.0264 - val_accuracy: 0.9214 - val_loss: 0.3561\n",
      "Epoch 59/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9897 - loss: 0.0305\n",
      "Epoch 59: val_loss did not improve from 0.30927\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 387ms/step - accuracy: 0.9904 - loss: 0.0293 - val_accuracy: 0.9308 - val_loss: 0.3392\n",
      "Epoch 60/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.9980 - loss: 0.0211\n",
      "Epoch 60: val_loss did not improve from 0.30927\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 464ms/step - accuracy: 0.9980 - loss: 0.0208 - val_accuracy: 0.9340 - val_loss: 0.3334\n",
      "Epoch 61/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step - accuracy: 0.9987 - loss: 0.0161\n",
      "Epoch 61: val_loss did not improve from 0.30927\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 485ms/step - accuracy: 0.9984 - loss: 0.0165 - val_accuracy: 0.9371 - val_loss: 0.3283\n",
      "Epoch 62/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.9982 - loss: 0.0172\n",
      "Epoch 62: val_loss improved from 0.30927 to 0.30741, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 463ms/step - accuracy: 0.9984 - loss: 0.0167 - val_accuracy: 0.9403 - val_loss: 0.3074\n",
      "Epoch 63/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9994 - loss: 0.0111\n",
      "Epoch 63: val_loss did not improve from 0.30741\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 437ms/step - accuracy: 0.9994 - loss: 0.0112 - val_accuracy: 0.9497 - val_loss: 0.3150\n",
      "Epoch 64/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step - accuracy: 0.9994 - loss: 0.0102\n",
      "Epoch 64: val_loss improved from 0.30741 to 0.30191, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 494ms/step - accuracy: 0.9994 - loss: 0.0104 - val_accuracy: 0.9497 - val_loss: 0.3019\n",
      "Epoch 65/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 1.0000 - loss: 0.0102\n",
      "Epoch 65: val_loss did not improve from 0.30191\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 444ms/step - accuracy: 1.0000 - loss: 0.0102 - val_accuracy: 0.9371 - val_loss: 0.3159\n",
      "Epoch 66/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368ms/step - accuracy: 0.9994 - loss: 0.0093\n",
      "Epoch 66: val_loss did not improve from 0.30191\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 462ms/step - accuracy: 0.9994 - loss: 0.0094 - val_accuracy: 0.9371 - val_loss: 0.3237\n",
      "Epoch 67/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 1.0000 - loss: 0.0077\n",
      "Epoch 67: val_loss did not improve from 0.30191\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 478ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.9403 - val_loss: 0.3112\n",
      "Epoch 68/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 1.0000 - loss: 0.0071\n",
      "Epoch 68: val_loss improved from 0.30191 to 0.29435, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 585ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9434 - val_loss: 0.2943\n",
      "Epoch 69/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 1.0000 - loss: 0.0089\n",
      "Epoch 69: val_loss improved from 0.29435 to 0.28396, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 436ms/step - accuracy: 1.0000 - loss: 0.0087 - val_accuracy: 0.9497 - val_loss: 0.2840\n",
      "Epoch 70/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 1.0000 - loss: 0.0074\n",
      "Epoch 70: val_loss improved from 0.28396 to 0.28161, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 490ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.9497 - val_loss: 0.2816\n",
      "Epoch 71/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 1.0000 - loss: 0.0068\n",
      "Epoch 71: val_loss improved from 0.28161 to 0.27992, saving model to ser_lstm_07_10_2024_16_59_56.keras\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 528ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.9528 - val_loss: 0.2799\n",
      "Epoch 72/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.9982 - loss: 0.0088\n",
      "Epoch 72: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 446ms/step - accuracy: 0.9984 - loss: 0.0084 - val_accuracy: 0.9528 - val_loss: 0.2806\n",
      "Epoch 73/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 73: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 458ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.9465 - val_loss: 0.2844\n",
      "Epoch 74/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step - accuracy: 1.0000 - loss: 0.0059\n",
      "Epoch 74: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 467ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9465 - val_loss: 0.2913\n",
      "Epoch 75/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 1.0000 - loss: 0.0063\n",
      "Epoch 75: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 515ms/step - accuracy: 1.0000 - loss: 0.0063 - val_accuracy: 0.9434 - val_loss: 0.2999\n",
      "Epoch 76/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 1.0000 - loss: 0.0053\n",
      "Epoch 76: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 432ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.9371 - val_loss: 0.2998\n",
      "Epoch 77/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 1.0000 - loss: 0.0058\n",
      "Epoch 77: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 479ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.9403 - val_loss: 0.3028\n",
      "Epoch 78/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 78: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 436ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9403 - val_loss: 0.3064\n",
      "Epoch 79/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - accuracy: 1.0000 - loss: 0.0048\n",
      "Epoch 79: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 398ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 0.9403 - val_loss: 0.3087\n",
      "Epoch 80/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 80: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 522ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9434 - val_loss: 0.3078\n",
      "Epoch 81/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 1.0000 - loss: 0.0040\n",
      "Epoch 81: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 402ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.9434 - val_loss: 0.3082\n",
      "Epoch 82/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 1.0000 - loss: 0.0045\n",
      "Epoch 82: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 438ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.9403 - val_loss: 0.3063\n",
      "Epoch 83/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 1.0000 - loss: 0.0035\n",
      "Epoch 83: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 466ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.9465 - val_loss: 0.3033\n",
      "Epoch 84/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 1.0000 - loss: 0.0038\n",
      "Epoch 84: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 582ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.9434 - val_loss: 0.3038\n",
      "Epoch 85/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 1.0000 - loss: 0.0041\n",
      "Epoch 85: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 470ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9465 - val_loss: 0.3058\n",
      "Epoch 86/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 1.0000 - loss: 0.0039\n",
      "Epoch 86: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 443ms/step - accuracy: 1.0000 - loss: 0.0039 - val_accuracy: 0.9528 - val_loss: 0.3026\n",
      "Epoch 87/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 335ms/step - accuracy: 1.0000 - loss: 0.0047\n",
      "Epoch 87: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 520ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.9528 - val_loss: 0.2985\n",
      "Epoch 88/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 1.0000 - loss: 0.0037\n",
      "Epoch 88: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 409ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.9497 - val_loss: 0.2960\n",
      "Epoch 89/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.9996 - loss: 0.0031\n",
      "Epoch 89: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 426ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9497 - val_loss: 0.2949\n",
      "Epoch 90/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396ms/step - accuracy: 1.0000 - loss: 0.0024\n",
      "Epoch 90: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 491ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.9497 - val_loss: 0.2953\n",
      "Epoch 91/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step - accuracy: 1.0000 - loss: 0.0030\n",
      "Epoch 91: val_loss did not improve from 0.27992\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 485ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.9465 - val_loss: 0.2957\n",
      "Epoch 91: early stopping\n",
      "Restoring model weights from the end of the best epoch: 71.\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9693 - loss: 0.2218\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9693 - loss: 0.2218\n",
      "Loss : 0.2476116567850113, Accuracy : 0.9661017060279846\n"
     ]
    }
   ],
   "source": [
    "X_train,X_val,X_test,y_train,y_val,y_test = train_val_test(X_logmel_semi_aug.squeeze(3),Y_semi_aug)\n",
    "LSTM_model = get_model(X_train.shape[1:])\n",
    "# LSTM_model.summary()\n",
    "\n",
    "\n",
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"ser_lstm_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "LSTM_history = LSTM_model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=256,\n",
    "                       epochs=1000,\n",
    "                       verbose=1,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {LSTM_model.evaluate(X_test,y_test)[0]}, Accuracy : {LSTM_model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372ms/step - accuracy: 0.1576 - loss: 1.9808\n",
      "Epoch 1: val_loss improved from inf to 1.88135, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 619ms/step - accuracy: 0.1587 - loss: 1.9784 - val_accuracy: 0.2406 - val_loss: 1.8814\n",
      "Epoch 2/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418ms/step - accuracy: 0.2422 - loss: 1.8577\n",
      "Epoch 2: val_loss improved from 1.88135 to 1.81651, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 475ms/step - accuracy: 0.2430 - loss: 1.8574 - val_accuracy: 0.3113 - val_loss: 1.8165\n",
      "Epoch 3/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.2844 - loss: 1.8015\n",
      "Epoch 3: val_loss improved from 1.81651 to 1.74696, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 408ms/step - accuracy: 0.2861 - loss: 1.8007 - val_accuracy: 0.3443 - val_loss: 1.7470\n",
      "Epoch 4/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.3289 - loss: 1.7188\n",
      "Epoch 4: val_loss improved from 1.74696 to 1.68218, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 417ms/step - accuracy: 0.3303 - loss: 1.7175 - val_accuracy: 0.3467 - val_loss: 1.6822\n",
      "Epoch 5/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.3567 - loss: 1.6392\n",
      "Epoch 5: val_loss improved from 1.68218 to 1.63052, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 415ms/step - accuracy: 0.3580 - loss: 1.6380 - val_accuracy: 0.3726 - val_loss: 1.6305\n",
      "Epoch 6/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.4264 - loss: 1.5351\n",
      "Epoch 6: val_loss improved from 1.63052 to 1.56597, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 429ms/step - accuracy: 0.4253 - loss: 1.5354 - val_accuracy: 0.3844 - val_loss: 1.5660\n",
      "Epoch 7/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - accuracy: 0.4589 - loss: 1.4606\n",
      "Epoch 7: val_loss improved from 1.56597 to 1.48538, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 494ms/step - accuracy: 0.4612 - loss: 1.4559 - val_accuracy: 0.4316 - val_loss: 1.4854\n",
      "Epoch 8/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.4948 - loss: 1.3561\n",
      "Epoch 8: val_loss improved from 1.48538 to 1.40491, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 490ms/step - accuracy: 0.4952 - loss: 1.3553 - val_accuracy: 0.4811 - val_loss: 1.4049\n",
      "Epoch 9/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.5222 - loss: 1.2850\n",
      "Epoch 9: val_loss improved from 1.40491 to 1.33639, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 489ms/step - accuracy: 0.5258 - loss: 1.2801 - val_accuracy: 0.5047 - val_loss: 1.3364\n",
      "Epoch 10/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 0.6250 - loss: 1.1245\n",
      "Epoch 10: val_loss improved from 1.33639 to 1.23524, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 486ms/step - accuracy: 0.6261 - loss: 1.1213 - val_accuracy: 0.5660 - val_loss: 1.2352\n",
      "Epoch 11/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - accuracy: 0.6489 - loss: 1.0017\n",
      "Epoch 11: val_loss improved from 1.23524 to 1.15268, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 503ms/step - accuracy: 0.6492 - loss: 1.0012 - val_accuracy: 0.5991 - val_loss: 1.1527\n",
      "Epoch 12/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step - accuracy: 0.6872 - loss: 0.9208\n",
      "Epoch 12: val_loss improved from 1.15268 to 1.10709, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 479ms/step - accuracy: 0.6878 - loss: 0.9196 - val_accuracy: 0.6156 - val_loss: 1.1071\n",
      "Epoch 13/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.7286 - loss: 0.8130\n",
      "Epoch 13: val_loss improved from 1.10709 to 1.00289, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 558ms/step - accuracy: 0.7303 - loss: 0.8100 - val_accuracy: 0.6651 - val_loss: 1.0029\n",
      "Epoch 14/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.7760 - loss: 0.7169\n",
      "Epoch 14: val_loss improved from 1.00289 to 0.89445, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 451ms/step - accuracy: 0.7771 - loss: 0.7131 - val_accuracy: 0.6863 - val_loss: 0.8944\n",
      "Epoch 15/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step - accuracy: 0.8177 - loss: 0.5851\n",
      "Epoch 15: val_loss improved from 0.89445 to 0.80629, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 366ms/step - accuracy: 0.8181 - loss: 0.5854 - val_accuracy: 0.7406 - val_loss: 0.8063\n",
      "Epoch 16/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 324ms/step - accuracy: 0.8461 - loss: 0.5168\n",
      "Epoch 16: val_loss improved from 0.80629 to 0.74256, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 395ms/step - accuracy: 0.8462 - loss: 0.5152 - val_accuracy: 0.7759 - val_loss: 0.7426\n",
      "Epoch 17/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.8823 - loss: 0.4376\n",
      "Epoch 17: val_loss improved from 0.74256 to 0.68664, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 415ms/step - accuracy: 0.8818 - loss: 0.4371 - val_accuracy: 0.7948 - val_loss: 0.6866\n",
      "Epoch 18/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.9043 - loss: 0.3639\n",
      "Epoch 18: val_loss improved from 0.68664 to 0.67965, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 406ms/step - accuracy: 0.9036 - loss: 0.3640 - val_accuracy: 0.8019 - val_loss: 0.6797\n",
      "Epoch 19/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.9142 - loss: 0.3084\n",
      "Epoch 19: val_loss improved from 0.67965 to 0.60955, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 470ms/step - accuracy: 0.9137 - loss: 0.3100 - val_accuracy: 0.8160 - val_loss: 0.6095\n",
      "Epoch 20/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.9304 - loss: 0.2788\n",
      "Epoch 20: val_loss improved from 0.60955 to 0.59881, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 437ms/step - accuracy: 0.9301 - loss: 0.2801 - val_accuracy: 0.8349 - val_loss: 0.5988\n",
      "Epoch 21/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9282 - loss: 0.2785\n",
      "Epoch 21: val_loss improved from 0.59881 to 0.58429, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 416ms/step - accuracy: 0.9283 - loss: 0.2779 - val_accuracy: 0.8302 - val_loss: 0.5843\n",
      "Epoch 22/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 352ms/step - accuracy: 0.9381 - loss: 0.2467\n",
      "Epoch 22: val_loss improved from 0.58429 to 0.56458, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 503ms/step - accuracy: 0.9371 - loss: 0.2479 - val_accuracy: 0.8349 - val_loss: 0.5646\n",
      "Epoch 23/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365ms/step - accuracy: 0.9382 - loss: 0.2518\n",
      "Epoch 23: val_loss improved from 0.56458 to 0.52828, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 477ms/step - accuracy: 0.9378 - loss: 0.2508 - val_accuracy: 0.8349 - val_loss: 0.5283\n",
      "Epoch 24/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.9369 - loss: 0.2285\n",
      "Epoch 24: val_loss improved from 0.52828 to 0.47954, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 518ms/step - accuracy: 0.9358 - loss: 0.2304 - val_accuracy: 0.8538 - val_loss: 0.4795\n",
      "Epoch 25/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.9384 - loss: 0.2082\n",
      "Epoch 25: val_loss did not improve from 0.47954\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 421ms/step - accuracy: 0.9382 - loss: 0.2095 - val_accuracy: 0.8679 - val_loss: 0.5148\n",
      "Epoch 26/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 0.9467 - loss: 0.2120\n",
      "Epoch 26: val_loss did not improve from 0.47954\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 406ms/step - accuracy: 0.9471 - loss: 0.2111 - val_accuracy: 0.8561 - val_loss: 0.5176\n",
      "Epoch 27/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 342ms/step - accuracy: 0.9635 - loss: 0.1737\n",
      "Epoch 27: val_loss improved from 0.47954 to 0.47327, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 400ms/step - accuracy: 0.9630 - loss: 0.1731 - val_accuracy: 0.8679 - val_loss: 0.4733\n",
      "Epoch 28/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398ms/step - accuracy: 0.9561 - loss: 0.1552\n",
      "Epoch 28: val_loss improved from 0.47327 to 0.40765, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 497ms/step - accuracy: 0.9558 - loss: 0.1560 - val_accuracy: 0.9033 - val_loss: 0.4076\n",
      "Epoch 29/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step - accuracy: 0.9612 - loss: 0.1479\n",
      "Epoch 29: val_loss did not improve from 0.40765\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 447ms/step - accuracy: 0.9611 - loss: 0.1478 - val_accuracy: 0.9033 - val_loss: 0.4502\n",
      "Epoch 30/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424ms/step - accuracy: 0.9705 - loss: 0.1205\n",
      "Epoch 30: val_loss did not improve from 0.40765\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 512ms/step - accuracy: 0.9701 - loss: 0.1215 - val_accuracy: 0.8892 - val_loss: 0.4248\n",
      "Epoch 31/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 357ms/step - accuracy: 0.9661 - loss: 0.1287\n",
      "Epoch 31: val_loss did not improve from 0.40765\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 510ms/step - accuracy: 0.9651 - loss: 0.1306 - val_accuracy: 0.8491 - val_loss: 0.4979\n",
      "Epoch 32/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.9638 - loss: 0.1336\n",
      "Epoch 32: val_loss did not improve from 0.40765\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 507ms/step - accuracy: 0.9641 - loss: 0.1333 - val_accuracy: 0.8892 - val_loss: 0.4114\n",
      "Epoch 33/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356ms/step - accuracy: 0.9797 - loss: 0.1094\n",
      "Epoch 33: val_loss did not improve from 0.40765\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 465ms/step - accuracy: 0.9792 - loss: 0.1104 - val_accuracy: 0.8986 - val_loss: 0.4282\n",
      "Epoch 34/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 360ms/step - accuracy: 0.9779 - loss: 0.0883\n",
      "Epoch 34: val_loss improved from 0.40765 to 0.35026, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 497ms/step - accuracy: 0.9775 - loss: 0.0894 - val_accuracy: 0.9175 - val_loss: 0.3503\n",
      "Epoch 35/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.9819 - loss: 0.0792\n",
      "Epoch 35: val_loss improved from 0.35026 to 0.30451, saving model to ser_lstm_07_10_2024_17_04_19.keras\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 498ms/step - accuracy: 0.9816 - loss: 0.0795 - val_accuracy: 0.9269 - val_loss: 0.3045\n",
      "Epoch 36/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.9905 - loss: 0.0571\n",
      "Epoch 36: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 470ms/step - accuracy: 0.9900 - loss: 0.0576 - val_accuracy: 0.9175 - val_loss: 0.3346\n",
      "Epoch 37/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.9970 - loss: 0.0453\n",
      "Epoch 37: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 473ms/step - accuracy: 0.9969 - loss: 0.0456 - val_accuracy: 0.9269 - val_loss: 0.3389\n",
      "Epoch 38/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.9974 - loss: 0.0375\n",
      "Epoch 38: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 433ms/step - accuracy: 0.9969 - loss: 0.0382 - val_accuracy: 0.9175 - val_loss: 0.3410\n",
      "Epoch 39/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9887 - loss: 0.0557\n",
      "Epoch 39: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 393ms/step - accuracy: 0.9884 - loss: 0.0569 - val_accuracy: 0.9292 - val_loss: 0.3335\n",
      "Epoch 40/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395ms/step - accuracy: 0.9919 - loss: 0.0499\n",
      "Epoch 40: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 422ms/step - accuracy: 0.9917 - loss: 0.0510 - val_accuracy: 0.9222 - val_loss: 0.3153\n",
      "Epoch 41/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9938 - loss: 0.0419\n",
      "Epoch 41: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 423ms/step - accuracy: 0.9936 - loss: 0.0427 - val_accuracy: 0.9009 - val_loss: 0.3878\n",
      "Epoch 42/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.9949 - loss: 0.0384\n",
      "Epoch 42: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 427ms/step - accuracy: 0.9949 - loss: 0.0382 - val_accuracy: 0.9198 - val_loss: 0.3597\n",
      "Epoch 43/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step - accuracy: 0.9956 - loss: 0.0360\n",
      "Epoch 43: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 605ms/step - accuracy: 0.9953 - loss: 0.0373 - val_accuracy: 0.9292 - val_loss: 0.3331\n",
      "Epoch 44/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 338ms/step - accuracy: 0.9950 - loss: 0.0284\n",
      "Epoch 44: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 490ms/step - accuracy: 0.9951 - loss: 0.0284 - val_accuracy: 0.9340 - val_loss: 0.3972\n",
      "Epoch 45/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9977 - loss: 0.0243\n",
      "Epoch 45: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 401ms/step - accuracy: 0.9976 - loss: 0.0245 - val_accuracy: 0.9292 - val_loss: 0.3405\n",
      "Epoch 46/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.9971 - loss: 0.0213\n",
      "Epoch 46: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 511ms/step - accuracy: 0.9971 - loss: 0.0212 - val_accuracy: 0.9245 - val_loss: 0.3442\n",
      "Epoch 47/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9960 - loss: 0.0236\n",
      "Epoch 47: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 411ms/step - accuracy: 0.9960 - loss: 0.0236 - val_accuracy: 0.9245 - val_loss: 0.3718\n",
      "Epoch 48/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289ms/step - accuracy: 0.9980 - loss: 0.0250\n",
      "Epoch 48: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - accuracy: 0.9980 - loss: 0.0247 - val_accuracy: 0.9269 - val_loss: 0.4072\n",
      "Epoch 49/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 0.9992 - loss: 0.0159\n",
      "Epoch 49: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 337ms/step - accuracy: 0.9991 - loss: 0.0159 - val_accuracy: 0.9340 - val_loss: 0.3514\n",
      "Epoch 50/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.9996 - loss: 0.0130\n",
      "Epoch 50: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 380ms/step - accuracy: 0.9996 - loss: 0.0131 - val_accuracy: 0.9316 - val_loss: 0.3170\n",
      "Epoch 51/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9985 - loss: 0.0110\n",
      "Epoch 51: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 341ms/step - accuracy: 0.9987 - loss: 0.0110 - val_accuracy: 0.9269 - val_loss: 0.3343\n",
      "Epoch 52/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 314ms/step - accuracy: 0.9985 - loss: 0.0139\n",
      "Epoch 52: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 422ms/step - accuracy: 0.9984 - loss: 0.0139 - val_accuracy: 0.9316 - val_loss: 0.3463\n",
      "Epoch 53/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9998 - loss: 0.0090\n",
      "Epoch 53: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 442ms/step - accuracy: 0.9998 - loss: 0.0090 - val_accuracy: 0.9292 - val_loss: 0.3322\n",
      "Epoch 54/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 1.0000 - loss: 0.0092\n",
      "Epoch 54: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 412ms/step - accuracy: 1.0000 - loss: 0.0092 - val_accuracy: 0.9340 - val_loss: 0.3146\n",
      "Epoch 55/1000\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.9996 - loss: 0.0087\n",
      "Epoch 55: val_loss did not improve from 0.30451\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 455ms/step - accuracy: 0.9996 - loss: 0.0087 - val_accuracy: 0.9340 - val_loss: 0.3217\n",
      "Epoch 55: early stopping\n",
      "Restoring model weights from the end of the best epoch: 35.\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9122 - loss: 0.2667\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9122 - loss: 0.2667\n",
      "Loss : 0.2642170190811157, Accuracy : 0.9194915294647217\n"
     ]
    }
   ],
   "source": [
    "X_train,X_val,X_test,y_train,y_val,y_test = train_val_test(X_logmel_aug.squeeze(3),Y_aug)\n",
    "LSTM_model = get_model(X_train.shape[1:])\n",
    "# LSTM_model.summary()\n",
    "\n",
    "\n",
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"ser_lstm_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.001,\n",
    "        patience=20,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "LSTM_history = LSTM_model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=256,\n",
    "                       epochs=1000,\n",
    "                       verbose=1,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {LSTM_model.evaluate(X_test,y_test)[0]}, Accuracy : {LSTM_model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "X_train,X_val,X_test,y_train,y_val,y_test = train_val_test(X_logmel.squeeze(3),Y_not_aug)\n",
    "X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "\n",
    "\n",
    "SVC_model = SVC(kernel = 'rbf', gamma = 'auto', probability = True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32653061224489793"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC_history = SVC_model.fit(X_train, np.argmax(y_train,axis=-1))\n",
    "SVC_model.score(X_test,np.argmax(y_test,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6384180790960452"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "X_train,X_val,X_test,y_train,y_val,y_test = train_val_test(X_logmel_semi_aug.squeeze(3),Y_semi_aug)\n",
    "X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "\n",
    "\n",
    "SVC_model = SVC(kernel = 'rbf', gamma = 'auto', probability = True, verbose=True)\n",
    "\n",
    "\n",
    "SVC_history = SVC_model.fit(X_train, np.argmax(y_train,axis=-1))\n",
    "SVC_model.score(X_test,np.argmax(y_test,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7966101694915254"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "X_train,X_val,X_test,y_train,y_val,y_test = train_val_test(X_logmel_aug.squeeze(3),Y_aug)\n",
    "X_train = X_train.reshape(X_train.shape[0],-1)\n",
    "X_test = X_test.reshape(X_test.shape[0],-1)\n",
    "\n",
    "\n",
    "SVC_model = SVC(kernel = 'rbf', gamma = 'auto', probability = True, verbose=True)\n",
    "\n",
    "SVC_history = SVC_model.fit(X_train, np.argmax(y_train,axis=-1))\n",
    "SVC_model.score(X_test,np.argmax(y_test,axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
