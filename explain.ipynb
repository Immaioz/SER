{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import librosa\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from typing import Tuple, Union\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"EMOVO_dataset/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_min(files):\n",
    "    min_, max_ = 100, 0\n",
    "    for file in files:\n",
    "        sound_file, samplerate = librosa.load(file)\n",
    "        t = sound_file.shape[0] / samplerate\n",
    "        if t < min_:\n",
    "            min_ = t\n",
    "        if t > max_:\n",
    "            max_ = t\n",
    "\n",
    "    return max_, min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file,pad):\n",
    "    X, sample_rate = librosa.load(file)\n",
    "    max_ = X.shape[0] / sample_rate\n",
    "    if pad:\n",
    "        length = (max_ * sample_rate) - X.shape[0]\n",
    "        X = np.pad(X, (0, int(length)), 'constant')\n",
    "    \n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    result = np.array([])\n",
    "\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=50).T, axis=0)\n",
    "    result = np.hstack((result, mfccs))\n",
    "\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, chroma))\n",
    "    \n",
    "    mel = np.mean(librosa.feature.melspectrogram(y=X, sr=sample_rate).T, axis=0) \n",
    "    result = np.hstack((result, mel))\n",
    "    \n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T, axis=0)\n",
    "    result = np.hstack((result, contrast))\n",
    "    \n",
    "    # tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    # result = np.hstack((result, tonnetz))\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max, min = get_max_min('EMOVO_dataset/'+data_df.file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = extract('EMOVO_dataset/'+data_df.file_name[0], max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-407.066681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43.688465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.330512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.860258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.041548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>17.163601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>16.742468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>16.851534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>16.808489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>47.624574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0   -407.066681\n",
       "1     43.688465\n",
       "2      0.330512\n",
       "3      8.860258\n",
       "4      9.041548\n",
       "..          ...\n",
       "192   17.163601\n",
       "193   16.742468\n",
       "194   16.851534\n",
       "195   16.808489\n",
       "196   47.624574\n",
       "\n",
       "[197 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(columns=['filename', 'features', 'label'])\n",
    "\n",
    "features = []\n",
    "for index, file in zip(data_df.index, data_df.file_name):\n",
    "    train_data.loc[index] = [file, extract('EMOVO_dataset/'+file, max), data_df.label[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1/dis-f1-b1.wav</td>\n",
       "      <td>0\n",
       "0   -407.066681\n",
       "1     43.68846...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1/dis-f1-b2.wav</td>\n",
       "      <td>0\n",
       "0   -406.009399\n",
       "1     35.83183...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1/dis-f1-b3.wav</td>\n",
       "      <td>0\n",
       "0   -393.554535\n",
       "1     58.40808...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1/dis-f1-d1.wav</td>\n",
       "      <td>0\n",
       "0   -395.404083\n",
       "1     67.96301...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1/dis-f1-d2.wav</td>\n",
       "      <td>0\n",
       "0   -450.395935\n",
       "1     69.13523...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>m3/tri-m3-n1.wav</td>\n",
       "      <td>0\n",
       "0   -442.870667\n",
       "1    106.22269...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>m3/tri-m3-n2.wav</td>\n",
       "      <td>0\n",
       "0   -464.318817\n",
       "1     81.76235...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>m3/tri-m3-n3.wav</td>\n",
       "      <td>0\n",
       "0   -493.679565\n",
       "1     84.39754...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>m3/tri-m3-n4.wav</td>\n",
       "      <td>0\n",
       "0   -528.805054\n",
       "1     75.34912...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>m3/tri-m3-n5.wav</td>\n",
       "      <td>0\n",
       "0   -534.222717\n",
       "1     83.88175...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             filename                                           features  \\\n",
       "0    f1/dis-f1-b1.wav                0\n",
       "0   -407.066681\n",
       "1     43.68846...   \n",
       "1    f1/dis-f1-b2.wav                0\n",
       "0   -406.009399\n",
       "1     35.83183...   \n",
       "2    f1/dis-f1-b3.wav                0\n",
       "0   -393.554535\n",
       "1     58.40808...   \n",
       "3    f1/dis-f1-d1.wav                0\n",
       "0   -395.404083\n",
       "1     67.96301...   \n",
       "4    f1/dis-f1-d2.wav                0\n",
       "0   -450.395935\n",
       "1     69.13523...   \n",
       "..                ...                                                ...   \n",
       "583  m3/tri-m3-n1.wav                0\n",
       "0   -442.870667\n",
       "1    106.22269...   \n",
       "584  m3/tri-m3-n2.wav                0\n",
       "0   -464.318817\n",
       "1     81.76235...   \n",
       "585  m3/tri-m3-n3.wav                0\n",
       "0   -493.679565\n",
       "1     84.39754...   \n",
       "586  m3/tri-m3-n4.wav                0\n",
       "0   -528.805054\n",
       "1     75.34912...   \n",
       "587  m3/tri-m3-n5.wav                0\n",
       "0   -534.222717\n",
       "1     83.88175...   \n",
       "\n",
       "       label  \n",
       "0    disgust  \n",
       "1    disgust  \n",
       "2    disgust  \n",
       "3    disgust  \n",
       "4    disgust  \n",
       "..       ...  \n",
       "583  sadness  \n",
       "584  sadness  \n",
       "585  sadness  \n",
       "586  sadness  \n",
       "587  sadness  \n",
       "\n",
       "[588 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "data_classes = (list((train_data[\"label\"].unique())))\n",
    "Y = to_categorical(list((train_data[\"label\"].apply(data_classes.index))))\n",
    "# X = pd.DataFrame(train_data[\"features\"])\n",
    "\n",
    "X = np.array(train_data[\"features\"])\n",
    "\n",
    "X = np.stack(train_data[\"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=22)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=22)\n",
    "\n",
    "input_shape = (X_train.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(588, 197, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.Sequential()\n",
    "kernel_sizes = [5, 5]\n",
    "model.add(keras.layers.Input(shape=input_shape))\n",
    "for size in kernel_sizes:\n",
    "    model.add(keras.layers.Conv1D(\n",
    "        filters = 32,\n",
    "        kernel_size = size,\n",
    "        padding = 'same'\n",
    "    )) \n",
    "    model.add(keras.layers.BatchNormalization(axis=-1))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32))\n",
    "model.add(keras.layers.BatchNormalization(axis = -1))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))  # 分类层\n",
    "optimzer = keras.optimizers.Adam(learning_rate= 0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimzer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.1602 - loss: 2.5228\n",
      "Epoch 1: val_loss improved from inf to 3.71491, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 222ms/step - accuracy: 0.1401 - loss: 2.5812 - val_accuracy: 0.0849 - val_loss: 3.7149\n",
      "Epoch 2/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1328 - loss: 2.3597\n",
      "Epoch 2: val_loss improved from 3.71491 to 3.03836, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.1341 - loss: 2.3719 - val_accuracy: 0.0943 - val_loss: 3.0384\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1562 - loss: 2.5953\n",
      "Epoch 3: val_loss improved from 3.03836 to 2.72056, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.1813 - loss: 2.4748 - val_accuracy: 0.1509 - val_loss: 2.7206\n",
      "Epoch 4/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1484 - loss: 2.4432\n",
      "Epoch 4: val_loss improved from 2.72056 to 2.50025, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.1582 - loss: 2.3992 - val_accuracy: 0.2830 - val_loss: 2.5002\n",
      "Epoch 5/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1836 - loss: 2.2118\n",
      "Epoch 5: val_loss improved from 2.50025 to 2.36446, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.1920 - loss: 2.2062 - val_accuracy: 0.2642 - val_loss: 2.3645\n",
      "Epoch 6/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2188 - loss: 2.1148\n",
      "Epoch 6: val_loss improved from 2.36446 to 2.26516, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.2069 - loss: 2.1644 - val_accuracy: 0.2736 - val_loss: 2.2652\n",
      "Epoch 7/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1914 - loss: 2.2195\n",
      "Epoch 7: val_loss improved from 2.26516 to 2.20823, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.1993 - loss: 2.1819 - val_accuracy: 0.2830 - val_loss: 2.2082\n",
      "Epoch 8/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2500 - loss: 1.9994\n",
      "Epoch 8: val_loss improved from 2.20823 to 2.15944, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.2441 - loss: 2.0060 - val_accuracy: 0.3019 - val_loss: 2.1594\n",
      "Epoch 9/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2383 - loss: 2.0331\n",
      "Epoch 9: val_loss improved from 2.15944 to 2.07791, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.2481 - loss: 2.0417 - val_accuracy: 0.3019 - val_loss: 2.0779\n",
      "Epoch 10/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2266 - loss: 2.0166\n",
      "Epoch 10: val_loss improved from 2.07791 to 2.00347, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2237 - loss: 2.0363 - val_accuracy: 0.3113 - val_loss: 2.0035\n",
      "Epoch 11/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2031 - loss: 2.1171\n",
      "Epoch 11: val_loss improved from 2.00347 to 1.93220, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.2048 - loss: 2.1081 - val_accuracy: 0.3396 - val_loss: 1.9322\n",
      "Epoch 12/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2852 - loss: 1.9342\n",
      "Epoch 12: val_loss improved from 1.93220 to 1.86836, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.2716 - loss: 1.9800 - val_accuracy: 0.3396 - val_loss: 1.8684\n",
      "Epoch 13/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2578 - loss: 1.9792\n",
      "Epoch 13: val_loss improved from 1.86836 to 1.81633, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.2751 - loss: 1.9444 - val_accuracy: 0.3585 - val_loss: 1.8163\n",
      "Epoch 14/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.2773 - loss: 1.8144\n",
      "Epoch 14: val_loss improved from 1.81633 to 1.76419, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.2768 - loss: 1.8421 - val_accuracy: 0.3962 - val_loss: 1.7642\n",
      "Epoch 15/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2578 - loss: 1.9058\n",
      "Epoch 15: val_loss improved from 1.76419 to 1.70796, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.2514 - loss: 1.9185 - val_accuracy: 0.4057 - val_loss: 1.7080\n",
      "Epoch 16/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3047 - loss: 1.8355\n",
      "Epoch 16: val_loss improved from 1.70796 to 1.65453, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.2954 - loss: 1.8473 - val_accuracy: 0.4245 - val_loss: 1.6545\n",
      "Epoch 17/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2852 - loss: 1.8955\n",
      "Epoch 17: val_loss improved from 1.65453 to 1.61424, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.2810 - loss: 1.9032 - val_accuracy: 0.4434 - val_loss: 1.6142\n",
      "Epoch 18/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3086 - loss: 1.8368\n",
      "Epoch 18: val_loss improved from 1.61424 to 1.58020, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.3093 - loss: 1.8311 - val_accuracy: 0.4528 - val_loss: 1.5802\n",
      "Epoch 19/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3164 - loss: 1.7719\n",
      "Epoch 19: val_loss improved from 1.58020 to 1.55281, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3025 - loss: 1.7965 - val_accuracy: 0.4340 - val_loss: 1.5528\n",
      "Epoch 20/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3125 - loss: 1.7551\n",
      "Epoch 20: val_loss improved from 1.55281 to 1.53686, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.3154 - loss: 1.7573 - val_accuracy: 0.4434 - val_loss: 1.5369\n",
      "Epoch 21/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3008 - loss: 1.8811\n",
      "Epoch 21: val_loss improved from 1.53686 to 1.52366, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3193 - loss: 1.8410 - val_accuracy: 0.4528 - val_loss: 1.5237\n",
      "Epoch 22/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3086 - loss: 1.7073\n",
      "Epoch 22: val_loss improved from 1.52366 to 1.51723, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.3156 - loss: 1.7189 - val_accuracy: 0.4434 - val_loss: 1.5172\n",
      "Epoch 23/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3594 - loss: 1.6658\n",
      "Epoch 23: val_loss improved from 1.51723 to 1.51337, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3530 - loss: 1.6712 - val_accuracy: 0.4340 - val_loss: 1.5134\n",
      "Epoch 24/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3672 - loss: 1.6064\n",
      "Epoch 24: val_loss improved from 1.51337 to 1.51284, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.3714 - loss: 1.6219 - val_accuracy: 0.4245 - val_loss: 1.5128\n",
      "Epoch 25/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3594 - loss: 1.6563\n",
      "Epoch 25: val_loss did not improve from 1.51284\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3594 - loss: 1.6447 - val_accuracy: 0.4245 - val_loss: 1.5144\n",
      "Epoch 26/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.3789 - loss: 1.6051\n",
      "Epoch 26: val_loss did not improve from 1.51284\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.3722 - loss: 1.6226 - val_accuracy: 0.4151 - val_loss: 1.5156\n",
      "Epoch 27/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4453 - loss: 1.5803\n",
      "Epoch 27: val_loss did not improve from 1.51284\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4605 - loss: 1.5524 - val_accuracy: 0.4151 - val_loss: 1.5164\n",
      "Epoch 28/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4062 - loss: 1.5563\n",
      "Epoch 28: val_loss did not improve from 1.51284\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.4018 - loss: 1.5578 - val_accuracy: 0.4151 - val_loss: 1.5140\n",
      "Epoch 29/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.4062 - loss: 1.5882\n",
      "Epoch 29: val_loss improved from 1.51284 to 1.50926, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.3876 - loss: 1.6284 - val_accuracy: 0.4151 - val_loss: 1.5093\n",
      "Epoch 30/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.3711 - loss: 1.5522\n",
      "Epoch 30: val_loss improved from 1.50926 to 1.50580, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.3837 - loss: 1.5394 - val_accuracy: 0.4151 - val_loss: 1.5058\n",
      "Epoch 31/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3867 - loss: 1.5211\n",
      "Epoch 31: val_loss improved from 1.50580 to 1.50107, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4000 - loss: 1.5155 - val_accuracy: 0.4151 - val_loss: 1.5011\n",
      "Epoch 32/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4102 - loss: 1.6040\n",
      "Epoch 32: val_loss improved from 1.50107 to 1.49664, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.4267 - loss: 1.5531 - val_accuracy: 0.4057 - val_loss: 1.4966\n",
      "Epoch 33/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4336 - loss: 1.4607\n",
      "Epoch 33: val_loss improved from 1.49664 to 1.49007, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4361 - loss: 1.4727 - val_accuracy: 0.4057 - val_loss: 1.4901\n",
      "Epoch 34/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4062 - loss: 1.5112\n",
      "Epoch 34: val_loss improved from 1.49007 to 1.48099, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4128 - loss: 1.5158 - val_accuracy: 0.4057 - val_loss: 1.4810\n",
      "Epoch 35/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4570 - loss: 1.4353\n",
      "Epoch 35: val_loss improved from 1.48099 to 1.47152, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.4423 - loss: 1.4642 - val_accuracy: 0.4151 - val_loss: 1.4715\n",
      "Epoch 36/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.3750 - loss: 1.5276\n",
      "Epoch 36: val_loss improved from 1.47152 to 1.46249, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.3819 - loss: 1.5423 - val_accuracy: 0.4151 - val_loss: 1.4625\n",
      "Epoch 37/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4219 - loss: 1.4284\n",
      "Epoch 37: val_loss improved from 1.46249 to 1.45549, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4227 - loss: 1.4371 - val_accuracy: 0.4151 - val_loss: 1.4555\n",
      "Epoch 38/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4258 - loss: 1.5064\n",
      "Epoch 38: val_loss improved from 1.45549 to 1.44988, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4177 - loss: 1.5013 - val_accuracy: 0.4151 - val_loss: 1.4499\n",
      "Epoch 39/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4609 - loss: 1.4378\n",
      "Epoch 39: val_loss improved from 1.44988 to 1.44389, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4641 - loss: 1.4247 - val_accuracy: 0.3962 - val_loss: 1.4439\n",
      "Epoch 40/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4609 - loss: 1.4164\n",
      "Epoch 40: val_loss improved from 1.44389 to 1.43683, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4752 - loss: 1.3931 - val_accuracy: 0.3962 - val_loss: 1.4368\n",
      "Epoch 41/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4688 - loss: 1.3564\n",
      "Epoch 41: val_loss improved from 1.43683 to 1.42496, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4683 - loss: 1.3607 - val_accuracy: 0.4057 - val_loss: 1.4250\n",
      "Epoch 42/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4531 - loss: 1.4082\n",
      "Epoch 42: val_loss improved from 1.42496 to 1.41201, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4615 - loss: 1.4066 - val_accuracy: 0.4245 - val_loss: 1.4120\n",
      "Epoch 43/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4961 - loss: 1.3809\n",
      "Epoch 43: val_loss improved from 1.41201 to 1.39962, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.4853 - loss: 1.4012 - val_accuracy: 0.4245 - val_loss: 1.3996\n",
      "Epoch 44/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4258 - loss: 1.4041\n",
      "Epoch 44: val_loss improved from 1.39962 to 1.38770, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4256 - loss: 1.4353 - val_accuracy: 0.4151 - val_loss: 1.3877\n",
      "Epoch 45/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.4688 - loss: 1.3928\n",
      "Epoch 45: val_loss improved from 1.38770 to 1.37456, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.4762 - loss: 1.3687 - val_accuracy: 0.4151 - val_loss: 1.3746\n",
      "Epoch 46/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.4297 - loss: 1.4057\n",
      "Epoch 46: val_loss improved from 1.37456 to 1.35796, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4458 - loss: 1.4071 - val_accuracy: 0.4245 - val_loss: 1.3580\n",
      "Epoch 47/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.4453 - loss: 1.4419\n",
      "Epoch 47: val_loss improved from 1.35796 to 1.34046, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4542 - loss: 1.4187 - val_accuracy: 0.4245 - val_loss: 1.3405\n",
      "Epoch 48/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5117 - loss: 1.3470\n",
      "Epoch 48: val_loss improved from 1.34046 to 1.32270, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5063 - loss: 1.3450 - val_accuracy: 0.4340 - val_loss: 1.3227\n",
      "Epoch 49/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4805 - loss: 1.3305\n",
      "Epoch 49: val_loss improved from 1.32270 to 1.30347, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4738 - loss: 1.3564 - val_accuracy: 0.4528 - val_loss: 1.3035\n",
      "Epoch 50/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.4727 - loss: 1.3849\n",
      "Epoch 50: val_loss improved from 1.30347 to 1.28231, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4838 - loss: 1.3620 - val_accuracy: 0.4528 - val_loss: 1.2823\n",
      "Epoch 51/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4766 - loss: 1.3190\n",
      "Epoch 51: val_loss improved from 1.28231 to 1.26510, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.4914 - loss: 1.3148 - val_accuracy: 0.4528 - val_loss: 1.2651\n",
      "Epoch 52/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5156 - loss: 1.3082\n",
      "Epoch 52: val_loss improved from 1.26510 to 1.25021, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5044 - loss: 1.3280 - val_accuracy: 0.4528 - val_loss: 1.2502\n",
      "Epoch 53/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 1.3095\n",
      "Epoch 53: val_loss improved from 1.25021 to 1.23648, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5071 - loss: 1.2974 - val_accuracy: 0.4811 - val_loss: 1.2365\n",
      "Epoch 54/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5430 - loss: 1.3391\n",
      "Epoch 54: val_loss improved from 1.23648 to 1.22396, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5277 - loss: 1.3369 - val_accuracy: 0.5094 - val_loss: 1.2240\n",
      "Epoch 55/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.4961 - loss: 1.3682\n",
      "Epoch 55: val_loss improved from 1.22396 to 1.21371, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5121 - loss: 1.3414 - val_accuracy: 0.5094 - val_loss: 1.2137\n",
      "Epoch 56/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5547 - loss: 1.2788\n",
      "Epoch 56: val_loss improved from 1.21371 to 1.20360, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5269 - loss: 1.2989 - val_accuracy: 0.5094 - val_loss: 1.2036\n",
      "Epoch 57/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5039 - loss: 1.3252\n",
      "Epoch 57: val_loss improved from 1.20360 to 1.19415, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.4832 - loss: 1.3332 - val_accuracy: 0.5189 - val_loss: 1.1941\n",
      "Epoch 58/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5078 - loss: 1.2857\n",
      "Epoch 58: val_loss improved from 1.19415 to 1.18672, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.4939 - loss: 1.3109 - val_accuracy: 0.5472 - val_loss: 1.1867\n",
      "Epoch 59/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.4844 - loss: 1.3283\n",
      "Epoch 59: val_loss improved from 1.18672 to 1.18080, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.4956 - loss: 1.2936 - val_accuracy: 0.5472 - val_loss: 1.1808\n",
      "Epoch 60/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5117 - loss: 1.2859\n",
      "Epoch 60: val_loss improved from 1.18080 to 1.17473, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.5078 - loss: 1.2820 - val_accuracy: 0.5566 - val_loss: 1.1747\n",
      "Epoch 61/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5469 - loss: 1.2674\n",
      "Epoch 61: val_loss improved from 1.17473 to 1.16826, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5416 - loss: 1.2601 - val_accuracy: 0.5566 - val_loss: 1.1683\n",
      "Epoch 62/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5781 - loss: 1.1713\n",
      "Epoch 62: val_loss improved from 1.16826 to 1.16218, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5710 - loss: 1.1982 - val_accuracy: 0.5566 - val_loss: 1.1622\n",
      "Epoch 63/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5156 - loss: 1.2556\n",
      "Epoch 63: val_loss improved from 1.16218 to 1.15396, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.5233 - loss: 1.2661 - val_accuracy: 0.5755 - val_loss: 1.1540\n",
      "Epoch 64/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5234 - loss: 1.2357\n",
      "Epoch 64: val_loss improved from 1.15396 to 1.14542, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5370 - loss: 1.2310 - val_accuracy: 0.6038 - val_loss: 1.1454\n",
      "Epoch 65/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5117 - loss: 1.3029\n",
      "Epoch 65: val_loss improved from 1.14542 to 1.13781, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.4984 - loss: 1.3119 - val_accuracy: 0.5943 - val_loss: 1.1378\n",
      "Epoch 66/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5273 - loss: 1.2551\n",
      "Epoch 66: val_loss improved from 1.13781 to 1.12920, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5367 - loss: 1.2608 - val_accuracy: 0.5943 - val_loss: 1.1292\n",
      "Epoch 67/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5195 - loss: 1.2624\n",
      "Epoch 67: val_loss improved from 1.12920 to 1.12246, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5372 - loss: 1.2440 - val_accuracy: 0.6132 - val_loss: 1.1225\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5234 - loss: 1.2353\n",
      "Epoch 68: val_loss improved from 1.12246 to 1.11829, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.5338 - loss: 1.2138 - val_accuracy: 0.6321 - val_loss: 1.1183\n",
      "Epoch 69/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5820 - loss: 1.1529\n",
      "Epoch 69: val_loss improved from 1.11829 to 1.11378, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5660 - loss: 1.1767 - val_accuracy: 0.6415 - val_loss: 1.1138\n",
      "Epoch 70/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5117 - loss: 1.2751\n",
      "Epoch 70: val_loss improved from 1.11378 to 1.10913, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5283 - loss: 1.2656 - val_accuracy: 0.6509 - val_loss: 1.1091\n",
      "Epoch 71/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5391 - loss: 1.1957\n",
      "Epoch 71: val_loss improved from 1.10913 to 1.10479, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5564 - loss: 1.1903 - val_accuracy: 0.6509 - val_loss: 1.1048\n",
      "Epoch 72/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5234 - loss: 1.2048\n",
      "Epoch 72: val_loss improved from 1.10479 to 1.10011, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5307 - loss: 1.2137 - val_accuracy: 0.6604 - val_loss: 1.1001\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5469 - loss: 1.2101\n",
      "Epoch 73: val_loss improved from 1.10011 to 1.09422, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.5464 - loss: 1.2100 - val_accuracy: 0.6698 - val_loss: 1.0942\n",
      "Epoch 74/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5508 - loss: 1.2113\n",
      "Epoch 74: val_loss improved from 1.09422 to 1.08665, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5492 - loss: 1.2003 - val_accuracy: 0.6792 - val_loss: 1.0866\n",
      "Epoch 75/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5547 - loss: 1.1604\n",
      "Epoch 75: val_loss improved from 1.08665 to 1.08071, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.5553 - loss: 1.1710 - val_accuracy: 0.6887 - val_loss: 1.0807\n",
      "Epoch 76/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5742 - loss: 1.1303\n",
      "Epoch 76: val_loss improved from 1.08071 to 1.07535, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5823 - loss: 1.1315 - val_accuracy: 0.6887 - val_loss: 1.0754\n",
      "Epoch 77/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6133 - loss: 1.1338\n",
      "Epoch 77: val_loss improved from 1.07535 to 1.07079, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5953 - loss: 1.1374 - val_accuracy: 0.6792 - val_loss: 1.0708\n",
      "Epoch 78/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6289 - loss: 1.0738\n",
      "Epoch 78: val_loss improved from 1.07079 to 1.06842, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6241 - loss: 1.0876 - val_accuracy: 0.6698 - val_loss: 1.0684\n",
      "Epoch 79/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5977 - loss: 1.1085\n",
      "Epoch 79: val_loss improved from 1.06842 to 1.06576, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5775 - loss: 1.1312 - val_accuracy: 0.6792 - val_loss: 1.0658\n",
      "Epoch 80/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5781 - loss: 1.1076\n",
      "Epoch 80: val_loss improved from 1.06576 to 1.06404, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.5804 - loss: 1.1346 - val_accuracy: 0.6887 - val_loss: 1.0640\n",
      "Epoch 81/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6094 - loss: 1.0999\n",
      "Epoch 81: val_loss improved from 1.06404 to 1.06167, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6034 - loss: 1.1053 - val_accuracy: 0.6792 - val_loss: 1.0617\n",
      "Epoch 82/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5898 - loss: 1.1899\n",
      "Epoch 82: val_loss improved from 1.06167 to 1.05773, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5812 - loss: 1.1832 - val_accuracy: 0.6887 - val_loss: 1.0577\n",
      "Epoch 83/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5938 - loss: 1.0894\n",
      "Epoch 83: val_loss improved from 1.05773 to 1.05326, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5904 - loss: 1.1149 - val_accuracy: 0.6887 - val_loss: 1.0533\n",
      "Epoch 84/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5898 - loss: 1.1338\n",
      "Epoch 84: val_loss improved from 1.05326 to 1.05036, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.5890 - loss: 1.1369 - val_accuracy: 0.6792 - val_loss: 1.0504\n",
      "Epoch 85/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6445 - loss: 1.1184\n",
      "Epoch 85: val_loss improved from 1.05036 to 1.04784, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.6435 - loss: 1.1215 - val_accuracy: 0.6887 - val_loss: 1.0478\n",
      "Epoch 86/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6016 - loss: 1.0235\n",
      "Epoch 86: val_loss improved from 1.04784 to 1.04555, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.5993 - loss: 1.0519 - val_accuracy: 0.6792 - val_loss: 1.0456\n",
      "Epoch 87/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5859 - loss: 1.1274\n",
      "Epoch 87: val_loss improved from 1.04555 to 1.04490, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.5846 - loss: 1.1149 - val_accuracy: 0.6981 - val_loss: 1.0449\n",
      "Epoch 88/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6133 - loss: 1.0758\n",
      "Epoch 88: val_loss improved from 1.04490 to 1.04443, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6268 - loss: 1.0656 - val_accuracy: 0.6981 - val_loss: 1.0444\n",
      "Epoch 89/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6367 - loss: 1.0590\n",
      "Epoch 89: val_loss improved from 1.04443 to 1.04424, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6110 - loss: 1.0925 - val_accuracy: 0.6887 - val_loss: 1.0442\n",
      "Epoch 90/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6562 - loss: 1.0435\n",
      "Epoch 90: val_loss improved from 1.04424 to 1.04333, saving model to models/ser_1d_26_09_2024_15_17_47.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6427 - loss: 1.0472 - val_accuracy: 0.7075 - val_loss: 1.0433\n",
      "Epoch 91/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6289 - loss: 1.0159\n",
      "Epoch 91: val_loss did not improve from 1.04333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6163 - loss: 1.0327 - val_accuracy: 0.6981 - val_loss: 1.0435\n",
      "Epoch 92/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6094 - loss: 1.0690\n",
      "Epoch 92: val_loss did not improve from 1.04333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6176 - loss: 1.0643 - val_accuracy: 0.6981 - val_loss: 1.0438\n",
      "Epoch 93/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5938 - loss: 1.1110\n",
      "Epoch 93: val_loss did not improve from 1.04333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5840 - loss: 1.1104 - val_accuracy: 0.6887 - val_loss: 1.0456\n",
      "Epoch 94/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6055 - loss: 1.1228\n",
      "Epoch 94: val_loss did not improve from 1.04333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6132 - loss: 1.0966 - val_accuracy: 0.6887 - val_loss: 1.0472\n",
      "Epoch 95/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6523 - loss: 1.0368\n",
      "Epoch 95: val_loss did not improve from 1.04333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6493 - loss: 1.0294 - val_accuracy: 0.6981 - val_loss: 1.0459\n",
      "Epoch 96/1000\n",
      "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6328 - loss: 1.0231\n",
      "Epoch 96: val_loss did not improve from 1.04333\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6365 - loss: 1.0230 - val_accuracy: 0.6981 - val_loss: 1.0448\n",
      "Epoch 96: early stopping\n",
      "Restoring model weights from the end of the best epoch: 86.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5952 - loss: 1.0456 \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5952 - loss: 1.0456 \n",
      "Loss : 1.0313513278961182, Accuracy : 0.6271186470985413\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"models/ser_1d_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=256,\n",
    "                       epochs=1000,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {model.evaluate(X_test,y_test)[0]}, Accuracy : {model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.panel.rocket import Rocket\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=22)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=22)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(423, 197, 1)\n",
      "(423, 20000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "trf = Rocket() \n",
    "trf.fit(X_train) \n",
    "X_train = trf.transform(X_train) \n",
    "print(X_train.shape)\n",
    "X_val = trf.transform(X_val)\n",
    "X_test = trf.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.expand_dims(X_train,axis = 2)\n",
    "X_val = np.expand_dims(X_val,axis = 2)\n",
    "X_test = np.expand_dims(X_test,axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "model = keras.Sequential()\n",
    "kernel_sizes = [5, 5]\n",
    "model.add(keras.layers.Input(shape=(X_train.shape[1],1)))\n",
    "for size in kernel_sizes:\n",
    "    model.add(keras.layers.Conv1D(\n",
    "        filters = 32,\n",
    "        kernel_size = size,\n",
    "        padding = 'same'\n",
    "    ))  # 卷积层\n",
    "    model.add(keras.layers.BatchNormalization(axis=-1))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32))\n",
    "model.add(keras.layers.BatchNormalization(axis = -1))\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Dense(7, activation='softmax'))  # 分类层\n",
    "optimzer = keras.optimizers.Adam(learning_rate= 0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimzer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1396 - loss: 2.4651\n",
      "Epoch 1: val_loss improved from inf to 3.83423, saving model to models/ser_rocket_26_09_2024_15_09_59.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3s/step - accuracy: 0.1380 - loss: 2.4583 - val_accuracy: 0.1792 - val_loss: 3.8342\n",
      "Epoch 2/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1130 - loss: 2.5742\n",
      "Epoch 2: val_loss did not improve from 3.83423\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1116 - loss: 2.5806 - val_accuracy: 0.1792 - val_loss: 4.9840\n",
      "Epoch 3/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1557 - loss: 2.5171\n",
      "Epoch 3: val_loss did not improve from 3.83423\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1543 - loss: 2.5176 - val_accuracy: 0.1792 - val_loss: 4.9219\n",
      "Epoch 4/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1228 - loss: 2.5942\n",
      "Epoch 4: val_loss did not improve from 3.83423\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1220 - loss: 2.6022 - val_accuracy: 0.1792 - val_loss: 4.1736\n",
      "Epoch 5/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.0989 - loss: 2.6298\n",
      "Epoch 5: val_loss improved from 3.83423 to 3.22295, saving model to models/ser_rocket_26_09_2024_15_09_59.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.1046 - loss: 2.6182 - val_accuracy: 0.1792 - val_loss: 3.2230\n",
      "Epoch 6/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1330 - loss: 2.4580\n",
      "Epoch 6: val_loss improved from 3.22295 to 2.39874, saving model to models/ser_rocket_26_09_2024_15_09_59.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.1304 - loss: 2.4700 - val_accuracy: 0.1792 - val_loss: 2.3987\n",
      "Epoch 7/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1451 - loss: 2.5271\n",
      "Epoch 7: val_loss improved from 2.39874 to 1.99701, saving model to models/ser_rocket_26_09_2024_15_09_59.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3s/step - accuracy: 0.1440 - loss: 2.5283 - val_accuracy: 0.1792 - val_loss: 1.9970\n",
      "Epoch 8/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1455 - loss: 2.5298\n",
      "Epoch 8: val_loss improved from 1.99701 to 1.97437, saving model to models/ser_rocket_26_09_2024_15_09_59.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.1419 - loss: 2.5408 - val_accuracy: 0.0755 - val_loss: 1.9744\n",
      "Epoch 9/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1228 - loss: 2.5430\n",
      "Epoch 9: val_loss did not improve from 1.97437\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1220 - loss: 2.5427 - val_accuracy: 0.0755 - val_loss: 1.9830\n",
      "Epoch 10/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1158 - loss: 2.4931\n",
      "Epoch 10: val_loss did not improve from 1.97437\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1205 - loss: 2.4948 - val_accuracy: 0.0755 - val_loss: 1.9971\n",
      "Epoch 11/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1640 - loss: 2.4981\n",
      "Epoch 11: val_loss did not improve from 1.97437\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1613 - loss: 2.4893 - val_accuracy: 0.0755 - val_loss: 2.0111\n",
      "Epoch 12/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1193 - loss: 2.4411\n",
      "Epoch 12: val_loss did not improve from 1.97437\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1213 - loss: 2.4445 - val_accuracy: 0.0755 - val_loss: 2.0250\n",
      "Epoch 13/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1502 - loss: 2.4874\n",
      "Epoch 13: val_loss did not improve from 1.97437\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1482 - loss: 2.4877 - val_accuracy: 0.0755 - val_loss: 2.0382\n",
      "Epoch 14/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1922 - loss: 2.3464\n",
      "Epoch 14: val_loss did not improve from 1.97437\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1912 - loss: 2.3541 - val_accuracy: 0.0755 - val_loss: 2.0497\n",
      "Epoch 15/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1275 - loss: 2.5212\n",
      "Epoch 15: val_loss did not improve from 1.97437\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1283 - loss: 2.5200 - val_accuracy: 0.1509 - val_loss: 2.0616\n",
      "Epoch 16/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1514 - loss: 2.3608\n",
      "Epoch 16: val_loss did not improve from 1.97437\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1498 - loss: 2.3687 - val_accuracy: 0.1509 - val_loss: 2.0721\n",
      "Epoch 17/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1240 - loss: 2.5219\n",
      "Epoch 17: val_loss did not improve from 1.97437\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1236 - loss: 2.5181 - val_accuracy: 0.1509 - val_loss: 2.0818\n",
      "Epoch 18/1000\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.1648 - loss: 2.4446\n",
      "Epoch 18: val_loss did not improve from 1.97437\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.1650 - loss: 2.4371 - val_accuracy: 0.1509 - val_loss: 2.0926\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2528 - loss: 1.9336\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2528 - loss: 1.9336\n",
      "Loss : 1.935768485069275, Accuracy : 0.2542372941970825\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime  \n",
    "name = datetime.now().strftime(\"models/ser_rocket_%d_%m_%Y_%H_%M_%S.keras\")  \n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath = name,\n",
    "        save_best_only=True,\n",
    "        verbose=1,\n",
    "        monitor=\"val_loss\"),\n",
    "\n",
    "    keras.callbacks.EarlyStopping(  \n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0.01,\n",
    "        patience=10,\n",
    "        verbose=1,\n",
    "        mode=\"auto\",\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                       validation_data=(X_val,y_val), \n",
    "                       batch_size=256,\n",
    "                       epochs=1000,\n",
    "                       callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(f\"Loss : {model.evaluate(X_test,y_test)[0]}, Accuracy : {model.evaluate(X_test,y_test)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_test[0].reshape(1,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.collections as mcoll\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import itertools\n",
    "import logging\n",
    "# Set random seed\n",
    "np.random.seed(123)\n",
    "\n",
    "def multicolored_lines(x,y,heatmap,title_name):\n",
    "    fig, ax = plt.subplots()\n",
    "    lc = colorline(x, y, heatmap,cmap='rainbow')\n",
    "    plt.colorbar(lc)\n",
    "    lc.set_linewidth(2)\n",
    "    lc.set_alpha(0.8)\n",
    "    plt.xlim(x.min(), x.max())\n",
    "    plt.ylim(y.min(), y.max())\n",
    "    plt.title(title_name)\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "def colorline(x, y, heatmap,cmap='rainbow'):\n",
    "    z = np.array(heatmap)\n",
    "    points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "    lc = mcoll.LineCollection(segments, array=z, cmap=cmap)\n",
    "    ax = plt.gca()\n",
    "    ax.add_collection(lc)\n",
    "    return lc\n",
    "def compute_cam_1d_output (model, data , layer_name , N):\n",
    "        \"\"\"\n",
    "        model: The Deep Learning model\n",
    "        data : A input data. Data shape has to be (n,1,1)\n",
    "        layer_name : The target layer for explanation\n",
    "        N: signal length in seconds\n",
    "        \"\"\"\n",
    "        # input layer, model output layer and target layer\n",
    "        grad_model = tf.keras.models.Model(inputs=[model.inputs],\n",
    "                                           outputs=[model.get_layer(layer_name).output,model.output])     \n",
    "        \n",
    "        # Getting gradients of input layer, model output layer (predictions) and target layer\n",
    "        with tf.GradientTape() as tape:\n",
    "            inputs = np.expand_dims(data,axis=0)\n",
    "            conv_outs, predictions = grad_model(inputs) \n",
    "            class_idx = tf.argmax(predictions[0])\n",
    "            y_c = predictions[:, class_idx]\n",
    "\n",
    "        batch_grads = tape.gradient(y_c, conv_outs) \n",
    "        grads = batch_grads[0]\n",
    "        \n",
    "        # First, second and third derivative of output gradient\n",
    "        first = tf.exp(y_c) * grads\n",
    "        second = tf.exp(y_c) * tf.pow(grads, 2)\n",
    "        third = tf.exp(y_c) * tf.pow(grads, 3)\n",
    "        \n",
    "        # Compute salienty maps for the class_idx prediction\n",
    "        global_sum = tf.reduce_sum(tf.reshape(conv_outs[0], shape=(-1, first.shape[1])), axis=0)\n",
    "        alpha_num = second\n",
    "        alpha_denom = second * 2.0 + third * tf.reshape(global_sum, shape=(1,1,first.shape[1]))\n",
    "        alpha_denom = tf.where(alpha_denom != 0.0, alpha_denom, tf.ones(shape=alpha_denom.shape))\n",
    "        alphas = alpha_num / alpha_denom\n",
    "        weights = tf.maximum(first, 0.0)\n",
    "        alpha_normalization_constant = tf.reduce_sum(tf.reduce_sum(alphas, axis=0), axis=0)\n",
    "        alphas /= tf.reshape(alpha_normalization_constant, shape=(1,1,first.shape[1]))\n",
    "        alphas_thresholding = np.where(weights, alphas, 0.0)\n",
    "\n",
    "        alpha_normalization_constant = tf.reduce_sum(tf.reduce_sum(alphas_thresholding, axis=0),axis=0)\n",
    "        alpha_normalization_constant_processed = tf.where(alpha_normalization_constant != 0.0, alpha_normalization_constant,\n",
    "                                                          tf.ones(alpha_normalization_constant.shape))\n",
    "\n",
    "        alphas /= tf.reshape(alpha_normalization_constant_processed, shape=(1,1,first.shape[1]))\n",
    "        deep_linearization_weights = tf.reduce_sum(tf.reshape((weights*alphas), shape=(-1,first.shape[1])), axis=0)\n",
    "        grad_CAM_map = tf.reduce_sum(deep_linearization_weights * conv_outs[0], axis=-1)\n",
    "        \n",
    "        # Normalization\n",
    "        cam = np.maximum(grad_CAM_map, 0)\n",
    "        cam = cam / np.max(cam)  \n",
    "        \n",
    "        # Turn result into a heatmap\n",
    "        heatmap=[]\n",
    "        heatmap.append(cam.tolist())\n",
    "        big_heatmap = cv2.resize(np.array(heatmap), dsize=(data.shape[0], 500),interpolation=cv2.INTER_CUBIC)\n",
    "        x = np.linspace(0, N, data.shape[0])\n",
    "        plt.style.use(\"seaborn-whitegrid\")\n",
    "        multicolored_lines(x,np.array([i[0] for i in data]),big_heatmap[0],f\"GradCAM ++ Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The layer sequential_3 has never been called and thus has no defined output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcompute_cam_1d_output\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdense_6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[53], line 45\u001b[0m, in \u001b[0;36mcompute_cam_1d_output\u001b[1;34m(model, data, layer_name, N)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03mmodel: The Deep Learning model\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03mdata : A input data. Data shape has to be (n,1,1)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03mlayer_name : The target layer for explanation\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03mN: signal length in seconds\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# input layer, model output layer and target layer\u001b[39;00m\n\u001b[0;32m     44\u001b[0m grad_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m[model\u001b[38;5;241m.\u001b[39minputs],\n\u001b[1;32m---> 45\u001b[0m                                    outputs\u001b[38;5;241m=\u001b[39m[model\u001b[38;5;241m.\u001b[39mget_layer(layer_name)\u001b[38;5;241m.\u001b[39moutput,\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m])     \n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Getting gradients of input layer, model output layer (predictions) and target layer\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n",
      "File \u001b[1;32mc:\\Users\\anton\\Documents\\PhD\\Speech_Emotion_Recognition\\EMOVO_dataset\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:266\u001b[0m, in \u001b[0;36mOperation.output\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moutput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    258\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the output tensor(s) of a layer.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m        Output tensor or list of output tensors.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\anton\\Documents\\PhD\\Speech_Emotion_Recognition\\EMOVO_dataset\\.venv\\Lib\\site-packages\\keras\\src\\ops\\operation.py:285\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    287\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     )\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    291\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    294\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The layer sequential_3 has never been called and thus has no defined output."
     ]
    }
   ],
   "source": [
    "compute_cam_1d_output (model, data , \"dense_6\" , 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
